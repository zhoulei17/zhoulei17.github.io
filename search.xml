<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>【Solr】-【SolrCloud】SolrCloud核心概念</title>
    <url>/2020/04/25/solr-solrcloud/</url>
    <content><![CDATA[<h1 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h1><h2 id="core"><a href="#core" class="headerlink" title="core"></a>core</h2><h2 id="collection"><a href="#collection" class="headerlink" title="collection"></a>collection</h2><p>SolrCloud使用集合这个概念来描述多个Solr实例的索引分割。</p>
<h2 id="shard"><a href="#shard" class="headerlink" title="shard"></a>shard</h2><h2 id="replic"><a href="#replic" class="headerlink" title="replic"></a>replic</h2><h2 id="master-slave"><a href="#master-slave" class="headerlink" title="master-slave"></a>master-slave</h2><h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><p>ZK提供Solr集中化的配置管理、集群状态管理和选主（分片代表,leader）的作用。</p>
<p>Solr创建的watcher会更新/clusterstate.json 这个znode节点，已便集群状态改变时通知其他所有节点。</p>
<h2 id="如何选择分片代表"><a href="#如何选择分片代表" class="headerlink" title="如何选择分片代表"></a>如何选择分片代表</h2><h3 id="分工"><a href="#分工" class="headerlink" title="分工"></a>分工</h3><p><strong>针对索引更新：</strong></p>
<p><strong>分片代表</strong>负责接收更新请求，并将这些更新请求协调分配至各个副本。具体来说，分片代表负责以下几项额外的更新请求，副本无法负责这些请求：</p>
<ul>
<li>为分片接收更新请求。</li>
<li>在更新后的文档上增加<strong><em>version</em></strong>字段的值，并将之执行乐观锁定。</li>
<li>将文档写入更新日志。</li>
<li>以并行方式将更新请求发送给所有副本并且封锁，直到收到响应。</li>
</ul>
<p><strong>针对查询：</strong></p>
<p>在处理查询请求时，分片代表没有额外的工作。每个分片的主机都可以充当分片代表的角色，其他主机自然就是副本了。与副本一样，分片代表也可以参与到分布式查询（这个跟主从架构不一样）。</p>
<p>在<strong>主从架构</strong>中，主节点只负责索引，而从节点负责执行查询。</p>
<h3 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h3><p>在了解如何确定分片代表之前，我们要搞清楚选择分片的目的是什么？</p>
<p>SolrCloud的设计目的在于，让分片里的任何主机都能充当代表，并且能够选择新的代表。我们不应该也不用关注分片里的哪个节点是当前代表，也不要尝试控制它。在大多数情况下，分片代表仅仅是一个实现的细节问题，对怎么设置和操作集群是没有什么影响的。</p>
<h3 id="分片代表选择"><a href="#分片代表选择" class="headerlink" title="分片代表选择"></a>分片代表选择</h3><p>选择最初的代表和在当前代表出现故障时自动选择一个新的代表。对于代表的选择需要<strong>集中控制</strong>，不希望出现同一个分片里的两台主机(对应两个replicas)都是代表的情况。</p>
<p>在我们了解的一些分布式系统中，有的代表（leader）是通过leader和follow之间通过协同一致性算法进行选择，比如我们耳熟能详的<a href="http://thesecretlivesofdata.com/raft/" target="_blank" rel="noopener"><strong>Raft算法</strong></a>、<strong>Paxos</strong>等。现在我们有了Zookeeper分布式协调器这个现现成的解决方案，就可以进行集中的控制。</p>
<p>为了说明代表是如何选择的，我们来举一个场景作为例子说明：</p>
<p>假设，一个分片(shard)有4个副本(replicas)，它们同时加入集群，需要选择其中一个副本作为代表。</p>
<p>4个节点中的第1个注册的节点应该被选为分片代表。在后台，Solr使用ZoooKeeper的序列标志跟踪各节点各自注册成为代表候选人的顺序。序列标志以原子方式递增，所以有客户端试图同时增加序列，也不会造成什么影响。</p>
<img data-src="/img/in-post/image-20200426015339058.png" alt="image-20200426015339058" style="zoom: 50%;" />

<p>如上图，我们有16个shard，每个shard有1个replicas。如图，/shard1/election下的数据节点(znode)就表示每个shard有1个个replicas，红框为序列标志。（此处只有1个replicas，如果有2个replicas，下面一个序列号就是递增的）</p>
<ul>
<li><p>序列号最小的节点会胜出，成为分片代表。</p>
</li>
<li><p>如果当前代表处故障的话，会发生什么呢？</p>
<p>这种情况需要选出新的代表，索引才能继续进行。事实证明，候选序列中下一个状态良好的节点会成为代表。（关于代表故障如何转移的细节，可以阅读<a href="http://zookeeper.apache.org/doc/r3.5.7/recipes.html" target="_blank" rel="noopener">ZooKeeper的文档</a>）</p>
</li>
</ul>
<h1 id="SolrCloud的有关配置"><a href="#SolrCloud的有关配置" class="headerlink" title="SolrCloud的有关配置"></a>SolrCloud的有关配置</h1><h2 id="solr-xml"><a href="#solr-xml" class="headerlink" title="solr.xml"></a>solr.xml</h2>]]></content>
      <categories>
        <category>Solr</category>
      </categories>
      <tags>
        <tag>Solr</tag>
        <tag>Search</tag>
        <tag>SolrCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>【Solr】-【SolrCloud】分布式索引</title>
    <url>/2020/04/25/solr-solrcloud%E2%80%94index/</url>
    <content><![CDATA[<p>SloudCloud中shard中的索引与单机中的索引文档是一样的结构，且一个shard的多个replicas理想状态下是完全一样的。从客户端角度看，在访问单机索引或分布式索引客户端是不感知的。从Solr服务器角度看，原来单机的索引被分割为多个shard索引目录，就单个shard来说，都是一个完整的索引结果，都可以单独访问。</p>
<p>SolrCloud中分布式索引的总体目标是能够把文档发送到集群的的任何节点上，并且能把文档在正确的分片中被索引。此外，SolrCloud的分布式索引目的在于，能够避免单点故障，达到高可用。</p>
<h1 id="文档的分片"><a href="#文档的分片" class="headerlink" title="文档的分片"></a>文档的分片</h1><p>当Solr索引新文档时，需要将其分配到一个分片上。Solr使用<strong>文档管理器</strong>组件来确认文档应当被分到哪个分片上。SolrCloud支持两种文档路由策略：</p>
<ul>
<li>compositeID(默认)</li>
<li>隐式路由。用户可以自定义路由策略。</li>
</ul>
<img data-src="/img/in-post/image-20200426015707997.png" alt="image-20200426015707997" style="zoom: 50%;" />

<p>查看/clusterstate.json，可以看到笔者所在公司collection由16个shard组成。每个分片会分配一个32位的散列值，如上图，shar1的散列区间是80000000-8fffffff，而shard2的散列区间是90000000-9fffffff(十六进制数)。系统在每个分片之间均分这32位散列值区间。</p>
<p>默认的compositeID路由器会计算出文档里唯一ID字段的数值散列值，并将文档分配给哈希值区间包含计算得到的哈希值的分片。每个发送给SolrCloud的文档都必须具有唯一的文档ID号。</p>
<p>（注：这种Hash算法的源码为：</p>
<p><code>HashBasedRouter</code>，使用了一种称为<code>murmurhash3_x86_32</code>的hash算法。有兴趣的同学，可以自行扩展阅读源码。）</p>
<p>如上图，如果当前这份文档唯一ID字段的散列值是80000001(十六进制)，那这份文档会被分配到shard1。</p>
<p>关于文档ID的散列值如何计算的问题，可以看我括号注明的Solr源码。这个散列函数的目标（基本上所有的散列的函数都是）：第一、必须要要块，因为在分布式Solr中，确定将文档分配到哪个分片是非常基本的操作；第二、应该把文档在分片之间平均分配。如果不平均分配，很可能这个shard就会出现查询瓶颈，这样总的查询时间就会延长。</p>
<h1 id="添加文档到分布式索引"><a href="#添加文档到分布式索引" class="headerlink" title="添加文档到分布式索引"></a>添加文档到分布式索引</h1><p>介绍下，如何把文档添加到索引中，这是理解SolrCloud中其他类型的更新请求工作原理的基础。下面画了SolrCloud中分布式文档的索引过程。</p>
<img data-src="/img/in-post/image-20200426014919722.png" alt="image-20200426014919722" style="zoom:50%;" />

<h2 id="步骤1：使用CloudSolrClient发送更新请求"><a href="#步骤1：使用CloudSolrClient发送更新请求" class="headerlink" title="步骤1：使用CloudSolrClient发送更新请求"></a>步骤1：使用CloudSolrClient发送更新请求</h2><p>首先CloudSolrClient连接到ZooKeeper上以获取集群的当前状态。即，索引客户端知道集群里哪个节点是Leader，以及每个节点的状态。在客户端中生成请求时会判断当前集群状态。</p>
<p>CloudSolrClient获取集群状态有两个好处：</p>
<ol>
<li>更新请求在被路由到副本之前一定会被路由给分片的代表，所以不如直接发请求给分片代表。</li>
<li>可以提供基本的负载均衡和客户端重试机制。如果客户端应用程序正在索引文档，一个节点崩溃了，CloudSolrClient会从ZK得到通知，该节点不可用，然后就会停止向该节点发送请求（从负载均衡列表中删除）。如果崩溃的节点是代表，那么CloudSolrClient会受到选择新分片代表的通知。以后通知能收到的原因是，CloudSolrClient已经在ZK的/clusterstate.json和live_nodes znode节点注册了watcher监听。</li>
</ol>
<h2 id="步骤2：将文档分配给正确的分片"><a href="#步骤2：将文档分配给正确的分片" class="headerlink" title="步骤2：将文档分配给正确的分片"></a>步骤2：将文档分配给正确的分片</h2><p>CloudSolrClient需要使用文档路由来确定将文档发送到哪个分片上。源码见方法：</p>
<pre><code class="java">  public Map&lt;String,LBHttpSolrClient.Req&gt; getRoutes(DocRouter router,
      DocCollection col, Map&lt;String,List&lt;String&gt;&gt; urlMap,
      ModifiableSolrParams params, String idField) 
  {

  }</code></pre>
<p>一旦分片被选中，并会走客户端负载均衡选出serverUrl，并使用原HttpSolrClient 发送请求。</p>
<p>单个文档添加的过程非常简单。但是，如果添加到CloudSolrClient中文档是如何分发的？</p>
<p>会把该批次的文档分解成shard数批次，比如我们的shard是16，那么这篇文档被分解为16批次，然后使用文档路由的计算方法把每一篇文档分解到对应的16个批次的其中一个去。最后，再将自批次发送给各个正确的分片代表。</p>
<h2 id="步骤3：shard代表分配版本ID号"><a href="#步骤3：shard代表分配版本ID号" class="headerlink" title="步骤3：shard代表分配版本ID号"></a>步骤3：shard代表分配版本ID号</h2><p>在将文档发送给副本之前，分片代表会在本地索引文档。这是为了把文档转送给副本之前，使用更新日志验证文档并确保文档是安全持久的存储了。此外代表会给每个文档分配一个版本号。对现存文档，代表会将文档的当前版本与版本号作对比，以支持乐观锁定的过程。</p>
<h2 id="步骤4：将请求转发给副本"><a href="#步骤4：将请求转发给副本" class="headerlink" title="步骤4：将请求转发给副本"></a>步骤4：将请求转发给副本</h2><p>一旦文档通过验证并且给分配了版本号。代表就会决定哪些副本是OK的，并多线程的把更新请求发送给每个副本。对于任何更新请求，都可能会有一些副本处于脱机或宕机状态。代表在发送文件时并不关心副本发生了啥情况，因为代表能够使用恢复程序对没有发送成功的文档进行修复。</p>
<p>还有一种情况，代表也会把更新请求发送给那些还在恢复状态的副本。处在恢复状态的副本节点在恢复运行过程中会把更新请求写到自己的更新事务日志里面去。</p>
<h2 id="步骤5：确认写操作成功"><a href="#步骤5：确认写操作成功" class="headerlink" title="步骤5：确认写操作成功"></a>步骤5：确认写操作成功</h2><p>一旦代表收到了来自所有活跃和恢复进程中的副本的确认，它就会把确认返回给索引客户端。只要分片里面至少还有一个活跃的副本，Solr就会持续地接收更新请求。然而，<strong>这种方法更偏向于写操作的可用性</strong>，虽然有可能会<strong>以失去一致性</strong>为代价。在<strong>包含Solr-4.9之后的版本</strong>，用执行QUORUM（关于QUORUM问题，网上有很多介绍，比如<a href="https://www.cnblogs.com/hapjin/p/5626889.html" target="_blank" rel="noopener">这篇</a>）机制以便接受：</p>
<pre><code class="java">SOLR-5468: Allow a client application to request the minium achieved
  replication factor for an update request (single or batch) by sending
  an optional parameter &quot;min_rf&quot;. (Timothy Potter)</code></pre>
<p>比起写操作的可用性，这种可选方法更加注重一致性。如果写操作不能被分片里的大部分副本接受，那么写操作就会失败。</p>
<p>在假设场景中，如果一个分片只有一个活跃副本，写操作就会失败，因为在只有两个副本的分片中，1个节点不能表示大多数。如果分片被复制到三个节点上，其中一个节点出现了故障，那么写操作会成功（大于3分之2）。</p>
<p>当然，在服务器段引起写操作失败知会把问题带给客户端，但至少可以避免掉代表和副本之间不一致的可能。</p>
<p>这也说明了，在构建分布式的系统中，在写操作的可用性和一致性上会存在权衡取舍。</p>
<h2 id="提交"><a href="#提交" class="headerlink" title="提交"></a>提交</h2><p>除非文件被提交了，否则在搜索结果里是看不到它们的。在分布式式搜索中，当提交请求发送给任何节点时，系统会将提交请求转发给集群里的搜索节点，以便顺利提交每个分片。</p>
<p>简单说，在需要打开新的SolrIndexSearcher时，客户端应用程序代码应该发送硬提交请求，SolrCloud会将提交请求传播给集群里的所有节点。</p>
<h1 id="近实时搜索（NRT）"><a href="#近实时搜索（NRT）" class="headerlink" title="近实时搜索（NRT）"></a>近实时搜索（NRT）</h1><p>引用网上的一句话：</p>
<blockquote>
<p>如果不学习近实时搜索（NRT），那么对于SolrCloud的理解就是不完整的，因为它是SolrCloud设计背后的主要驱动之一。</p>
</blockquote>
<p>近实时搜索能够使文件在被索引之后的数秒内就出现在搜索结果中。Solr提供软提交机制实现近实时搜索，可以避免硬提交高昂的操作成本，比如把存储在内存的文件写入词频。</p>
<p>在上文中介绍了，分片代码在对索引客户端程序做响应之前，会将更新请求转发给所有副本。这可以确保所有分片产生一致的搜索结果。</p>
<p>这也说明了，此设计决定把更新发送给所有副本在很大程度上依赖了近实时搜索的支持。</p>
<p>相反，主从系统里面不能支持近实时搜索，这是因为近实时搜索的目的是使文档在被添加到索引之后的大约一秒钟内就能搜到。基于主从系统的复制操作依赖将整个片段从主节点复制到从节点。如果Solr必须每秒都讲片段复制到从节点上，搜索性能就会简练很多个小片段，查询性能就会大大受到影响。</p>
<h2 id="软提交"><a href="#软提交" class="headerlink" title="软提交"></a>软提交</h2><p>由于软提交的成本更低，所以每隔几秒钟就可以发起一个软提交，这样就可以在近实时搜搜中看到新近被搜索的文件。然后在某个时间点还是要执行硬提交，确保索引永久持久化。</p>
<p>当提交软提交时，Solr必须打开新的搜索器，让软提交的文档在搜索结果可见。这就意味，SOLR还必须让所有缓存与软提交带来的改变保持一致。</p>
<p>在软提交之后打开新的搜索器，Solr会对缓存进行预热，执行在solrconfig.xml中配置好的预热查询。</p>
<p>因此，缓存预热设置和预热查询的执行速度必须比执行软提交的速度更快。如果每隔两秒钟执行一次软提交，那么预热查询和缓存自动预热的完成就不应该超过两秒，否则会打开太多的搜索器被打开，这会导致后期提交失败。</p>
<p>还有个关键点是，执行软提交时，需要为近实时搜索恰当地调整缓存和预热查询的配置。</p>
<p>近实时搜索，为什么这么强大的功能，但并不是说一定要将它与SOLRCLOUD一块使用。不使用软提交，近实时搜索也完全可以接受。</p>
<p>使用软提交的的缺点之一，就是缓存经常会失效。</p>
<h1 id="Solr如何对代表和副本保持同步"><a href="#Solr如何对代表和副本保持同步" class="headerlink" title="Solr如何对代表和副本保持同步"></a>Solr如何对代表和副本保持同步</h1><p>在设计和运行大型分布式系统时，节点出现故障本就是普遍现象。当节点出现故障时，只需要简单使用复制操作来保护系统，无须购买昂贵的机器和容错硬件。此外，还需要升级SOLR，修复错误和增加新功能，或修改JVM。最坏的情况是，集群中随时都可能出现宕机或者脱机。不过SolrCloud可能搞定：</p>
<p>SolrCloud提供了两种基本的恢复方案：<strong>对等同步(peer sync)</strong>和<strong>快照复制(snapshot replication)</strong>。根据在节点脱机状态下错过了多少更新请求（增加、删除和更新），这两个方案的恢复过程是由差异的：</p>
<ul>
<li><strong>对等同步</strong>——如果故障时间短，并且处于恢复状态的节点只错过了少数的更新请求，那么节点就会从分片代表的更新日志中获取更新请求。目前错过更新请求的上限硬编码为100。如果错过的数量超过这个限制，恢复节点将从分片代表哪里获取完整的索引快照。</li>
<li><strong>快照复制</strong>——如果一节点较长时间处于脱机状态，导致它不能与分片代表保持同步，那么它会使用Solr的基于HTTP的复制操作，基于索引的快照进行恢复。</li>
</ul>
<p>大多数情况下，都不需要担心这些过程，因为节点能够将索引状态和分片代表作比较，自动启用合适的处理程序处理。这也可以保证，可以在任何时间将副本添加到集群里，因为它能自己从分片哪里获取完整的索引。</p>
]]></content>
      <categories>
        <category>Solr</category>
      </categories>
      <tags>
        <tag>Solr</tag>
        <tag>Search</tag>
        <tag>SolrCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>【Solr】-【SolrCloud】分布式搜索</title>
    <url>/2020/04/25/solr-solrcloud%E2%80%94search/</url>
    <content><![CDATA[<p>源码入口为：</p>
<pre><code>SearchHandler</code></pre><p>跟单机Solr不同，SolrCloud模式下，必须查询所有的分片才能得得到完整得结果集合。查询结果集合里所有分片并创建统一结果集的过程称为<strong>分布式查询</strong>。</p>
<p>SolrCloud模式下，distrib参数默认为true。distrib参数设置false则禁用分布式查询，只能借助本地搜索执行查询。</p>
<h1 id="多阶段查询流程"><a href="#多阶段查询流程" class="headerlink" title="多阶段查询流程"></a>多阶段查询流程</h1><img data-src="/img/in-post/image-20200426223554450.png" alt="image-20200426223554450" style="zoom:50%;" />

<h2 id="步骤1：客户端发送查询请求到任何节点"><a href="#步骤1：客户端发送查询请求到任何节点" class="headerlink" title="步骤1：客户端发送查询请求到任何节点"></a>步骤1：客户端发送查询请求到任何节点</h2><p>当客户端应用程序向集群中的任意节点发送查询请求时，分布式查询从这里开始。客户端发送请求的方式，可以使用负载均衡器将查询请求分配到集群中各个不同的节点上。也可以在代码中调用SolrJ，那么CloudSolrClient类就会充当一个简单分布式查询请求的负载均衡器。</p>
<h2 id="步骤2：查询控制器接收请求"><a href="#步骤2：查询控制器接收请求" class="headerlink" title="步骤2：查询控制器接收请求"></a>步骤2：查询控制器接收请求</h2><p>分布式查询会发生在多个阶段。</p>
<p>在第一次接收查询请求的节点叫<strong>查询控制器</strong>（或者也可以叫聚合器）它主要负责创建统一的结果集并且把结果返回给客户端。集群里的任意节点都可以充查询控制器。</p>
<p>在SolrCloud中，查询控制器从ZooKeeper获取集群中所有其他节点的信息。但是，查询控制器不是每次接收查询请求都需要从ZooKeeper哪里获取集群状态，因为实时的去ZK中查性能不好。那么通过什么方法？每个节点都会对ZK的znode /clusterstate.json数据节点建立wathcer，如果ZK中保存的节点状态发生变更会通知watcher。</p>
<p>很容易想到，如果有节点出故障的通知还没通知到订阅的watcher节点，而watcher节点已经发送了请求到这个故障节点上，应该怎么处理呢？</p>
<p>Solr具有基本的容错能力，会把请求重新发送给同一个分片上的其他健康的replicas节点处理。</p>
<h2 id="步骤3：第一阶段——查询阶段"><a href="#步骤3：第一阶段——查询阶段" class="headerlink" title="步骤3：第一阶段——查询阶段"></a>步骤3：第一阶段——查询阶段</h2><p>查询控制器会给每个分片发送一个非分布式查询（distrib=false），以确认匹配分片里的文档。控制器能通过ZooKeeper提供的集群信息来确定哪些节点参与查询。查询控制器使用SolrJ的API在所有分片上并行执行查询。则意味着，分片查询的响应时间瓶颈在最慢的那个分片的查询时间（这也是为什么要把文档平均分配到所有分片的原因）。</p>
<p>在发送给每个分片的查询式只请求id字段和score字段。这样可以避免过早地读取存储字段。假设将页面大小10(rows=10)的查询发送给由10个分片组成的集群。因为每个分片识别10个文档，因此查询控制器就必须对多达100个文档合并和排序，以最终处理成10条结果。所以查询控制器会等到最后一个shard返回10个文档结果。</p>
<h2 id="步骤4：第二阶段——获取字段阶段"><a href="#步骤4：第二阶段——获取字段阶段" class="headerlink" title="步骤4：第二阶段——获取字段阶段"></a>步骤4：第二阶段——获取字段阶段</h2><p>步骤3、一旦确定了最终匹配的文档，查询控制器就会把第二阶段查询发送给节点的子集获取查询请求中需要获取的其他指定字段。</p>
<p>如果查询请求了rows=10，那么在获取字段阶段会请求10个文档。因为在步骤3中就已经知道了每个节点的所需文档。（如果仅仅需要的时文档ID和Score，就不需要获取额外字段的这个阶段了）只有需要返回包含文档的分片，才会接收到第二阶段的查询。例如，被确认的所有文档都来自于shard1，那么Solr将第二步查询只发送给shard1。</p>
<p>如果查询时没有服务器托管分片的话，会发生什么？</p>
<p>在查询阶段，查询控制器会尝试查询脱机的分片。就会导致请求失败，合并阶段无法完成，这是因为Solr默认不会对查询到的不完整结果集返回。可以通过设置<code>shards.tolerant=true</code>作为查询参数进行干预，表示可以接受不完整的结果。</p>
]]></content>
      <categories>
        <category>Solr</category>
      </categories>
      <tags>
        <tag>Solr</tag>
        <tag>Search</tag>
        <tag>SolrCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>【Lucene】-【Search】查询原理一、Query及其各种实现</title>
    <url>/2020/04/13/lucene-search-collector4/</url>
    <content><![CDATA[<h1 id="Query及子类"><a href="#Query及子类" class="headerlink" title="Query及子类"></a>Query及子类</h1><h2 id="Query-类"><a href="#Query-类" class="headerlink" title="Query 类"></a>Query 类</h2><img data-src="/img/in-post/image-20200419112647627.png" alt="image-20200419112647627" style="zoom:67%;" />

<pre><code class="java">  /**
   * Expert: Constructs an appropriate Weight implementation for this query.
   * &lt;p&gt;
   * Only implemented by primitive queries, which re-write to themselves.
   *
   * @param needsScores   True if document scores ({@link Scorer#score}) are needed.
   * @param boost         The boost that is propagated by the parent queries.
   */
  public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {
    throw new UnsupportedOperationException(&quot;Query &quot; + this + &quot; does not implement createWeight&quot;);
  }

  /** Expert: called to re-write queries into primitive queries. For example,
   * a PrefixQuery will be rewritten into a BooleanQuery that consists
   * of TermQuerys.
   */
  public Query rewrite(IndexReader reader) throws IOException {
    return this;
  }
</code></pre>
<p>Query类主要有2个方法createWeight和rewrite方法。看方法名和注释，就知道是干啥的，不详细赘述。</p>
<h2 id="常用Query子类"><a href="#常用Query子类" class="headerlink" title="常用Query子类"></a>常用Query子类</h2><p><img data-src="/img/in-post/image-20200419112527008.png" alt="image-20200419112527008"></p>
<ul>
<li>TermQuery</li>
<li>BooleanQuery</li>
<li>WildcardQuery</li>
<li>PrefixQuery</li>
<li>FuzzyQuery</li>
<li>RegexpQuery</li>
<li>PhraseQuery</li>
<li>TermRangeQuery</li>
<li>ConstantScoreQuery</li>
<li>DisjunctionMaxQuery</li>
<li>PonitRangeQuery</li>
</ul>
<h1 id="TermQuery"><a href="#TermQuery" class="headerlink" title="TermQuery"></a>TermQuery</h1><pre><code class="java">    Query termQuery = new TermQuery(new Term(&quot;content&quot;, &quot;quick&quot;));
    super.search(termQuery, 10);</code></pre>
<p>包含<strong>域名(FieldName)为”content”，域值(FieldValue)中包含”a”的域（Field）</strong>的文档。</p>
<h1 id="BooleanQuery"><a href="#BooleanQuery" class="headerlink" title="BooleanQuery"></a>BooleanQuery</h1><pre><code class="java">  @Test
  public void test() throws IOException {
    BooleanQuery.Builder builder = new BooleanQuery.Builder();
    builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;quick&quot;)), BooleanClause.Occur.SHOULD);
    builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;fox&quot;)), BooleanClause.Occur.SHOULD);
    builder.setMinimumNumberShouldMatch(1);
    super.search(builder.build(), 10);
  }

  public void indexData() throws IOException {
    Document doc;
    // 文档0
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;a quick black fox，quick white fox&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author1&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);
    // 文档1
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;fox quick&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author2&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);
    // 文档2
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;quick red dog&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author3&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);
    // 文档3
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;a really quick red fox&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author3&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);
    indexWriter.commit();
    // 索引阶段结束
  }</code></pre>
<p>BooleanQuery为组合查询，上图给出的最简单的多个TermQuery的组合（允许其他多种不同查询方式的组合），上图描述的是，期望的文档必须至少（根据BooleanClause.Occur.SHOULD）满足两个TermQuery中的一个，如果都满足，打分更高。</p>
<h1 id="WildcardQuery"><a href="#WildcardQuery" class="headerlink" title="WildcardQuery"></a>WildcardQuery</h1><p><strong>通配符查询方式</strong>，支持两种通配符：</p>
<pre><code class="java">  @Test
  public void test2() {
    Query query = new WildcardQuery(new Term(&quot;content&quot;, &quot;q*k&quot;));
    super.search(query, 10);
  }

  @Test
  public void test3() {
    Query query = new WildcardQuery(new Term(&quot;content&quot;, &quot;q\&quot;d&quot;));
    super.search(query, 10);
  }

  @Test
  public void test4() {
    Query query = new WildcardQuery(new Term(&quot;content&quot;, &quot;q\\\&quot;d&quot;));
    super.search(query, 10);
  }
</code></pre>
<p>支持两种通配符，转义符号是对星号、问号进行转义查询的，并不是通配符。</p>
<ul>
<li>*星号：匹配零个或多个字符。</li>
<li>？问号：匹配一个字符。</li>
<li>\转义：用来对星号跟问号进行转移，表示这两个作为字符使用，而不是通配符。</li>
</ul>
<h1 id="PrefixQuery"><a href="#PrefixQuery" class="headerlink" title="PrefixQuery"></a>PrefixQuery</h1><p>表示查询前缀的Query。如下查询前缀是”go”的域的文档。</p>
<pre><code class="java">  @Test
  public void test() throws IOException {
    Query query = new PrefixQuery(new Term(&quot;content&quot;, &quot;qo&quot;));
    super.search(query, 10);
  }

  public void indexData() throws IOException {

    System.out.println(&quot;index mine test case data&quot;);

    Document doc;

    // 文档0
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;a quick black fox，quick white fox qck quisk&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author1&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);
    // 文档1
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;fox qoik&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author2&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);


    // 文档2
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;qouick red dog&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author3&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);

    // 文档3
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;a really quick red fox and dog, qok fox , qek fox&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author3&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);



    indexWriter.commit();
    indexWriter.close();
    // 索引阶段结束
  }</code></pre>
<h1 id="FuzzyQuery"><a href="#FuzzyQuery" class="headerlink" title="FuzzyQuery"></a>FuzzyQuery</h1><p>模糊查询，使用编辑距离来实现模糊匹配，如：</p>
<p><img data-src="/img/in-post/image-20200420231427751.png" alt="image-20200420231427751"></p>
<p><strong>编辑距离是2，必须至少2个相同的前缀字符。</strong>会匹配0，1文档。</p>
<p>索引代码如下：</p>
<pre><code class="java">    Document doc;

    // 文档0
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;good job&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author1&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);

    // 文档1
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;my god&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author2&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);

    // 文档2
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;gd&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author3&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);

    // 文档3
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;g*d&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author3&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);

    indexWriter.commit();
    indexWriter.close();</code></pre>
<p>如上图，各个参数介绍如下：</p>
<ul>
<li>maxEdits：编辑距离的最大编辑值。<strong>默认值2</strong></li>
<li>prefixLength：模糊匹配到term的至少跟上面Query的域值”god”有两个相同的前缀值，即term的前缀要以”go”开头。<strong>默认为0。</strong></li>
<li>maxExpansions：在maxEidts跟prefixLength条件下，可能匹配到很多个term，但是只允许处理最多20个term。<strong>默认为50。</strong></li>
<li>transpositions：该值暂不介绍，需要了解<a href="https://www.amazingkoala.com.cn/Lucene/gongjulei/2019/0417/51.html" target="_blank" rel="noopener">确定性有穷自动机</a>的知识。<strong>默认为true。</strong></li>
</ul>
<p>再看例子：</p>
<pre><code>@Test
public void test2() {
  Query query = new FuzzyQuery(new Term(&quot;content&quot;, &quot;god&quot;),2);
  super.search(query, 10);
}</code></pre><p> 编辑距离为2，其他都使用默认。匹配文档0~3。</p>
<h1 id="RegexpQuery"><a href="#RegexpQuery" class="headerlink" title="RegexpQuery"></a>RegexpQuery</h1><p>查询方式为正则表达式查询，使用正则表达式来匹配域的域值：</p>
<pre><code class="java">  @Test
  public void test() {
    Query query = new RegexpQuery(new Term(&quot;content&quot;, &quot;q[o]*k&quot;));
    super.search(query, 10);
  }</code></pre>
<p>如上，域值表示 以 “q”开头，以”d”结尾，中间包含零个或多个”o”的域（Field）的文档。如下索引，会匹配文档1和3。</p>
<pre><code class="java">    // 文档0
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;quisk&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);
    // 文档1
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;qooook&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);
    // 文档2
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;qouick&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);
    // 文档3
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;qok fox&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);
</code></pre>
<h1 id="PhraseQuery"><a href="#PhraseQuery" class="headerlink" title="PhraseQuery"></a>PhraseQuery</h1><p>参数position表示Phrase中输入的两个term的位置相对关系</p>
<p>setSlop中的slop设置表示允许编辑距离，用来调整两个term的相对位置（必须满足）。</p>
<p>有关于PhraseQuery实现原理见<a href="https://zhoulei.site/2020/03/29/lucene-search-phrase/" target="_blank" rel="noopener">一文读懂PhraseQuery</a></p>
<p>索引代码：</p>
<pre><code class="java">    // 文档0
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;a quick black fox&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author1&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);

    // 文档1
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;a really quick fox&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author2&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);

    // 文档2
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;quick good good fox&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author3&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);


    // 文档3
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;quick good good good fox&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author3&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);


    // 文档4
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;fox quick&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author3&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);
</code></pre>
<p>多个例子：</p>
<pre><code class="java">  @Test
  //0,1，2
  public void test() {
    PhraseQuery.Builder builder = new PhraseQuery.Builder();
    builder.add(new Term(&quot;content&quot;, &quot;quick&quot;), 1);
    builder.add(new Term(&quot;content&quot;, &quot;fox&quot;), 3);
    builder.setSlop(1);
    super.search(builder.build(), 10);
  }
</code></pre>
<p>相对位置为(3-1)=2，同时允许编辑最大距离1，可以命中0，1，2。</p>
<p>命中0，是因为相对位置就为2。</p>
<p>命中1，2是因为quick和fox的相对距离是1和3，因为允许的编辑距离是1，所以文档1，2也可以匹配。</p>
<p>同理：</p>
<p>如果slop=0，可以命中文档0。</p>
<p>如果slop=1，可以命中文档0、1、 2、 3。</p>
<p>如果slop=3，可以命中文档0、1、2、3、4。命中4、的原因是因为虽然fox 出现在了 quick前面，但是因为两者相对位置为-1，3-（1+3）=-1。</p>
<h1 id="TermRangeQuery"><a href="#TermRangeQuery" class="headerlink" title="TermRangeQuery"></a>TermRangeQuery</h1><p>表示term的范围查询：</p>
<pre><code class="java">    Document doc;
    // 文档0
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;a&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;name&quot;, &quot;author1&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);
    // 文档1
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;bcd&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;name&quot;, &quot;author2&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);
    // 文档2
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;ga&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;name&quot;, &quot;author3&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);
    // 文档3
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;gc&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;name&quot;, &quot;author3&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);

    // 文档4
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;gch&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;name&quot;, &quot;author3&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);

    // 文档5
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;gchb&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;name&quot;, &quot;author3&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);</code></pre>
<p>查询代码：</p>
<pre><code class="java">  @Test
  //1,2,3
  //通过确定型有穷自动机的机制来找到查询条件范围类的所有term
  public void test() {
    TermRangeQuery query = new TermRangeQuery(&quot;content&quot;, new BytesRef(&quot;bc&quot;), new BytesRef(&quot;gc&quot;), true,true);
    super.search(query, 10);
  }</code></pre>
<p>匹配文档1、2、3。</p>
<p>基于确定性有穷自动机实现，具体可以参考<a href="https://www.amazingkoala.com.cn/Lucene/gongjulei/2019/0417/51.html" target="_blank" rel="noopener">Automaton</a>,通过确定性有穷自动机的机制来找到查询条件范围内的所有term。</p>
<h1 id="PointRangeQuery"><a href="#PointRangeQuery" class="headerlink" title="PointRangeQuery"></a>PointRangeQuery</h1><p>数值类型的范围查询（多维度查询）</p>
<pre><code class="java">    // 文档0
    doc = new Document();
    doc.add(new IntPoint(&quot;coordinate&quot;, 2,8));
    indexWriter.addDocument(doc);
    // 文档1
    doc = new Document();
    doc.add(new IntPoint(&quot;coordinate&quot;, 4,6));
    indexWriter.addDocument(doc);
    // 文档2
    doc = new Document();
    doc.add(new IntPoint(&quot;coordinate&quot;, 6,7));
    indexWriter.addDocument(doc);
    // 文档3
    doc = new Document();
    doc.add(new IntPoint(&quot;coordinate&quot;, 4,3));
    indexWriter.addDocument(doc);

    indexWriter.commit();
    indexWriter.close();</code></pre>
<pre><code class="java">  @Test
  public void test() {
    int[] lowValue = {1,5};
    int[] upValue = {4,7};
    Query query = IntPoint.newRangeQuery(&quot;coordinate&quot;,lowValue,upValue);
    super.search(query, 10);
  }
</code></pre>
<p>匹配文档1。</p>
<img data-src="/img/in-post/image-20200423003100442.png" alt="image-20200423003100442" style="zoom:50%;" />

<p>可以看到红框描述的是lowValue和upValue组成的矩形，所以文档1会匹配。</p>
<p>另外关于数值类型的索引信息是如何在索引阶段存储的，需要熟悉BKD-TREE和索引文件dim&amp;&amp;dii。</p>
<h1 id="DisjunctionMaxQuery"><a href="#DisjunctionMaxQuery" class="headerlink" title="DisjunctionMaxQuery"></a>DisjunctionMaxQuery</h1><p>多Query联合查询</p>
<pre><code class="java">    // 文档0
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;a quick black fox&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author1 author2&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);

    // 文档1
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;a really quick red fox&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author2 author3 author4&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);

    // 文档2
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;quick fox&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author2 author3&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);

    // 文档3
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;fox quick&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author1 author2 author3&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);

    // 文档4
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;fox quick&quot;, Field.Store.YES));
    doc.add(new TextField(&quot;author&quot;, &quot;author1 author2&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);</code></pre>
<pre><code class="java">    PhraseQuery.Builder builder = new PhraseQuery.Builder();
    builder.add(new Term(&quot;content&quot;, &quot;quick&quot;), 1);
    builder.add(new Term(&quot;content&quot;, &quot;fox&quot;), 3);
    builder.setSlop(0);

    Query termQuery = new TermQuery(new Term(&quot;author&quot;, &quot;author2&quot;));
    Query termQuery2 = new TermQuery(new Term(&quot;author&quot;, &quot;author3&quot;));
    BooleanQuery.Builder booleanQueryBuidler = new BooleanQuery.Builder();
    booleanQueryBuidler.add(termQuery, BooleanClause.Occur.MUST);
    booleanQueryBuidler.add(termQuery2, BooleanClause.Occur.MUST);


    List&lt;Query&gt; queryList = new ArrayList&lt;&gt;();
    queryList.add(builder.build());
    queryList.add(booleanQueryBuidler.build());
    Query query = new DisjunctionMaxQuery(queryList, 1);
    super.search(query,10);</code></pre>
<p>如上示例，联合PhraseQuery和BooleanQuery查询，查询的结果为DisjunctionMaxQuery联合的Query的结果合集。</p>
<p>可以匹配到文档1、2、3、0。文档4匹配不到，是因为它既通过PhraseQuery、又通过BooleanQuery匹配不到。</p>
<p>两者查询结果的打分如何组合进行最终打分排序，见DisjunctionMaxScorer中按照如下公式组合:</p>
<pre><code class="java">  protected float score(DisiWrapper topList) throws IOException {
    float scoreSum = 0;
    float scoreMax = Float.NEGATIVE_INFINITY;
    for (DisiWrapper w = topList; w != null; w = w.next) {
      final float subScore = w.scorer.score();
      scoreSum += subScore;
      if (subScore &gt; scoreMax) {
        scoreMax = subScore;
      }
    }
    return scoreMax + (scoreSum - scoreMax) * tieBreakerMultiplier; 
  }
}</code></pre>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>至此Query的所有Query使用基本介绍完了，关于使用自动机实现的Query，后续再总结自动机时介绍原理。</p>
]]></content>
      <categories>
        <category>Lucene</category>
      </categories>
      <tags>
        <tag>Search</tag>
        <tag>Lucene</tag>
        <tag>Query</tag>
      </tags>
  </entry>
  <entry>
    <title>【Lucene】-【Search】Collector（四）TopDocsCollector及其子类TopFieldCollector</title>
    <url>/2020/04/13/lucene-search-yuanli1/</url>
    <content><![CDATA[<p><img data-src="/img/in-post/Collector-5579809.png" alt="Collector"></p>
<p>在上一篇Collector(二)的文章中，介绍了<code>TopDocsCollector</code>的其中一个子类<code>TopScoreDocCollector</code>收集器，以及<code>TopScoreDocCollector</code>的两个子类<code>SimpleTopScoreDocCollector</code>、<code>PagingTopScoreDocCollector</code>，它们的排序规则是“先打分、后文档号”。</p>
<p>这次，介绍<code>TopDocsCollector</code>的另外一个子类<code>TopFieldCollector</code>，它的排序规则是“先域比较（FieldComparator），后文档号”。</p>
<ul>
<li>先域比较（FieldComparator）：根据文档（Document）中的排序域（SortField）的阈值进行排序。</li>
<li>后文档号：由于文档号是唯一的，当无法通过域比较来获得顺序关系时，可以再通过文档号进行排序，文档号越小，排名越靠前。</li>
</ul>
<p>下面通过一个例子先介绍怎么使用TopFieldCollector，然后再来介绍排序的原理。</p>
<p>在搜索阶段如果使用了域排序，那么Lucene默认使用的是<code>TopFieldCollector</code>。</p>
<h1 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h1><h2 id="索引代码"><a href="#索引代码" class="headerlink" title="索引代码"></a>索引代码</h2><pre><code class="java">    //0
    Document doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;a b&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);

    //1
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;b&quot;, Field.Store.YES));
    doc.add(new NumericDocValuesField(&quot;sortByNumber&quot;,-1));
    indexWriter.addDocument(doc);

    //2
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;c b&quot;, Field.Store.YES));
    doc.add(new NumericDocValuesField(&quot;sortByNumber&quot;,4));
    indexWriter.addDocument(doc);

    //3
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;a c&quot;, Field.Store.YES));
    doc.add(new NumericDocValuesField(&quot;sortByNumber&quot;,1));
    indexWriter.addDocument(doc);

    //4
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;h c e&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);

    //5
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;a c&quot;, Field.Store.YES));
    doc.add(new NumericDocValuesField(&quot;sortByNumber&quot;,3));
    indexWriter.addDocument(doc);

    indexWriter.commit();
    indexWriter.close();
</code></pre>
<h2 id="查询代码"><a href="#查询代码" class="headerlink" title="查询代码"></a>查询代码</h2><pre><code class="java">  public void test() {

    BooleanQuery.Builder builder = new BooleanQuery.Builder();
    builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;a&quot;)), BooleanClause.Occur.SHOULD);
    builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;b&quot;)), BooleanClause.Occur.SHOULD);
    builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;c&quot;)), BooleanClause.Occur.SHOULD);
    builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;e&quot;)), BooleanClause.Occur.SHOULD);
    builder.setMinimumNumberShouldMatch(2);

    SortField sortField = new SortedNumericSortField(&quot;sortByNumber&quot;, SortField.Type.LONG);
    Sort sort = new Sort(sortField);

    searchBySort(builder.build(), 10, sort);
    //search(builder.build(), 10);
  }</code></pre>
<p>Sort可以在查询时指定(IndexSearcher)，也可以在在Index阶段设置如：</p>
<pre><code class="java">    IndexWriterConfig iwc = new IndexWriterConfig(new MockAnalyzer(random()));
    Sort indexSort = new Sort(new SortedNumericSortField(&quot;foo&quot;, SortField.Type.LONG));
    iwc.setIndexSort(indexSort);</code></pre>
<ul>
<li><p>SortedNumericSortField：根据文档（document)中NumericDocValues域的阈值进行排序，如果文档没有这个域，那么阈值视为0。</p>
</li>
<li><p>如上面的索引代码，文档1和文档4没有这个域，那么就按照文档号排序。查询排序代码排序结果为：</p>
<img data-src="/img/in-post/image-20200406230101284.png" alt="image-20200406230101284" style="zoom: 50%;" />



</li>
</ul>
<h1 id="排序类型选择"><a href="#排序类型选择" class="headerlink" title="排序类型选择"></a>排序类型选择</h1><p><strong>上面除了可以使用<code>NumericDocValue</code>类型索引字段然后使用SortedNumericSortField进行Numeric类型排序检索，还可以使用<code>SortedSetSortField</code>String类型排序字段。</strong></p>
<pre><code class="java">    //4
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;h c e&quot;, Field.Store.YES));
    indexWriter.addDocument(doc);

    //5
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;a c&quot;, Field.Store.YES));
    doc.add(new NumericDocValuesField(&quot;sortByNumber&quot;,3));
    indexWriter.addDocument(doc);


    //6
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;a c&quot;, Field.Store.YES));
    doc.add(new SortedSetDocValuesField(&quot;sortByString&quot;,new BytesRef(&quot;a&quot;)));//MIN
    doc.add(new SortedSetDocValuesField(&quot;sortByString&quot;,new BytesRef(&quot;h&quot;)));//MIDDLE_MAX
    doc.add(new SortedSetDocValuesField(&quot;sortByString&quot;,new BytesRef(&quot;f&quot;)));//MIDDLE_MIN
    doc.add(new SortedSetDocValuesField(&quot;sortByString&quot;,new BytesRef(&quot;y&quot;)));//MAX
    indexWriter.addDocument(doc);

    //7
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;a c&quot;, Field.Store.YES));
    doc.add(new SortedSetDocValuesField(&quot;sortByString&quot;,new BytesRef(&quot;c&quot;)));
    doc.add(new SortedSetDocValuesField(&quot;sortByString&quot;,new BytesRef(&quot;i&quot;)));
    doc.add(new SortedSetDocValuesField(&quot;sortByString&quot;,new BytesRef(&quot;e&quot;)));
    doc.add(new SortedSetDocValuesField(&quot;sortByString&quot;,new BytesRef(&quot;z&quot;)));
    indexWriter.addDocument(doc);

    //8
    doc = new Document();
    doc.add(new TextField(&quot;content&quot;, &quot;a c&quot;, Field.Store.YES));
    doc.add(new SortedSetDocValuesField(&quot;sortByString&quot;,new BytesRef(&quot;b&quot;)));
    doc.add(new SortedSetDocValuesField(&quot;sortByString&quot;,new BytesRef(&quot;j&quot;)));
    doc.add(new SortedSetDocValuesField(&quot;sortByString&quot;,new BytesRef(&quot;d&quot;)));
    doc.add(new SortedSetDocValuesField(&quot;sortByString&quot;,new BytesRef(&quot;x&quot;)));</code></pre>
<p>然后使用<strong>查询代码</strong>为：</p>
<pre><code class="java">    BooleanQuery.Builder builder = new BooleanQuery.Builder();
    builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;a&quot;)), BooleanClause.Occur.SHOULD);
    builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;b&quot;)), BooleanClause.Occur.SHOULD);
    builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;c&quot;)), BooleanClause.Occur.SHOULD);
    builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;e&quot;)), BooleanClause.Occur.SHOULD);
    builder.setMinimumNumberShouldMatch(2);

    SortField sortField = new SortedSetSortField(&quot;sortByString&quot;, false , SortedSetSelector.Type.MIN);
    Sort sort = new Sort(sortField);

    searchBySort(builder.build(), 10, sort);</code></pre>
<p>默认从小到大输出，结果为：</p>
<p><img data-src="/img/in-post/image-20200406232808460.png" alt="image-20200406232808460"></p>
<h2 id="SortedSetSelector-Type"><a href="#SortedSetSelector-Type" class="headerlink" title="SortedSetSelector.Type"></a>SortedSetSelector.Type</h2><p>reverse设置false，按照从小到大排序，反之true是从大到小排序。</p>
<p>除了上面使用的<code>SortedSetSelector.Type.MIN</code>，还有<img data-src="/img/in-post/image-20200406231935935.png" alt="image-20200406231935935"></p>
<p><code>MIDDLE_MAX</code></p>
<p><code>MIDDLE_MIN</code></p>
<p><code>MAX</code></p>
<p>下面介绍下这四种类型</p>
<ul>
<li><p><code>MIN</code>：选择域值最小的进行排序，如上面文档6、7、8 会使用a c b作为排序条件，即结果：</p>
<p>4-&gt;5-&gt;6-&gt;8-&gt;7（4、5该域为null，默认按照文档号排序）</p>
</li>
<li><p><code>MAX</code>：选择域值最大的进行排序，如上面的文档6、7、8会使用y z x作为排序条件，即结果：</p>
<p>4-&gt;5-&gt;8-&gt;6-&gt;7</p>
</li>
<li><p><code>MIDDLE_MIN</code>：选择中间域值，如果域值个数为偶数个，那么中间域值有两个，则取<strong>较小值</strong>。如上面的6、7、8 会使用f e d作为排序条件。结果为：</p>
<p>4-&gt;5-&gt;8-&gt;7-&gt;6</p>
</li>
<li><p><code>MIDLE_MAX</code>：参考MIDDLE_MIN就是取中间两个的较大值作为排序条件了。具体不赘述了。</p>
</li>
</ul>
<p>刚刚讲了<strong><code>SortedNumericSortField</code></strong>和<strong><code>SortedSetSortField</code></strong>都可以在索引阶段设置多个具有相同域名的不通值，用法跟<strong><code>SortedSetSortField</code></strong>是一样的，就不赘述了。</p>
<p>接下来看下根据过滤(filtering)规则，接着介绍TopFieldCollector的两个子类：</p>
<ul>
<li><p>SimpleFieldCollector：无过滤规则</p>
</li>
<li><p>PagingFieldCollector：有过滤规则，具体内容在下文展开</p>
</li>
</ul>
<h1 id="SimpleFieldCollector"><a href="#SimpleFieldCollector" class="headerlink" title="SimpleFieldCollector"></a>SimpleFieldCollector</h1><p>它的collect的方法流程图如下：</p>
<img data-src="/img/in-post/image-20200406233905182.png" alt="image-20200406233905182" style="zoom:45%;" />





<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>下一篇Collector（四）继续</p>
]]></content>
      <categories>
        <category>Lucene</category>
      </categories>
      <tags>
        <tag>Search</tag>
        <tag>Lucene</tag>
        <tag>Collector</tag>
      </tags>
  </entry>
  <entry>
    <title>【Lucene】-【Search】Collector（三）TopDocsCollector及其子类TopFieldCollector</title>
    <url>/2020/04/08/lucene-search-collector3/</url>
    <content><![CDATA[<p><img data-src="/img/in-post/Collector-5579809.png" alt="Collector"></p>
<p>继上一篇介绍<code>TopDocsCollector</code>子类TopFieldCollector的子类SimpleFieldCollector，下面继续总结。</p>
<p>源码为：</p>
<pre><code>org.apache.lucene.search.TopFieldCollector</code></pre><h1 id="TopDocsCollector"><a href="#TopDocsCollector" class="headerlink" title="TopDocsCollector"></a>TopDocsCollector</h1><h2 id="TopFieldCollector"><a href="#TopFieldCollector" class="headerlink" title="TopFieldCollector"></a>TopFieldCollector</h2><p>根据过滤(filtering)规则，TopFieldCollector派生两个子类：</p>
<ul>
<li>SimpleFieldCollector：无过滤规则</li>
<li>PagingFieldCollector：有过滤规则</li>
</ul>
<p>TopFieldCollector中几个变量：</p>
<ul>
<li>trackMaxScore：该值是TopFieldCollector类的构造参数，是否需要记录所有满足查询条件的文档集合中最高的文档打分值，用maxScore记录该最大值。</li>
<li>trackDocScores：该值是TopFieldCollector类的构造参数，是否需要记录所有满足查询条件的文档的打分值。</li>
<li>totalHits：该值描述了Collector处理的满足搜索条件的文档数量，没当进入下图中SimpleFieldcCollector收集文档的流程就会增加+1。</li>
</ul>
<p>如果业务中不需要用到文档的打分值或者maxScore，建议另这两个参数为false，因为找出maxScore或者文档的打分值需要遍历所有满足条件的文档，无法提前结束Collector工作（canEalyTerminate），在满足查询提交的文档数量较大的情况下，提前结束Collector的收集工作能显著提供查询性能。canEalryTerminate会在下文中介绍。</p>
<h1 id="子类-SimpleFieldCollector"><a href="#子类-SimpleFieldCollector" class="headerlink" title="子类 SimpleFieldCollector"></a>子类 SimpleFieldCollector</h1><p>它的collect的方法流程图如下：</p>
<img data-src="/img/in-post/image-20200406233905182.png" alt="image-20200406233905182" style="zoom:45%;" />



<h2 id="记录文档打分值最高的文档"><a href="#记录文档打分值最高的文档" class="headerlink" title="记录文档打分值最高的文档"></a>记录文档打分值最高的文档</h2><pre><code class="java">          float score = Float.NaN;
          if (trackMaxScore) {
            score = scorer.score();
            if (score &gt; maxScore) {
              maxScore = score;
            }
          }</code></pre>
<img data-src="/img/in-post/3-7191040.png" alt="img" style="zoom:50%;" />

<p>如果参数trackMaxScore为true，那么Collector每处理一篇文档，就要记录该文档的打分值score，如果score大于当前maxScore的值，则更新maxScore的值。</p>
<h2 id="添加文档信息"><a href="#添加文档信息" class="headerlink" title="添加文档信息"></a>添加文档信息</h2><pre><code class="java">          } else {
            // Startup transient: queue hasn&#39;t gathered numHits yet
            final int slot = totalHits - 1;

            if (trackDocScores &amp;&amp; !trackMaxScore) {
              score = scorer.score();
            }

            // Copy hit into queue
            comparator.copy(slot, doc);
            add(slot, doc, score);
            if (queueFull) {
              comparator.setBottom(bottom.slot);
            }
          }</code></pre>
<img data-src="/img/in-post/4-7191031.png" alt="img" style="zoom:50%;" />

<p>使用优先级队列PriorityQueue来存放满足搜索条件的文档信息（文档信息至少包含了文档打分score以及文档docid），分数最低的文档信息位于堆顶，堆的大小默认为段中的文档总数（也可以指定堆的大小，即用户期望返回的TopN）。</p>
<p>如果堆没有满，将文档号交给FieldComparator，FieldComparator的概念可以参考<a href="https://www.amazingkoala.com.cn/Lucene/Search/2019/0415/50.html" target="_blank" rel="noopener">FieldComparator</a>，它用来描述文档间的排序关系（从代码层面来说，通过FieldComparator实现了优先级队列PriorityQueue的<code>lessThan()</code>方法，优先级队列实现为<code>FieldValueHitQueue</code> 根据比较字段的数量<code>FieldValueHitQueue</code> 有两个匿名实现类<code>MultiComparatorsFieldValueHitQueue</code>和<code>OneComparatorFieldValueHitQueue</code>）接着添加信息到堆中。</p>
<h2 id="设置bottom值"><a href="#设置bottom值" class="headerlink" title="设置bottom值"></a>设置bottom值</h2><pre><code class="java">            if (queueFull) {
              comparator.setBottom(bottom.slot);
            }</code></pre>
<img data-src="/img/in-post/5-7193863.png" alt="img" style="zoom:50%;" />

<p>在<code>添加文档信息到堆中</code>流程后，如果此时堆正好满了，需要设置bottom的值，即从我们已经处理的文档中找出最差的文档进行比较即可。</p>
<h2 id="仅统计满足查询条件的文档个数"><a href="#仅统计满足查询条件的文档个数" class="headerlink" title="仅统计满足查询条件的文档个数"></a>仅统计满足查询条件的文档个数</h2><pre><code class="java">         if (queueFull) {
            if (collectedAllCompetitiveHits) {
              return;
            }</code></pre>
<img data-src="/img/in-post/image-20200418171133754.png" alt="image-20200418171133754" style="zoom: 33%;" />

<p>在堆满的情况下，并且collectedAllCompetitiveHits为true，直接可以退出，尽快直接退出了，还是统计了totalHits的值，所以从collectedAllCompetitiveHits的命中方式也可以看出只是统计了totalHits。</p>
<p>满足如下条件的情况下，collectedAllCompetitiveHits会为true：</p>
<p><code>canEarlyStopComparing = true &amp; canEarlyTerminate = false</code></p>
<ul>
<li><p><code>canEarlyStopComparing</code>：该值描述了是否可以提前结束域比较，当索引期间通过<code>IndexWriterConfig.setIndexSort(Sort sort)</code>设置的排序规则与搜索期间提供的排序规则一致时，Collector收到的文档集合已经是有序的，<code>canEarlyStopComparing</code>设置true的依据方法：</p>
<pre><code class="java">  static boolean canEarlyTerminate(Sort searchSort, Sort indexSort) {
    return canEarlyTerminateOnDocId(searchSort) ||
           canEarlyTerminateOnPrefix(searchSort, indexSort);
  }

  private static boolean canEarlyTerminateOnDocId(Sort searchSort) {
    final SortField[] fields1 = searchSort.getSort();
    return SortField.FIELD_DOC.equals(fields1[0]);
  }

  private static boolean canEarlyTerminateOnPrefix(Sort searchSort, Sort indexSort) {
    if (indexSort != null) {
      final SortField[] fields1 = searchSort.getSort();
      final SortField[] fields2 = indexSort.getSort();
      // early termination is possible if fields1 is a prefix of fields2
      if (fields1.length &gt; fields2.length) {
        return false;
      }
      return Arrays.asList(fields1).equals(Arrays.asList(fields2).subList(0, fields1.length));
    } else {
      return false;
    }
  }</code></pre>
<p>在堆已满的情况下，后面的处理文档号就没有比较的必要性了。</p>
<p>每次获取一个段的信息时设置<code>canEalryStopComparing</code>，即调用getLeafCollector(LeafReaderContext context)时候设置。</p>
</li>
</ul>
<ul>
<li><p><code>caneEarlyTerminate</code>：该值描述了是否可以提前结束Collector的收集工作，canEarlyTerminate设置为true需要满足下面条件：</p>
<pre><code class="java">boolean canEarlyTerminate = trackTotalHits == false &amp;&amp;
          trackMaxScore == false &amp;&amp;
          canEarlyStopComparing;
</code></pre>
<p>如果满足上面的条件，Lucene会通过抛出异常的方式结束Collector，该异常会被IndexSearcher捕获。这样的好处在于能提高性能。比如说某一次查询，需要返回TOP5，但是满足搜索条件的文档数量有1000000W条，那么在Collector中当处理了5篇文档后（文档在段中有序），就可以直接返回结果了。</p>
<p>如果条件不满足，即canEarlyTerminate值为false，那么尽管我们已经收集了TOP5的数据（查询结果不会再变化），但是需要继续遍历处理剩余的999999篇文档，因为我们需要记录totalHits（如果trackTotalHits为true）或者需要获得打分值最大的文档（trackMaxScore为true），所以此时collectedAllCompetitiveHits为true，继续处理下一篇文档。</p>
</li>
</ul>
<h2 id="无法提前结束域比较"><a href="#无法提前结束域比较" class="headerlink" title="无法提前结束域比较"></a>无法提前结束域比较</h2><img data-src="/img/in-post/image-20200418201402142.png" alt="image-20200418201402142" style="zoom:50%;" />

<img data-src="/img/in-post/image-20200418202459263.png" alt="image-20200418202459263" style="zoom:50%;" />

<p>由于通过域比较后，当前文档比bottom还要差，那么先通过canEarlyStopingComparing判断出能不能提前结束比较，如果canEarlyStopComparing为false，则退出并处理下一篇文档。</p>
<p>canEarlyStopComparing为false说明段中的文档没有按照搜索期间的排序规则进行排序，所以当前已经收集的TopN未必是最终的搜索结果，所以退出处理下一篇文档。</p>
<h2 id="设置collectedAllCompetitiveHits"><a href="#设置collectedAllCompetitiveHits" class="headerlink" title="设置collectedAllCompetitiveHits"></a>设置collectedAllCompetitiveHits</h2><img data-src="/img/in-post/image-20200418211251733.png" alt="image-20200418211251733" style="zoom:50%;" />



<img data-src="/img/in-post/image-20200418211332115.png" alt="image-20200418211332115" style="zoom:50%;" />

<p>可以提前结束域比较，即canEalyStopComparing为true，并且不可以提前结束Collector的收集工作，即canEarlyTerminate为false，那么同时满足这两个条件就可以设置collectedAllCompetitiveHits为true了。使得处理下一篇文档时就可以走<code>仅统计满足查询条件的文档个数</code>的流程。</p>
<h2 id="提前结束Collector的收集工作"><a href="#提前结束Collector的收集工作" class="headerlink" title="提前结束Collector的收集工作"></a>提前结束Collector的收集工作</h2><img data-src="/img/in-post/image-20200419005405886.png" alt="image-20200419005405886" style="zoom:50%;" />

<p><img data-src="/img/in-post/10-20200419005634534.png" alt="img"></p>
<p>可以提前结束Collector的收集工作，那么闲估算剩余满足查询条件的文档数量，通过线性估算出文档数量。估算方法见代码，</p>
<p>接着设置一个earlyTerminated的值为true，用户在得到查询结果后可以通过该值来了解Collector提前结束收集工作这个事件。</p>
<p>抛出CollectionTerminatedException异常的方式来实现。</p>
<h1 id="子类-PagingFieldCollector"><a href="#子类-PagingFieldCollector" class="headerlink" title="子类 PagingFieldCollector"></a>子类 PagingFieldCollector</h1><p>PagingFieldCollector同PaingTopScoreDocCollector一样，相对于SimpleFieldCollector实现了分页功能，collect(int doc)的流程图是相似的，并用红圈标记了不同处。</p>
<p>PaingFieldCollector的collect(int doc)方法流程图：</p>
<h1 id=""><a href="#" class="headerlink" title=""></a><img data-src="/img/in-post/11-7229567.png" alt="img"></h1><p>相对于SimpleFieldCollector来说对了<code>是否已经被收集</code></p>
<h2 id="是否已经被收集"><a href="#是否已经被收集" class="headerlink" title="是否已经被收集"></a>是否已经被收集</h2><p><code>是否已经被收集了</code>描述的是该文档是否已经在前面的索引中被收集了，判断条件如下：</p>
<pre><code class="java">          final int topCmp = reverseMul * comparator.compareTop(doc);
          if (topCmp &gt; 0 || (topCmp == 0 &amp;&amp; doc &lt;= afterDoc)) {
            // Already collected on a previous page
            return;
          }</code></pre>
<ul>
<li>topCmp： 该值描述当前文档与FieldCollector的top值做比较后的值，top值描述的是之前所有分页收集结果中最差的文档，在初始化PagingFieldCollector对象时需要用户提供该值(通过上一次的查询结果就能获得)，并设置top的值。如果topComp&gt;0，说明当前文档比最差的好(competitive)，必定该偏文档已经在前面某次某分页收集中被收集过了。</li>
<li>afterDoc：该值描述之前所有分页搜索结果中最差的文档的文档号，如果域比较无法区分得出排序结果，由于文档号是唯一的，所以再根据文档号进行比较，文档号的大的比文档号小的差，所以再topComp==0的情况下，如果当前文档号小于等于afterDoc，必定该篇文档已经在前面某次分页中被收集过了。</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>至此【search】系列常见的Collector已经总结完了，下一篇开始介绍查询原理相关内容。</p>
]]></content>
      <categories>
        <category>Lucene</category>
      </categories>
      <tags>
        <tag>Search</tag>
        <tag>Lucene</tag>
        <tag>Collector</tag>
      </tags>
  </entry>
  <entry>
    <title>【Lucene】-【Search】SHOULD原理</title>
    <url>/2020/04/02/lucene-search-should/</url>
    <content><![CDATA[<p>这篇文章主要介绍如何对满足搜索条件的文档进行合并（筛选）。源码实现为：</p>
<p><strong>BooleanScorer</strong></p>
<h1 id="索引代码"><a href="#索引代码" class="headerlink" title="索引代码"></a>索引代码</h1><pre><code class="java">//0
Document doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;a&quot;, Field.Store.YES));
indexWriter.addDocument(doc);
//1
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;b&quot;, Field.Store.YES));
indexWriter.addDocument(doc);
//2
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;c&quot;, Field.Store.YES));
indexWriter.addDocument(doc);
//3
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;a c e&quot;, Field.Store.YES));
indexWriter.addDocument(doc);
//4
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;h&quot;, Field.Store.YES));
indexWriter.addDocument(doc);
//5
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;c e&quot;, Field.Store.YES));
indexWriter.addDocument(doc);
//6
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;c a&quot;, Field.Store.YES));
indexWriter.addDocument(doc);
//7
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;f&quot;, Field.Store.YES));
indexWriter.addDocument(doc);
//8
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;b c d e c e&quot;, Field.Store.YES));
indexWriter.addDocument(doc);
//9
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;a c e a b c&quot;, Field.Store.YES));
indexWriter.addDocument(doc);</code></pre>
<h1 id="查询代码"><a href="#查询代码" class="headerlink" title="查询代码"></a>查询代码</h1><p>表示满足查询条件的文档<strong>必须</strong>至少包含“a” “b” “c” “e” 四个关键字。</p>
<pre><code class="java">BooleanQuery.Builder builder = new BooleanQuery.Builder();
builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;a&quot;)), BooleanClause.Occur.SHOULD);
builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;b&quot;)), BooleanClause.Occur.SHOULD);
builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;c&quot;)), BooleanClause.Occur.SHOULD);
builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;e&quot;)), BooleanClause.Occur.SHOULD);
builder.setMinimumNumberShouldMatch(2);</code></pre>
<h1 id="文档号合并"><a href="#文档号合并" class="headerlink" title="文档号合并"></a>文档号合并</h1><p>不详细介绍怎么根据term找到文档号的过程（简单来说就是取倒排表，具体是怎么取出term对应</p>
<p>的倒排表的 在其他文章中介绍，最重要的一点是我们已经把term与文档的映射全部存起来了）。</p>
<p>本文只介绍合并（筛选）文档号的过程。</p>
<p>首先给出一个Bucket[]数组，Bucket[]数组下标是文档号，数组元素为文档号出现的频率。</p>
<pre><code class="java">/**
 * {@link BulkScorer} that is used for pure disjunctions and disjunctions
 * that have low values of {@link BooleanQuery.Builder#setMinimumNumberShouldMatch(int)}
 * and dense clauses. This scorer scores documents by batches of 2048 docs.
 */
final class BooleanScorer extends BulkScorer {
    static class Bucket {
      double score;
      int freq;
    }
    final Bucket[] buckets = new Bucket[SIZE];
}   </code></pre>
<p>然后分别统计包含”a” “b” “c” “d” 的文档数，将文档出现的次数写入到Bucket[]数组。</p>
<h2 id="处理包含a的文档"><a href="#处理包含a的文档" class="headerlink" title="处理包含a的文档"></a>处理包含a的文档</h2><p>将包含a的文档号记录到Bucket[]数组中：</p>
<img data-src="/img/in-post/image-20200406174907675.png" alt="image-20200406174907675" style="zoom:50%;" />



<h2 id="处理包含b的文档"><a href="#处理包含b的文档" class="headerlink" title="处理包含b的文档"></a>处理包含b的文档</h2><p>将包含b的文档号记录到Bucket[]数组中：</p>
<img data-src="/img/in-post/image-20200406174928285.png" alt="image-20200406174928285" style="zoom:50%;" />



<h2 id="处理包含c的文档"><a href="#处理包含c的文档" class="headerlink" title="处理包含c的文档"></a>处理包含c的文档</h2><img data-src="/img/in-post/image-20200406175050897.png" alt="image-20200406175050897" style="zoom:50%;" />



<h2 id="处理包含e的文档"><a href="#处理包含e的文档" class="headerlink" title="处理包含e的文档"></a>处理包含e的文档</h2><img data-src="/img/in-post/image-20200406175105542.png" alt="image-20200406175105542" style="zoom:50%;" />

<h1 id="统计文档号"><a href="#统计文档号" class="headerlink" title="统计文档号"></a>统计文档号</h1><p>在Bucket数组中，下标值代表了文档号，当我们处理所有关键字后，需要遍历文档号，判断每一个文档号出现的次数是否满足MinimumNumbetrShouldMatch，为了使得只对出现的文档号进行遍历，Lucene使用了一个matching数组记录上面出现的文档号。matching数组记录文档号的原理跟FixedBitSet一样，都是用一个bit位来记录文档号。</p>
<p>在本文的例子中，只要用到matching[]的第一个元素，第一个元素的值是879，如图：</p>
<img data-src="/img/in-post/image-20200406180350541.png" alt="image-20200406180350541" style="zoom:50%;" />

<p>根据二进制bit位的值为1，这个bit位的位置来记录包含查询关键字的文档号，包含查询关键字的文档号只有0，1，2，3，5，6，8，9一共8篇文档。</p>
<p>接着根据这些文档号，把他们作为bucket[]数组的下标，找到每个数组的值，如果元素的值大于等于minShouldMatch，对应的文档就是我们最终的结果。在例子中</p>
<pre><code class="java">    builder.setMinimumNumberShouldMatch(2);</code></pre>
<p>所以根据最终的包含e的文档号bucket[]的结果：</p>
<img data-src="/img/in-post/image-20200406181151085.png" alt="image-20200406181151085" style="zoom:50%;" />

<p>只有文档3、5、6、8、9对应的元素值才大于minShouldMatch，满足查询要求。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文总结了使用BooleanQuery并且所有的TermQuery之间是SHOULD关系的文档号合并的原理，在后面的文章中会依次介绍MUST_NOT、Filter的TermQuery的文档号合并原理。</p>
]]></content>
      <categories>
        <category>Lucene</category>
      </categories>
      <tags>
        <tag>Search</tag>
        <tag>Lucene</tag>
        <tag>Collector</tag>
      </tags>
  </entry>
  <entry>
    <title>【Lucene】-【Search】MUST原理</title>
    <url>/2020/04/01/lucene-search-must/</url>
    <content><![CDATA[<p>本文通过一个例子来介绍文档号合并的逻辑。源码实现为：</p>
<p><strong>ConjunctionDISI</strong></p>
<h1 id="索引代码"><a href="#索引代码" class="headerlink" title="索引代码"></a>索引代码</h1><pre><code class="java">
Document doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;a&quot;, Field.Store.YES));
indexWriter.addDocument(doc);

//1
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;b&quot;, Field.Store.YES));
indexWriter.addDocument(doc);


//2
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;c b&quot;, Field.Store.YES));
indexWriter.addDocument(doc);

//3
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;a c&quot;, Field.Store.YES));
indexWriter.addDocument(doc);

//4
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;h&quot;, Field.Store.YES));
indexWriter.addDocument(doc);

//5
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;c e&quot;, Field.Store.YES));
indexWriter.addDocument(doc);

//6
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;c a&quot;, Field.Store.YES));
indexWriter.addDocument(doc);


//7
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;f e&quot;, Field.Store.YES));
indexWriter.addDocument(doc);

//8
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;a c d e c e&quot;, Field.Store.YES));
indexWriter.addDocument(doc);

//9
doc = new Document();
doc.add(new TextField(&quot;content&quot;, &quot;a c e a b c&quot;, Field.Store.YES));
indexWriter.addDocument(doc);

indexWriter.commit();
indexWriter.close();</code></pre>
<h1 id="查询代码"><a href="#查询代码" class="headerlink" title="查询代码"></a>查询代码</h1><p>表示满足查询条件的文档<strong>必须</strong>至少包含“a” “b” “c” “e” 四个关键字。</p>
<pre><code class="java">BooleanQuery.Builder builder = new BooleanQuery.Builder();
builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;a&quot;)), BooleanClause.Occur.MUST);
builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;b&quot;)), BooleanClause.Occur.MUST);
builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;c&quot;)), BooleanClause.Occur.MUST);
builder.add(new TermQuery(new Term(&quot;content&quot;, &quot;e&quot;)), BooleanClause.Occur.MUST);</code></pre>
<h1 id="文档号合并"><a href="#文档号合并" class="headerlink" title="文档号合并"></a>文档号合并</h1><p>将包含各个关键字的文档分别放入到各自的数组中，数组元素是文档号。</p>
<img data-src="/img/in-post/image-20200401222208403.png" alt="image-20200401222208403" style="zoom:50%;" />



<img data-src="/img/in-post/image-20200401222228426.png" alt="image-20200401222228426" style="zoom:50%;" />

<img data-src="/img/in-post/image-20200401222253626.png" alt="image-20200401222253626" style="zoom:50%;" />

<img data-src="/img/in-post/image-20200401222325534.png" alt="image-20200401222325534" style="zoom:50%;" />

<p><strong>由于满足查询要求文档中必须都包含”a” “b” “c” “e” 四个关键字，所以满足查询条件要求的文档个数最多是上面几个数组中最小的数组。</strong></p>
<p>所以合并的逻辑即遍历数组大小最小的那个，在上面的例子中，包含b的文档号的数组。</p>
<p>每次遍历一个数组元素后，再去其他数组中匹配是否也包含这个文档号。遍历其他数组的顺序同样按照数组元素大小从小到大的顺序，即包含e -&gt; a -&gt; c顺序。</p>
<h1 id="文档号合并过程"><a href="#文档号合并过程" class="headerlink" title="文档号合并过程"></a>文档号合并过程</h1><ol>
<li>从包含b的文档号的数组中取出第一个文档号doc1的值，然后从包含e的文档号的数组中取出第一个不小于doc1(1)的文档号doc2的值，即5。比较的结果就是doc1(1)不等于dco2(5)，那么没有必要继续跟其他数组比较了。因为文档号1中不包含关键字e。</li>
</ol>
<img data-src="/img/in-post/image-20200401222517012.png" alt="image-20200401222517012" style="zoom:50%;" />



<ol start="2">
<li><p>接着，继续从从包含b的数组中取出不小于doc2(5)的值（在上图的比较过程中，我们已确定文档号1～文档号5中不同时包含关键字b跟e，所以下一个比较的文档号并不是直接从包含b的数组中取下一个值2，而是根据包含e的文档号的数组中的doc2(5)，从包含b的数组中取出不小于5的值，也就是9。</p>
<img data-src="/img/in-post/image-20200401222629544.png" alt="image-20200401222629544" style="zoom:50%;" />

<ul>
<li><p><strong>想下为什么这么要在b中取大于5的继续比较？</strong></p>
<p>那是因为既然我们要同时找包含e和b的文档，因为已经证明包含e的文档号是5，但并不包含b（因为doc1(1)不等于doc(2))），所以如果取下一个同时包含b和e的文档号，肯定要在包含b的数组中找大于e中的5的文档号（e的数组文档号有序，e数组下一个元素肯定大于5）。</p>
</li>
</ul>
</li>
</ol>
<ol start="3">
<li><p>从包含”a”的文档号数组中取出不小于doc1(9)的文档号doc3的值，也就是9（因为上一步已经证明小于9不同时包含b和e）。</p>
<img data-src="/img/in-post/image-20200401222812613.png" alt="image-20200401222812613" style="zoom:50%;" />
</li>
<li><p>包含b的文档号数组已经遍历结束，至此所有的数组都遍历结束，并且文档号9都在所有数组中出现，即文档9满足查询要求。</p>
</li>
</ol>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文总结了使用BooleanQuery并且所有的TermQuery之间是MUST关系的文档号合并的原理，在后面的文章中会依次介绍SHOULD、MUST_NOT、Filter的TermQuery的文档号合并原理。</p>
]]></content>
      <categories>
        <category>Lucene</category>
      </categories>
      <tags>
        <tag>Search</tag>
        <tag>Lucene</tag>
        <tag>Collector</tag>
      </tags>
  </entry>
  <entry>
    <title>【JVM】-垃圾回收算法和策略</title>
    <url>/2020/04/01/java-jvm-GCPolicy/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Java</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title>【Solr】-【Search】Solr fq与pf的原理与实现</title>
    <url>/2020/03/31/solr-search-fq&amp;pf/</url>
    <content><![CDATA[<p>环境：在单机模式下，启动本地solr调试。</p>
<h1 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h1><pre><code class="java">http://127.0.0.1:8983/test/Collection/select?q=ABST:apple&amp;fq=TTL:apple&amp;timeAllowed=10000000</code></pre>
<h1 id="q与fq的主要流程图"><a href="#q与fq的主要流程图" class="headerlink" title="q与fq的主要流程图"></a>q与fq的主要流程图</h1><img data-src="/img/in-post/image-20200401013329206.png" alt="image-20200401013329206" style="zoom:150%;" />

]]></content>
      <categories>
        <category>Solr</category>
      </categories>
      <tags>
        <tag>Solr</tag>
        <tag>Search</tag>
      </tags>
  </entry>
  <entry>
    <title>【Lucene】-【Search】Collector（二）FilterCollector与TopDocsCollector及其子类TopScoreDocCollector</title>
    <url>/2020/03/30/lucene-search-collector2/</url>
    <content><![CDATA[<p><img data-src="/img/in-post/Collector-5579809.png" alt="Collector"></p>
<h1 id="FilterCollector"><a href="#FilterCollector" class="headerlink" title="FilterCollector"></a>FilterCollector</h1><p>FilterCollector是一个抽象类，用来封装其他的Collector来提供额外的功能。</p>
<h2 id="PositiveScoresOnlyCollector"><a href="#PositiveScoresOnlyCollector" class="headerlink" title="PositiveScoresOnlyCollector"></a>PositiveScoresOnlyCollector</h2><pre><code class="java">public class PositiveScoresOnlyCollector extends FilterCollector {

  public PositiveScoresOnlyCollector(Collector in) {
    super(in);
  }

  @Override
  public LeafCollector getLeafCollector(LeafReaderContext context)
      throws IOException {
    return new FilterLeafCollector(super.getLeafCollector(context)) {

      private Scorer scorer;

      @Override
      public void setScorer(Scorer scorer) throws IOException {
        this.scorer = new ScoreCachingWrappingScorer(scorer);
        in.setScorer(this.scorer);
      }

      @Override
      public void collect(int doc) throws IOException {
        if (scorer.score() &gt; 0) {
          in.collect(doc);
        }
      }

    };
  }

}</code></pre>
<p>首先过滤出文档的打分值大于0的文档号，然后将文档号交给封装的Collector。</p>
<p>其中in是PositiveScorerOnlyCollectro封装的Collector，scorer即一个Scorer对象。</p>
<h2 id="CachingCollector"><a href="#CachingCollector" class="headerlink" title="CachingCollector"></a>CachingCollector</h2><p>CachingCollector可以缓存Collector收集的一次搜索的结果，使得其他Collector可以复用该Collector的数据。</p>
<p>看下Lucene中都有哪些地方在用：</p>
<p><img data-src="/img/in-post/image-20200330231540231.png" alt="image-20200330231540231"></p>
<p>Grouping是Solr中的，GroupingSearch是Lucuene中的。</p>
<p><strong>CachingCollector缓存了哪些数据：</strong></p>
<ul>
<li>List<LeafReaderContext>：LeafReaderContext描述的是一个段内的信息，当索引目录中存在多个段，那么需要List来缓存所有的LeafReaderContext。</li>
<li>List&lt;int[]&gt; docs：一个段中可能有多个满足查询条件的文档，所以使用int[]来缓存那些文档的文档号，当缓存目录中存在多个段时，需要用List来缓存每个段中的所有文档号集合。</li>
<li>List&lt;float[]&gt; scores： 一个段中所有满足查询条件的文档的打分值使用float[]缓存，当索引目录中存在多个段时，需要用List来缓存每个段中的所有文档的打分值集合。</li>
</ul>
<p>两个子类<strong>NoScoreCachingCollector、ScoreCachingCollector</strong>两者的区别在于是否缓存文档的打分值。</p>
<h1 id="TopDocsCollector"><a href="#TopDocsCollector" class="headerlink" title="TopDocsCollector"></a>TopDocsCollector</h1><p>TopDocsCollector类在收集完文档后，会返回一个TopDocs对象。TopDocs对象是收集后的文档信息按照某种规则有序的存放在TopDocs对象中，该对象是搜索结果的返回值。</p>
<p>根据不同<strong>排序(sorting)规则</strong>，TopDocsCollector派生出类图中的3个子类：</p>
<ul>
<li>TopFieldCollector，有如下两个内部子类：<ul>
<li>PagingFieldCollector</li>
<li>SimpleFieldCollector</li>
</ul>
</li>
<li>TopScoreDocsCollector，有如下两个内部子类：<ul>
<li>PagingTopScoreDocCollector</li>
<li>SimpleTopScoreDocCollector</li>
</ul>
</li>
<li>DiversifiedTopDocsCollector</li>
</ul>
<p>上面给出的7个TopDocsCollector的子类，它们的流程差异仅仅是<code>处理该文档</code>这个流程点，即collect(int doc)方法的不同实现。</p>
<p>所以在下文中仅介绍每个Collector的collect(int doc)方法的具体实现：</p>
<h2 id="TopScoreDocsCollector"><a href="#TopScoreDocsCollector" class="headerlink" title="TopScoreDocsCollector"></a>TopScoreDocsCollector</h2><p>TopScoreDocCollector类的排序规则是“先打分、后文档号”。</p>
<ul>
<li>先打分：即先通过文档的打分进行排序，打分值越高，排名越靠前。</li>
<li>后文档号：由于文档号是唯一的，所以当打分值相等时，可以再通过文档号的排序，文档号越小，排名越靠前。</li>
</ul>
<p>在IndexSearcher中准备Collector时会调用create方法选择子类：</p>
<pre><code class="java">  public static TopScoreDocCollector create(int numHits, ScoreDoc after) {

    if (numHits &lt;= 0) {
      throw new IllegalArgumentException(&quot;numHits must be &gt; 0; please use TotalHitCountCollector if you just need the total hit count&quot;);
    }

    if (after == null) {
      return new SimpleTopScoreDocCollector(numHits);
    } else {
      return new PagingTopScoreDocCollector(numHits, after);
    }
  }</code></pre>
<p>根据过滤规则，TopScoreDocCollector的两个子类：</p>
<ul>
<li>SimpleTopScoreDocCollector：无过滤规则</li>
<li>PagingTopScoreDocCollector：有规律规则，具体下文展开。</li>
</ul>
<h3 id="SimpleTopScoreDocCollector"><a href="#SimpleTopScoreDocCollector" class="headerlink" title="SimpleTopScoreDocCollector"></a>SimpleTopScoreDocCollector</h3><img data-src="/img/in-post/image-20200331002708554.png" alt="image-20200331002708554" style="zoom: 50%;" />

<h4 id="score是否大于栈顶元素的score？"><a href="#score是否大于栈顶元素的score？" class="headerlink" title="score是否大于栈顶元素的score？"></a>score是否大于栈顶元素的score？</h4><p>使用优先级队列PriorityQueue来存放满足条件的文档信息<strong>ScoreDoc</strong>（包含了打分和文档号），分数最低的文档信息位于堆顶，堆的大小默认为段中的文档总数（用户也可以指定堆的大小，即用户期望的返回结果TopN的N值）。</p>
<ul>
<li><p>为什么判断条件是score等于堆顶元素的score的情况下也不满足？</p>
<pre><code class="java">          if (score &lt;= pqTop.score) {
            // Since docs are returned in-order (i.e., increasing doc Id), a document
            // with equal score to pqTop.score cannot compete since HitQueue favors
            // documents with lower doc Ids. Therefore reject those docs too.
            return;
          }</code></pre>
<p>因为collect(int doc)方法接受到的文档号总是按照从小到大的顺序，当score等于堆顶元素的score时，当前文档号肯定肯定大于堆顶元素的文档号，根据上文中TopScoreDocCollector的排序规则，故不满足。</p>
</li>
</ul>
<h4 id="调整堆"><a href="#调整堆" class="headerlink" title="调整堆"></a>调整堆</h4><p>替换堆顶元素后，需要调整整堆重新找到分数最低的文档信息，调整的规则同样按照<strong>“先分数，后文档号”</strong>。</p>
<pre><code class="java">          pqTop.doc = doc + docBase;
          pqTop.score = score;
          pqTop = pq.updateTop();</code></pre>
<p>其中pqTop是通过pqTop = pq.top();初始化的，因此永远指向优先级队列（用来作为一个堆）的堆顶，用来更新堆顶，然后updateTop会继续调整pg堆内的元素，保证堆内是按照分数大小的优先级排序。</p>
<h3 id="PagingTopScoreDocCollector"><a href="#PagingTopScoreDocCollector" class="headerlink" title="PagingTopScoreDocCollector"></a>PagingTopScoreDocCollector</h3><p>PagingTopScoreDocCollector是带有过滤规则的Collector，用来<strong>实现分页功能</strong>。</p>
<p>在SimpleTopScoreDocCollector中如果满足搜索条件的文档个数有M个，其中N为用户期望返回的个数（即TopN），为了便于理解，这里假设M&gt;2N，那么第一次搜索后，返回的搜索结果，任意一篇的打分值score都是大于等于剩余的（M-N）篇文档中的任意一篇。</p>
<p>如果使用了PagingTopScoreDocCollector，就可以从（M-N）篇文档中继续找出N篇文档，即执行第二次搜索。该PagingTopScoreDocCollector可以使得多次调用IndexSearcher：</p>
<pre><code class="java">  public TopDocs searchAfter(ScoreDoc after, Query query, int n, Sort sort) throws IOException {
    return searchAfter(after, query, n, sort, false, false);
  }</code></pre>
<p>的方法来实现分页，其中ScoreDoc即after即过滤规则：</p>
<pre><code class="java">           final int afterDoc = after.doc - context.docBase;
                    if (score &gt; after.score || (score == after.score &amp;&amp; doc &lt;= afterDoc)) {
            // hit was collected on a previous page
            return;
          }

          if (score &lt;= pqTop.score) {
            // Since docs are returned in-order (i.e., increasing doc Id), a document
            // with equal score to pqTop.score cannot compete since HitQueue favors
            // documents with lower doc Ids. Therefore reject those docs too.
            return;
          }
          collectedHits++;
          pqTop.doc = doc + docBase;
          pqTop.score = score;
          pqTop = pq.updateTop();</code></pre>
<h4 id="是否已经被收集了？"><a href="#是否已经被收集了？" class="headerlink" title="是否已经被收集了？"></a>是否已经被收集了？</h4><p>很明显看出来这比SimpleTopScoreDocCollector对了一条判断规则：</p>
<pre><code class="java">          if (score &gt; after.score || (score == after.score &amp;&amp; doc &lt;= afterDoc)) {
            // hit was collected on a previous page
            return;
          }</code></pre>
<p>after实际承载的就是上一次分页的最低的那个文档的分数。</p>
<ul>
<li>socore： 该值描述的当前文档的打分值。</li>
<li>after：该值即上文中的ScoreDoc对象。</li>
</ul>
<p>所以下一页就从after的分数后开始计数，即一旦大于after.score 就return了，因为已经在前面的某一页收集返回过了。</p>
<p>其中考虑的score == after.score的情况：</p>
<p>如果两篇文档的打分值一样，那么文档号较大的就不会被收集，所以如果当前的文档号小于等于after.doc，必定该篇文档已经在前面的某一页搜索收集过了。</p>
<p>所以可以看出来，如果一个段中有M篇文档满足搜索条件，在使用分页搜索的情况下，每一次Collecotr都需要处理这M篇文档，只是在每一次的分页搜索时选出N篇文档。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>下一篇Collector（三）继续</p>
]]></content>
      <categories>
        <category>Lucene</category>
      </categories>
      <tags>
        <tag>Search</tag>
        <tag>Lucene</tag>
        <tag>Collector</tag>
      </tags>
  </entry>
  <entry>
    <title>【Lucene】-【Search】Collector（一）总体流程与TimeLimitingCollector</title>
    <url>/2020/03/29/lucene-search-collector1/</url>
    <content><![CDATA[<p>在搜索阶段，每当Lucene找到一个满足查询条件的文档，就会将该文档的文档号(docID)交给Collector，并在Collector中对文档集合中排序(sorting)、过滤(filtering)、打分(score)或者我们可以自己定义的操作。</p>
<p>下面给出常见的Collector的类图，Collector相关的文章也会基于这个类图来展开介绍：</p>
<p><img data-src="/img/in-post/image-20200329162523692.png" alt="image-20200329162523692"></p>
<h1 id="Collector处理文档流程"><a href="#Collector处理文档流程" class="headerlink" title="Collector处理文档流程"></a>Collector处理文档流程</h1><pre><code class="java">  protected void search(List&lt;LeafReaderContext&gt; leaves, Weight weight, Collector collector)
      throws IOException {

    // TODO: should we make this
    // threaded...?  the Collector could be sync&#39;d?
    // always use single thread:
    for (LeafReaderContext ctx : leaves) { // search each subreader
      final LeafCollector leafCollector;
      try {
        leafCollector = collector.getLeafCollector(ctx);
      } catch (CollectionTerminatedException e) {
        // there is no doc of interest in this reader context
        // continue with the following leaf
        continue;
      }
      BulkScorer scorer = weight.bulkScorer(ctx);
      if (scorer != null) {
        try {
          scorer.score(leafCollector, ctx.reader().getLiveDocs());
        } catch (CollectionTerminatedException e) {
          // collection was terminated prematurely
          // continue with the following leaf
        }
      }
    }
  }</code></pre>
<p>处理总体流程图：</p>
<img data-src="/img/in-post/image-20200329170043980.png" alt="image-20200329170043980" style="zoom:50%;" />

<h1 id="获得LeafCollector"><a href="#获得LeafCollector" class="headerlink" title="获得LeafCollector"></a>获得LeafCollector</h1><img data-src="/img/in-post/image-20200329183203594.png" alt="image-20200329183203594" style="zoom:50%;" />      

<p>当索引目录中存在多个段时，需要从每个段中分别找出满足查询条件的文档，LeafReaderContext即用来描述某一个段的信息，并且通过它能获得一个LeafCollector对象，在后面介绍IndexReader的文章中会展开。</p>
<p>在搜索阶段，通过Collector类的方法来获得LeafCollector对象，下面是Collector类的代码，由于Collector类是一个接口类，并且只有两个接口方法：</p>
<pre><code class="java">public interface Collector {

  /**
   * Create a new {@link LeafCollector collector} to collect the given context.
   *
   * @param context
   *          next atomic reader context
   */
  LeafCollector getLeafCollector(LeafReaderContext context) throws IOException;

  /**
   * Indicates if document scores are needed by this collector.
   * 
   * @return {@code true} if scores are needed.
   */
  boolean needsScores();
}
</code></pre>
<h2 id="接口方法getLeafCollector"><a href="#接口方法getLeafCollector" class="headerlink" title="接口方法getLeafCollector"></a>接口方法getLeafCollector</h2><p>通过该方法获得一个LeafCollector对象，Lucene每处理完一个段，就会调用该方法获得下一个段对应的LeafCollector对象。</p>
<p><strong>LeafCollector对象有什么作用：</strong></p>
<ul>
<li><p>首先看下LeafCollector类的结构</p>
<pre><code class="java">public interface LeafCollector {

  /**
   * Called before successive calls to {@link #collect(int)}. Implementations
   * that need the score of the current document (passed-in to
   * {@link #collect(int)}), should save the passed-in Scorer and call
   * scorer.score() when needed.
   */
  void setScorer(Scorer scorer) throws IOException;

  /**
   * Called once for every document matching a query, with the unbased document
   * number.
   * &lt;p&gt;Note: The collection of the current segment can be terminated by throwing
   * a {@link CollectionTerminatedException}. In this case, the last docs of the
   * current {@link org.apache.lucene.index.LeafReaderContext} will be skipped and {@link IndexSearcher}
   * will swallow the exception and continue collection with the next leaf.
   * &lt;p&gt;
   * Note: This is called in an inner search loop. For good search performance,
   * implementations of this method should not call {@link IndexSearcher#doc(int)} or
   * {@link org.apache.lucene.index.IndexReader#document(int)} on every hit.
   * Doing so can slow searches by an order of magnitude or more.
   */
  void collect(int doc) throws IOException;

}</code></pre>
</li>
<li><p>setScorer方法：调用此方法通过Scorer对象获得一篇文档的打分，对文档集合进行排序时，可以作为排序条件，当然Scorer对象包含不仅仅是文档的打分值，在后面文章中会展开。</p>
</li>
<li><p>collect方法：在这个方法中实现了对所有满足查询条件的文档进行排序(sorting)、过滤（filtering）或者用自定义的操作的具体逻辑。</p>
</li>
</ul>
<h2 id="接口方法needScores"><a href="#接口方法needScores" class="headerlink" title="接口方法needScores"></a>接口方法needScores</h2><p>设置该方法用来告诉Lucene在搜索阶段，当找到一篇文档时，是否对齐进行打分。如果用户期望的查询结果不依赖打分，那么可以设置false来提高查询性能。</p>
<h1 id="处理一篇文档"><a href="#处理一篇文档" class="headerlink" title="处理一篇文档"></a>处理一篇文档</h1><img data-src="/img/in-post/image-20200329202854565.png" alt="image-20200329202854565" style="zoom:50%;" />

<p>  调用setScorer设置后续执行<code>获得打分的打分器</code>，随后在获得文档号docID流程后获得一个docID，最后调用LeafCollector的collect(int doc)方法（参数doc即文档号docID）来执行<code>处理该文档</code>的流程，在该流程中，实现对文档进行排序、过滤或者用户自定义的操作。</p>
<h1 id="TimeLimitingCollector"><a href="#TimeLimitingCollector" class="headerlink" title="TimeLimitingCollector"></a>TimeLimitingCollector</h1><p>依次看下类图中的收集器。</p>
<p>TimeLimitingCollector封装了其他Collector，用来限制Collectro处理文档的时间，即设定一次查询允许的最长时间。如果超时就抛出超时异常TimeExeceededException。</p>
<h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><p>在SorIndexSearcher中，有：</p>
<pre><code class="java">    final long timeAllowed = cmd.getTimeAllowed();
    if (timeAllowed &gt; 0) {
      collector = new TimeLimitingCollector(collector, TimeLimitingCollector.getGlobalCounter(), timeAllowed);
    }</code></pre>
<p>作为最外层的collector，调用Lucene 的IndexSearcher search方法。</p>
<p>构造方法中会对计时器初始化：</p>
<pre><code class="java">new TimeLimitingCollector(collector, TimeLimitingCollector.getGlobalCounter(), timeAllowed);</code></pre>
<pre><code class="java">  public TimeLimitingCollector(final Collector collector, Counter clock, final long ticksAllowed ) {
    this.collector = collector;
    this.clock = clock;
    this.ticksAllowed = ticksAllowed;
  }
</code></pre>
<p>Counter在线程安全的场景下是一个AtomicLong。</p>
<h2 id="计时点"><a href="#计时点" class="headerlink" title="计时点"></a>计时点</h2><p>看在哪些流程点会判断查询超时，按照流程的顺序：</p>
<ol>
<li><p>在遍历分片查询时，调用Collector.getLeafCollector(LeafReader)方法时会执行超时判断，即图中是否<code>还有LeafReaderContex</code>t的流程点。</p>
<pre><code class="java">    for (LeafReaderContext ctx : leaves) { // search each subreader
      final LeafCollector leafCollector;
      try {
        leafCollector = collector.getLeafCollector(ctx);
       ...</code></pre>
</li>
<li><p>调用LeafCollector.collect(int doc)方法会执行超时判断，即图中<code>处理该文档</code>的流程点。</p>
</li>
</ol>
<h2 id="如何实现超时机制"><a href="#如何实现超时机制" class="headerlink" title="如何实现超时机制"></a>如何实现超时机制</h2><ul>
<li><p>通过后台线程、解析值resolution、计数器counter实现</p>
<ul>
<li><p>新的query线程进来，就会根据当前clock的时间重新设置超时时间。</p>
<pre><code class="java">  public LeafCollector getLeafCollector(LeafReaderContext context) throws IOException {
    this.docBase = context.docBase;
    if (Long.MIN_VALUE == t0) {
      setBaseline();
    }</code></pre>
</li>
<li><p>计数器counter：AtomicLong类型、用来描述查询已花费的时间。</p>
</li>
<li><p>解析值resolution：long类型，默认是20 表示20毫秒，计数线程没20毫秒sleep一次，然后累加resolution计数。</p>
</li>
<li><p>后台线程：Thread.setDaemon(true)的线程。确保当前父线程退出后，该线程不会退出，继续在后台进行计数。</p>
</li>
</ul>
</li>
<li><p>后台线程先执行counter的累加操作，即调用counter.addAndGet(resolution)的方法，随后调用Thread.sleep(resloution)，如此返回实现计时的功能。</p>
<pre><code class="java">    @Override
    public void run() {
      while (!stop) {
        // TODO: Use System.nanoTime() when Lucene moves to Java SE 5.
        counter.addAndGet(resolution);
        try {
          Thread.sleep( resolution );
        } catch (InterruptedException ie) {
          throw new ThreadInterruptedException(ie);
        }
      }
    }</code></pre>
<p>随后在收集文档号的线程在判断超时的流程点处通过counter.get的值判断是否大于timeout时间。</p>
<pre><code class="java">    return new FilterLeafCollector(collector.getLeafCollector(context)) {

      @Override
      public void collect(int doc) throws IOException {
        final long time = clock.get();
        if (time - timeout &gt; 0L) {
          if (greedy) {
            //System.out.println(this+&quot;  greedy: before failing, collecting doc: &quot;+(docBase + doc)+&quot;  &quot;+(time-t0));
            in.collect(doc);
          }
          //System.out.println(this+&quot;  failing on:  &quot;+(docBase + doc)+&quot;  &quot;+(time-t0));
          throw new TimeExceededException( timeout-t0, time-t0, docBase + doc );
        }
        //System.out.println(this+&quot;  collecting: &quot;+(docBase + doc)+&quot;  &quot;+(time-t0));
        in.collect(doc);
      }

    };</code></pre>
</li>
</ul>
<h2 id="使用这种超时时间机制有什么注意点"><a href="#使用这种超时时间机制有什么注意点" class="headerlink" title="使用这种超时时间机制有什么注意点"></a>使用这种超时时间机制有什么注意点</h2><ul>
<li>由于后台线程先执行counter的累加操作，随后睡眠，故收集文档号的线程超时的时间范围为timeLimt-resolution直timeLimit+resolution的区间，单位是毫秒，因此不是精确的。</li>
<li>resolution设置的越小，查询超时的计算精度越低，但是性能越差（例如线程频繁的睡眠导致的线程上下文切换）。</li>
<li>由于使用了睡眠机制，在运行过程中实时将resolution的值调整为比当前resolution小的值（比如从20毫秒调整为5毫秒），可能会存在调整延迟的问题。</li>
<li>resolution至少要设置5毫秒，因为要保证能正确的调用执行Object.wait(long)方法。</li>
</ul>
<h2 id="笔者注意到的问题以及优化方案"><a href="#笔者注意到的问题以及优化方案" class="headerlink" title="笔者注意到的问题以及优化方案"></a>笔者注意到的问题以及优化方案</h2><p>在上面可以看到，在初始化TimeLimitingCollector后，直到调用到，</p>
<pre><code class="java">  public LeafCollector getLeafCollector(LeafReaderContext context) throws IOException {
    this.docBase = context.docBase;
    if (Long.MIN_VALUE == t0) {
      setBaseline();
    }</code></pre>
<p>才真正重置了计数器，然后开始计时，其实这中间一段时间，发生了很多事情，比如rewrite的时间都没有计算。我们在项目中计算了rewrite的时间，当超长query在rewrite时也会占用大概4秒左右的时间，因此这个计时器的计时就更加不准了。</p>
<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>这个优化主要是通过更好的时间计数器来实现，这个方案我后面来总结。</p>
<h2 id="贪婪模式"><a href="#贪婪模式" class="headerlink" title="贪婪模式"></a>贪婪模式</h2><p>在开启贪婪模式的情况下（默认不开启），如果在LeafCollector.collect()中判断出查询超时，那么还是会收集当前的文档号并随后抛出超时异常，代码如下：</p>
<p>在TimeLimitingCollector中，getLeafCollector方法中：</p>
<pre><code class="java">        if (time - timeout &gt; 0L) {
          if (greedy) {
            //System.out.println(this+&quot;  greedy: before failing, collecting doc: &quot;+(docBase + doc)+&quot;  &quot;+(time-t0));
            in.collect(doc);
          }
          //System.out.println(this+&quot;  failing on:  &quot;+(docBase + doc)+&quot;  &quot;+(time-t0));
          throw new TimeExceededException( timeout-t0, time-t0, docBase + doc );
        }</code></pre>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>下一篇，Collector（二）继续。</p>
]]></content>
      <categories>
        <category>Lucene</category>
      </categories>
      <tags>
        <tag>Search</tag>
        <tag>Lucene</tag>
        <tag>collector</tag>
      </tags>
  </entry>
  <entry>
    <title>【Lucene】-【Search】一文读懂Lucene PhraseQuery</title>
    <url>/2020/03/29/lucene-search-phrase/</url>
    <content><![CDATA[<p>本文介绍PhraseQuery的基本用法，为简单起见，只介绍slop=0的场景下的源码，主要是我了说明Luene的优化点和词频统计的算法。slop等于非0部分的算法后续再补充。也因为这是【search系列】的第一篇介绍query的文章，因此本文会把查询的流程和各个类初始化的过程也写了下来，方便其他query总结时参照。</p>
<h1 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h1><p>直接给出笔者调试源码的demo：</p>
<pre><code class="java">  private void doDemo() {
    PhraseQuery.Builder builder = new PhraseQuery.Builder();
    builder.add(new Term(&quot;content&quot;, &quot;quick&quot;), 1);
    builder.add(new Term(&quot;content&quot;, &quot;fox&quot;), 2);
    builder.add(new Term(&quot;content&quot;, &quot;dog&quot;), 3);


    //builder.add(new Term(&quot;content&quot;, &quot;dog&quot;), 9);
    //builder.setSlop(1);
    //builder.add(new Term(&quot;content&quot;,&quot;a quick black fox&quot;));
    Query query = builder.build();
    // 返回Top5的结果
    int resultTopN = 5;

    ScoreDoc[] scoreDocs = new ScoreDoc[0];
    try {
      scoreDocs = searcher.search(query, resultTopN).scoreDocs;
    } catch (IOException e) {
      e.printStackTrace();
    }

    System.out.println(&quot;Total Result Number: &quot;+scoreDocs.length+&quot;&quot;);
    for (int i = 0; i &lt; scoreDocs.length; i++) {
      ScoreDoc scoreDoc = scoreDocs[i];
      // 输出满足查询条件的 文档号
      System.out.println(&quot;result&quot;+i+&quot;: 文档&quot;+scoreDoc.doc+&quot;&quot;);
    }
  }</code></pre>
<h1 id="代码流程"><a href="#代码流程" class="headerlink" title="代码流程"></a>代码流程</h1><p>给出从输入到文档收集的总体流程，如果图片太小，请打开查看清晰大图。</p>
<p><img data-src="/img/in-post/image-20200325224838395.png" alt="image-20200325224838395"></p>
<p>总体流程：</p>
<ol>
<li><p>如果使用Solr的REST API请求，根据输入String解析由Solr的Parser类解析并构建出PhraseQuery。如果直接调用Lucene API，就直接构造PhraseQuery并初始化，其中输入position如果position[0]不等于0，就统一把position[]处理为以postion[0]=0为起始的poistion[]数组。</p>
</li>
<li><p>初始化PhraseWeight，目的主要是要初始化好BM25Similarity（当然也可以是其他Similarity）相关类为后续打分类做准备，以及在PhraseWeight内部构建好输入Phrase对应的每个Term对象对应的TermContext。</p>
</li>
<li><p>初始化PhraseScorer，目的主要有3个：</p>
<ol>
<li><p>构建出打分相关的对象。</p>
</li>
<li><p>以及打分中会用到的PhraseMatcher对象，PhraseMatcher对象用于在打分之前计算Phrase的词频。</p>
</li>
<li><p>对每个Term对应倒排表文档进行合并处理生成ConjuntionDISI对象（同时这也是一个DocIdIterator迭代器，保存了满足所有Term出现在当前字段的文档列表）并封装到TwoPhraseIterator中，这样在后续收集文档时就会在这个文档里面中迭代TwoPhraseIterator中的文档号。</p>
</li>
</ol>
</li>
<li><p>在步骤3中生成文档列表TwoPhraseIterator进行迭代文档号，通过PhraseMatcher子类，判断当前文档对应的字段对应的一批Term是否满足PhraseQuery中的Position要求，如果满足要求就统计词频。</p>
<p>统计词频后，使用步骤3中的PhraseScorer进行打分，并使用LeafCollector封装的文档队列进行TOP排序或者其他类似collector类型的收集处理，收集好文档返回。</p>
</li>
</ol>
<p>​      </p>
<h1 id="核心算法"><a href="#核心算法" class="headerlink" title="核心算法"></a>核心算法</h1><p>如果你对初始化这些准备工作都已经很熟悉了，那直接跳到<code>Phrase匹配以及词频统计算法</code>。</p>
<h2 id="PhraseQuery初始化"><a href="#PhraseQuery初始化" class="headerlink" title="PhraseQuery初始化"></a>PhraseQuery初始化</h2><p>成员变量：</p>
<pre><code class="java">    private int slop;
    private final List&lt;Term&gt; terms;
    private final List&lt;Integer&gt; positions;</code></pre>
<p>主要通过add方法添加term和对应的position，并通过Builder模式构建出PhraseQuery，</p>
<pre><code class="java">    public PhraseQuery build() {
      Term[] terms = this.terms.toArray(new Term[this.terms.size()]);
      int[] positions = new int[this.positions.size()];
      for (int i = 0; i &lt; positions.length; ++i) {
        positions[i] = this.positions.get(i);
      }
      return new PhraseQuery(slop, terms, positions);
    }
  }</code></pre>
<p>初始化slop、terms、positions。slop默认是0，slop是指，允许两个term之间移动的位数范围，如果slop=0，表示严格按照position指定的term的相对位置查找。</p>
<h2 id="PhraseQuery-rewrite"><a href="#PhraseQuery-rewrite" class="headerlink" title="PhraseQuery rewrite"></a>PhraseQuery rewrite</h2><p>我们知道所有Query都会在IndexSearcher中走到rewrite。并且每个Query都会进行rewrite。</p>
<pre><code class="java">public void search(Query query, Collector results)
  throws IOException {
  query = rewrite(query);
  search(leafContexts, createWeight(query, results.needsScores(), 1), results);
}</code></pre>
<p>PhraseQuery的rewrite方法为：</p>
<pre><code class="java">  public Query rewrite(IndexReader reader) throws IOException {
    if (terms.length == 0) {
      return new MatchNoDocsQuery(&quot;empty PhraseQuery&quot;);
    } else if (terms.length == 1) {
      return new TermQuery(terms[0]);
    } else if (positions[0] != 0) {
      int[] newPositions = new int[positions.length];
      for (int i = 0; i &lt; positions.length; ++i) {//input of term position of phrase query will normalize to 0 starting
        newPositions[i] = positions[i] - positions[0];
      }
      return new PhraseQuery(slop, terms, newPositions);
    } else {
      return super.rewrite(reader);
    }
  }</code></pre>
<ol>
<li><p>可以看到如果输入的term只有一个，会rewrite为TermQuery。</p>
</li>
<li><p>如果输入的term有多个且positions[0] != 0，则会把所有position转换，比如输入的postion 为 1，3，5，rewrite之后postion变为0，2，4。</p>
</li>
<li><p>如果position[0]=0，则直接返回当前对象。</p>
</li>
</ol>
<h2 id="PhraseWeight初始化"><a href="#PhraseWeight初始化" class="headerlink" title="PhraseWeight初始化"></a>PhraseWeight初始化</h2><p>在search之前需要计算Weight，初始化与打分相关的对象。</p>
<p>我们来看下PhraseQuery类的createWeight()方法：</p>
<pre><code class="java">public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {
    return new PhraseWeight(this, field, searcher, needsScores) {

      private transient TermContext states[];

      @Override
      protected Similarity.SimWeight getStats(IndexSearcher searcher) throws IOException {
        final int[] positions = PhraseQuery.this.getPositions();
        if (positions.length &lt; 2) {
          throw new IllegalStateException(&quot;PhraseWeight does not support less than 2 terms, call rewrite first&quot;);
        } else if (positions[0] != 0) {
          throw new IllegalStateException(&quot;PhraseWeight requires that the first position is 0, call rewrite first&quot;);
        }
        final IndexReaderContext context = searcher.getTopReaderContext();
        states = new TermContext[terms.length];
        TermStatistics termStats[] = new TermStatistics[terms.length];
        int termUpTo = 0;
        for (int i = 0; i &lt; terms.length; i++) {
          final Term term = terms[i];
          states[i] = TermContext.build(context, term);
          if (needsScores) {
            TermStatistics termStatistics = searcher.termStatistics(term, states[i]);
            if (termStatistics != null) {
              termStats[termUpTo++] = termStatistics;
            }
          }
        }
        if (termUpTo &gt; 0) {
          return similarity.computeWeight(boost, searcher.collectionStatistics(field), ArrayUtil.copyOfSubArray(termStats, 0, termUpTo));
        } else {
          return null; // no terms at all, we won&#39;t use similarity
        }
      }

      @Override
      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {
        assert terms.length &gt; 0;
        final LeafReader reader = context.reader();
        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];

        final Terms fieldTerms = reader.terms(field);
        if (fieldTerms == null) {
          return null;
        }

        if (fieldTerms.hasPositions() == false) {
          throw new IllegalStateException(&quot;field \&quot;&quot; + field + &quot;\&quot; was indexed without position data; cannot run PhraseQuery (phrase=&quot; + getQuery() + &quot;)&quot;);
        }

        // Reuse single TermsEnum below:
        final TermsEnum te = fieldTerms.iterator();
        float totalMatchCost = 0;

        for (int i = 0; i &lt; terms.length; i++) {
          final Term t = terms[i];
          final TermState state = states[i].get(context.ord);
          if (state == null) { /* term doesnt exist in this segment */
            assert termNotInReader(reader, t): &quot;no termstate found but term exists in reader&quot;;
            return null;
          }
          te.seekExact(t.bytes(), state);
          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS);
          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);
          totalMatchCost += termPositionsCost(te);
        }

        // sort by increasing docFreq order
        if (slop == 0) {
          ArrayUtil.timSort(postingsFreqs);
          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);
        }
        else {
          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost, exposeOffsets);
        }
      }

      @Override
      public void extractTerms(Set&lt;Term&gt; queryTerms) {
        Collections.addAll(queryTerms, terms);
      }
    };
  }</code></pre>
<p>这里创建了PhraseWeight对象，并自己实现了getStats与getPhraseMatcher两个特有的方法。</p>
<p>再看下PhraseWeight的构造方法：</p>
<pre><code class="java">abstract class PhraseWeight extends Weight {

  final boolean needsScores;
  final Similarity.SimWeight stats;
  final Similarity similarity;
  final String field;

  protected PhraseWeight(Query query, String field, IndexSearcher searcher, boolean needsScores) throws IOException {
    super(query);
    this.needsScores = needsScores;
    this.field = field;
    this.similarity = searcher.getSimilarity(needsScores);
    this.stats = getStats(searcher);
  }

  ....
}</code></pre>
<p>主要初始化了打分相关的类。并且在getStats方法中准备好了每个term对应的TermContext[]对象。</p>
<h2 id="PhraseScorer初始化"><a href="#PhraseScorer初始化" class="headerlink" title="PhraseScorer初始化"></a>PhraseScorer初始化</h2><p>当weight都准备好了以后，继续在IndexReader中开始对每个LeafReaderContext进行打分收集文档，这里LeafReaderContext对应一个Segment，未优化过的数据如果有3个Segment，就有3个LeafReaderContext对象。看下IndexReader代码：</p>
<pre><code class="java">  protected void search(List&lt;LeafReaderContext&gt; leaves, Weight weight, Collector collector)
      throws IOException {

    // TODO: should we make this
    // threaded...?  the Collector could be sync&#39;d?
    // always use single thread:
    for (LeafReaderContext ctx : leaves) { // search each subreader
      final LeafCollector leafCollector;
      try {
        leafCollector = collector.getLeafCollector(ctx);
      } catch (CollectionTerminatedException e) {
        // there is no doc of interest in this reader context
        // continue with the following leaf
        continue;
      }
      BulkScorer scorer = weight.bulkScorer(ctx);
      if (scorer != null) {
        try {
          scorer.score(leafCollector, ctx.reader().getLiveDocs());
        } catch (CollectionTerminatedException e) {
          // collection was terminated prematurely
          // continue with the following leaf
        }
      }
    }
  }</code></pre>
<p>这里的打分对象会封装在BulkScorer中，因为比如BoolenQuery中会封装多个Weight以及多个对应的Scorer对象，在打分时会综合所有的Scorer对象结果按照对应的算法进行计算。这里PhraseWeight创建的BulkScorer中只封装了PhraseScorer对象。</p>
<p>在Weight抽象类中定义了bulkScorer方法：</p>
<pre><code class="java">  public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {

    Scorer scorer = scorer(context);
    if (scorer == null) {
      // No docs match
      return null;
    }

    // This impl always scores docs in order, so we can
    // ignore scoreDocsInOrder:
    return new DefaultBulkScorer(scorer);
  }</code></pre>
<p>这里PhraseWeight对应的BulkScorer的实现类是DefaultBulkScorer：</p>
<pre><code class="java">    public DefaultBulkScorer(Scorer scorer) {
      if (scorer == null) {
        throw new NullPointerException();
      }
      this.scorer = scorer;
      this.iterator = scorer.iterator();
      this.twoPhase = scorer.twoPhaseIterator();
    }</code></pre>
<p>这里的初始化得到的文档迭代器是PhraseScorer中的twoPhaseIterator()，再看下PhraseScorer中的twoPhaseIterator方法：</p>
<pre><code class="java">  PhraseScorer(Weight weight, PhraseMatcher matcher, boolean needsScores, Similarity.SimScorer simScorer) {
    super(weight);
    this.matcher = matcher;
    this.needsScores = needsScores;
    this.simScorer = simScorer;
    this.matchCost = matcher.getMatchCost();
  }

  @Override
  public TwoPhaseIterator twoPhaseIterator() {
    return new TwoPhaseIterator(matcher.approximation) {
      @Override
      public boolean matches() throws IOException {
        matcher.reset();
        freq = 0;
        return matcher.nextMatch();
      }

      @Override
      public float matchCost() {
        return matchCost;
      }
    };
  }</code></pre>
<p>可以看到这里的TwoPhraseIterator实际封装的是matcher的approximation变量。</p>
<p>那DefaultBulkScorer中封装的PhraseScorer是如何初始化的：</p>
<pre><code class="java">abstract class PhraseWeight extends Weight {
    public Scorer scorer(LeafReaderContext context) throws IOException {
    PhraseMatcher matcher = getPhraseMatcher(context, false);
    if (matcher == null)
      return null;
    Similarity.SimScorer simScorer = similarity.simScorer(stats, context);
    return new PhraseScorer(this, matcher, needsScores, simScorer);
  }
  ...
}</code></pre>
<p>下面看下这个matcher对象以及对应的matcher中的approximation是如何来的。</p>
<h3 id="准备PhraseMatcher"><a href="#准备PhraseMatcher" class="headerlink" title="准备PhraseMatcher"></a>准备PhraseMatcher</h3><ul>
<li>准备term的倒排表</li>
</ul>
<p>在调用PhraseWeight的scorer方法准备PhraseScorer时，matcher对象通过调用PhraseWeight的匿名实现类获取，匿名类定义在PhraseQuery createWeight方法中，上面PhraseQuery creatWegith源码中已给出。</p>
<p>再给出</p>
<pre><code class="java">      protected PhraseMatcher getPhraseMatcher(LeafReaderContext context, boolean exposeOffsets) throws IOException {
        assert terms.length &gt; 0;
        final LeafReader reader = context.reader();
        PostingsAndFreq[] postingsFreqs = new PostingsAndFreq[terms.length];

        final Terms fieldTerms = reader.terms(field);
        if (fieldTerms == null) {
          return null;
        }

        if (fieldTerms.hasPositions() == false) {
          throw new IllegalStateException(&quot;field \&quot;&quot; + field + &quot;\&quot; was indexed without position data; cannot run PhraseQuery (phrase=&quot; + getQuery() + &quot;)&quot;);
        }

        // Reuse single TermsEnum below:
        final TermsEnum te = fieldTerms.iterator();
        float totalMatchCost = 0;

        for (int i = 0; i &lt; terms.length; i++) {
          final Term t = terms[i];
          final TermState state = states[i].get(context.ord);
          if (state == null) { /* term doesnt exist in this segment */
            assert termNotInReader(reader, t): &quot;no termstate found but term exists in reader&quot;;
            return null;
          }
          te.seekExact(t.bytes(), state);
          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS);
          postingsFreqs[i] = new PostingsAndFreq(postingsEnum, positions[i], t);
          totalMatchCost += termPositionsCost(te);
        }

        // sort by increasing docFreq order
        if (slop == 0) {
          ArrayUtil.timSort(postingsFreqs);
          return new ExactPhraseMatcher(postingsFreqs, totalMatchCost);
        }
        else {
          return new SloppyPhraseMatcher(postingsFreqs, slop, totalMatchCost, exposeOffsets);
        }
      }</code></pre>
<p>这里</p>
<pre><code class="java">          te.seekExact(t.bytes(), state);
          PostingsEnum postingsEnum = te.postings(null, exposeOffsets ? PostingsEnum.ALL : PostingsEnum.POSITIONS);</code></pre>
<p>用来获取term对应的倒排表，并将输入的position[] 封装到PostingsAndFreq中。</p>
<p>然后根据slop是否是0，来决定使用哪种matcher算法，这里只介绍ExactPhraseMatcher，下面看下ExactPhraseMatcher的初始化：</p>
<pre><code class="java">  ExactPhraseMatcher(PhraseQuery.PostingsAndFreq[] postings, float matchCost) {
    super(approximation(postings), matchCost);
    List&lt;PostingsAndPosition&gt; postingsAndPositions = new ArrayList&lt;&gt;();
    for(PhraseQuery.PostingsAndFreq posting : postings) {
      postingsAndPositions.add(new PostingsAndPosition(posting.postings, posting.position));
    }
    this.postings = postingsAndPositions.toArray(new PostingsAndPosition[postingsAndPositions.size()]);
  }

  private static DocIdSetIterator approximation(PhraseQuery.PostingsAndFreq[] postings) {
    List&lt;DocIdSetIterator&gt; iterators = new ArrayList&lt;&gt;();
    for (PhraseQuery.PostingsAndFreq posting : postings) {
      iterators.add(posting.postings);
    }
    return ConjunctionDISI.intersectIterators(iterators);
  }</code></pre>
<p>这里就是把各个term对应的倒排表调用<code>ConjunctionDISI.intersectIterators(iterators);</code>进行文档合并，返回的是一个ConjunctionDISI对象，看下这个类结构：</p>
<p><code>public final class ConjunctionDISI extends DocIdSetIterator</code>。</p>
<h2 id="Phrase匹配以及词频统计算法"><a href="#Phrase匹配以及词频统计算法" class="headerlink" title="Phrase匹配以及词频统计算法"></a>Phrase匹配以及词频统计算法</h2><p>下面看下本文的重点，使用ExactPhraseMatcher的approximation合并的倒排表中文档部分进行文档迭代并判断当前文档是否满足输入的position。迭代的代码如下：</p>
<pre><code class="java">    static void scoreAll(LeafCollector collector, DocIdSetIterator iterator, TwoPhaseIterator twoPhase, Bits acceptDocs) throws IOException {
      if (twoPhase == null) {
        for (int doc = iterator.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = iterator.nextDoc()) {
          if (acceptDocs == null || acceptDocs.get(doc)) {
            collector.collect(doc);
          }
        }
      } else {
        // The scorer has an approximation, so run the approximation first, then check acceptDocs, then confirm
        final DocIdSetIterator approximation = twoPhase.approximation();
        for (int doc = approximation.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = approximation.nextDoc()) {
          if ((acceptDocs == null || acceptDocs.get(doc)) &amp;&amp; twoPhase.matches()) {//为什么要在这里match(match一次freq就已经初始化成了1)，而在socer打分中再计算词phrase的freq
            collector.collect(doc);//这是为了提高效率，比如有些文档都包含了phrase中的词当时顺序不对，这样就可以先把这些文档过滤掉不用再参与打分排序了。
          }
        }
      }</code></pre>
<h3 id="Phrase按照position匹配"><a href="#Phrase按照position匹配" class="headerlink" title="Phrase按照position匹配"></a>Phrase按照position匹配</h3><p>先看下代码：</p>
<pre><code class="java">private static boolean advancePosition(PostingsAndPosition posting, int target) throws IOException {
    while (posting.pos &lt; target) {
      if (posting.upTo == posting.freq) {
        return false;
      } else {
        posting.pos = posting.postings.nextPosition();
        posting.upTo += 1;
      }
    }
    return true;
  }

  @Override
  public void reset() throws IOException {
    for (PostingsAndPosition posting : postings) {
      posting.freq = posting.postings.freq();
      posting.pos = -1;
      posting.upTo = 0;
    }
  }

  @Override
  public boolean nextMatch() throws IOException {
    final PostingsAndPosition lead = postings[0];
    if (lead.upTo &lt; lead.freq) {
      lead.pos = lead.postings.nextPosition();
      lead.upTo += 1;
    }
    else {
      return false;
    }
    advanceHead:
    while (true) {
      final int phrasePos = lead.pos - lead.offset;
      for (int j = 1; j &lt; postings.length; ++j) {
        final PostingsAndPosition posting = postings[j];
        final int expectedPos = phrasePos + posting.offset;

        // advance up to the same position as the lead
        if (advancePosition(posting, expectedPos) == false) {
          break advanceHead;
        }

        if (posting.pos != expectedPos) { // we advanced too far
          if (advancePosition(lead, posting.pos - posting.offset + lead.offset)) {
            continue advanceHead;//例：查quick fox dog，有数据：quick cat fox,定位到fox时发现发现位置时2，不是预期的1，
          } else {//所有重新计算，预期位置时pos - offset + lead.offset=2-1+0 为预期lead的位置，来判断当前fox的前方是不是(quick)lead。
            break advanceHead;
          }
        }
      }
      return true;
    }
    return false;
  }</code></pre>
<p>每次调用match方法先进行reset()重置当前倒排表对应postion以及词频的信息，然后调用nextMatch判断是否匹配：</p>
<p>这个算法初看使用了编程规范中的断点跳转，不容易理解。看上去写法不规范，实际是为了算法简单，下面取一个本文开头的例子：</p>
<ul>
<li>倒排表数据：</li>
</ul>
<p>输入的postion信息quick=1, fox=2 dog=3。</p>
<p>简单起见，使用<code>Analyzer analyzer = new WhitespaceAnalyzer();</code>进行简单的空格分词，空格把一句话分词为一个个Term，如下：</p>
<p><img data-src="/img/in-post/image-20200325233758673.png" alt="image-20200325233758673"></p>
<p>映射到倒排表中，每个term对应的倒排表信息中存储的position信息如下：</p>
<p><img data-src="/img/in-post/image-20200325234719671.png" alt="image-20200325234719671"></p>
<p>可知对应的词频为：</p>
<p>freq(quick)=5、freq(fox)=5、freq(dog)=2。</p>
<p>quick 、 fox 、dog分别对应posting[0] posting[2] posting[2]</p>
<ul>
<li><p>reset()初始化</p>
<p>posting[0].freq=5、posting[1]=5、posting[2]=2</p>
</li>
<li><ol>
<li>第一次循环：</li>
</ol>
<p>选出一个lead作为参考，即posting[0]。</p>
<p>如上图，这里lead.pos=0,upTo=1,upTo表示当前字段对应的posting迭代次数。注意：因为一个term对应的倒排表在内存中是连续的，<strong>因此迭代次数是不能超过词频的，否则就迭代到后续term对应的下一篇文档中了。</strong></p>
<p>下面进入while(true)</p>
<p>phrasePos =lead.pos - lead.offset，这里offset实际是输入的position位置，phrasePos表示lead的位置也是0。</p>
<p>并进入for循环，for循环最多循环3次，因为这里是3个term的phrase查找。</p>
<p>j=1，expectedPos= 0+ posting[1].offset = 0+1，即第二个term应该出现在1的位置上。下面进入<code>advancePosition(posting, expectedPos)</code>,判断预期的位置与posting[1]的实际位置是否一致，如果不一致就直接跳出循环(这里的不一致是指在词频范围内且target范围内都没有出现这个term，表示这个term在当前域中已经找完了，没必要再找了)，表示当前文档的这3个term的position不匹配。</p>
<p>如果满足，就在for内开始第二次循环：</p>
</li>
<li><ol start="2">
<li>第二次循环：</li>
</ol>
<p>Posting[2]的预期位置expected=0+2=2，然后继续进入<code>advancePosition</code>判断，如果返回true满足当前3个term的位置关系，就返回true。</p>
</li>
<li><ol start="3">
<li>重复循环lead的advancePosition，在freq范围内这3个term的位置关系都判断一遍</li>
</ol>
<p>这里在adavenPosition返回时true时，for的每一步循环都会判断(posting.pos != expectedPos)，这是因为有这个场景，假如有：quick cat fox，当准备查找第二个term fox的posting时，查到其位置信息是2，超过了预期的1时，这时候计算：posting.pos - posting.offset + lead.offset 得到fox倒推的lead是不是真正的lead（quick），这里fox的前一位是cat不是quick，而进入advancePosition找到了下一个的quick的位置是3，表示又找了新的lead，进行下一次的3次term的位置比较。以此类推，直到找到一次满足这3个term的position组合，就返回true，<strong>表示当前文档的字段满足查询要求，即将加入打分收集文档阶段</strong>。这里是一个优化，因为打分也需要计算词频，因此在进行文档过滤时就已经进行了第一次的词频计算，如果找到了词频freq就等于=1。</p>
</li>
</ul>
<h3 id="phrase词频计算"><a href="#phrase词频计算" class="headerlink" title="phrase词频计算"></a>phrase词频计算</h3><pre><code class="java">for (int doc = approximation.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = approximation.nextDoc()) {
            if ((acceptDocs == null || acceptDocs.get(doc)) &amp;&amp; twoPhase.matches()) {//为什么要在这里match(match一次freq就已经初始化成了1)，而在socer打分中再计算词phrase的freq
            collector.collect(doc);//这是为了提高效率，比如有些文档都包含了phrase中的词当时顺序不对，这样就可以先把这些文档过滤掉不用再参与打分排序了。
            }
        }</code></pre>
<p>  当在DefaultBulkScorer中迭代TwoPhraseIterator时，如果match会进入collector.collect(doc)收集文档阶段，该阶段会进行打分，下面看下PhraseScorer的打分方法：</p>
<pre><code class="java">    public float score() throws IOException {
      if (freq == 0) {
        freq = matcher.sloppyWeight(simScorer);
        while (matcher.nextMatch()) {
          freq += matcher.sloppyWeight(simScorer);
        }
      }
      return simScorer.score(docID(), freq);
    }</code></pre>
<p>  可以看到如果这时候freq=0时freq=matcher.sloppyWeight(simScorer);因为之前已经match，说明这时候freq至少等于1，然后再次进入nextMatch开始找下一对满足这3个term位置关系的组合，直到在词频范围内全部找完。至此freq累加计算完毕，开始进入BM25打分。BM25打分介绍在本人博客search系列的其他文章中给出，敬请期待。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>phrase查询的核心算法就是文档合并+term的postion匹配算法计算词频。为确保计算满足输入的term的postion组合，查找时不溢出到其他的文档字段中，每次进入nextMatch都会计算lead的upTo这个迭代次数不允许大于lead的词频或者在advancePosition时迭代不可以超过了当前查找此的词频次数，因为如果连lead或者lead后面的term都大于词频数了，那么当前文档的这个字段的term为起始的组合或者后续的这个term就已经找完了，非常巧妙吧。</p>
]]></content>
      <categories>
        <category>Lucene</category>
      </categories>
      <tags>
        <tag>Search</tag>
        <tag>Lucene</tag>
        <tag>PhraseQuery</tag>
      </tags>
  </entry>
  <entry>
    <title>【DocValues】一、SortedDocValues</title>
    <url>/2020/02/07/lucene-dv-SortedDocValues/</url>
    <content><![CDATA[<h1 id="DocValues前言"><a href="#DocValues前言" class="headerlink" title="DocValues前言"></a>DocValues前言</h1><p>在搜索引擎中一般会构建两种索引：</p>
<ul>
<li>倒排索引（inverted index）：简单来说实现域值（field value）到文档的映射。</li>
<li>正排索引：主要实现文档到域值的映射，<strong>DocValues</strong>就是这种正排索引。</li>
</ul>
<p>引用lucene-solr的文档中对于<a href="https://lucene.apache.org/solr/guide/7_7/docvalues.html" target="_blank" rel="noopener">为什么需要DocValue相关的介绍</a>：</p>
<blockquote>
<h2 id="Why-DocValues"><a href="#Why-DocValues" class="headerlink" title="Why DocValues?"></a>Why DocValues?</h2><p>The standard way that Solr builds the index is with an <em>inverted index</em>. This style builds a list of terms found in all the documents in the index and next to each term is a list of documents that the term appears in (as well as how many times the term appears in that document). This makes search very fast - since users search by terms, having a ready list of term-to-document values makes the query process faster.</p>
<p>For other features that we now commonly associate with search, such as sorting, faceting, and highlighting, this approach is not very efficient. The faceting engine, for example, must look up each term that appears in each document that will make up the result set and pull the document IDs in order to build the facet list. In Solr, this is maintained in memory, and can be slow to load (depending on the number of documents, terms, etc.).</p>
<p>In Lucene 4.0, a new approach was introduced. DocValue fields are now column-oriented fields with a document-to-value mapping built at index time. This approach promises to relieve some of the memory requirements of the fieldCache and make lookups for faceting, sorting, and grouping much faster.</p>
</blockquote>
<h2 id="DocValues的类型主要有5种类型"><a href="#DocValues的类型主要有5种类型" class="headerlink" title="DocValues的类型主要有5种类型"></a>DocValues的类型主要有5种类型</h2><ul>
<li>NumericDocValues</li>
<li>SortedNumericDocValues</li>
<li>SortedDocValues</li>
<li>SortedSetDocValues</li>
<li>BinaryDocValues</li>
</ul>
]]></content>
      <categories>
        <category>Lucene</category>
      </categories>
      <tags>
        <tag>Search</tag>
        <tag>Lucene</tag>
        <tag>DocValues</tag>
      </tags>
  </entry>
  <entry>
    <title>【工具使用】IEDA使用分享</title>
    <url>/2020/02/07/tools-idea-simple/</url>
    <content><![CDATA[<h1 id="IDEA-MAC下原生快捷键"><a href="#IDEA-MAC下原生快捷键" class="headerlink" title="IDEA MAC下原生快捷键"></a>IDEA MAC下原生快捷键</h1><p>之前一直在window平台使用eclipse后来切换成linux开发环境使用idea更加高效，快捷键一直沿用的eclipse，后来又切换成mac下办公，发现沿用eclipse的快捷键总不能习惯，于是索性完全去使用idea原生快捷键。本总结是本人最常用的一些快捷键。</p>
<ul>
<li>⌘ -&gt; command</li>
<li>⇧ -&gt; shift</li>
<li>⌥ -&gt; option</li>
<li>⬆ -&gt; 上箭头</li>
<li>⬇ -&gt; 下箭头</li>
<li>⌃ -&gt; Control</li>
</ul>
<h2 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h2><p><img data-src="/img/in-post/image-20200208004639972.png" alt=""></p>
<p><img data-src="/img/in-post/image-20200208004702512.png" alt=""></p>
<table>
<thead>
<tr>
<th>快捷键</th>
<th>中文描述</th>
<th>英文描述</th>
</tr>
</thead>
<tbody><tr>
<td>⌘+O</td>
<td>查找类</td>
<td>Class</td>
</tr>
<tr>
<td>⌘+⇧+O</td>
<td>查找文件</td>
<td>File</td>
</tr>
<tr>
<td>⌘+⌥+O</td>
<td>查找符号</td>
<td>Symbols</td>
</tr>
<tr>
<td>⌘+⇧+F</td>
<td>全局查找</td>
<td>Find in Path</td>
</tr>
</tbody></table>
<h2 id="快速跳转"><a href="#快速跳转" class="headerlink" title="快速跳转"></a>快速跳转</h2><p><img data-src="/img/in-post/image-20200208011618763.png" alt=""></p>
<table>
<thead>
<tr>
<th>快捷键</th>
<th>中文描述</th>
<th>英文描述</th>
</tr>
</thead>
<tbody><tr>
<td>⌘+E</td>
<td>跳转最近打开的文件</td>
<td>recent files</td>
</tr>
<tr>
<td>⌘+⇧+delete</td>
<td>跳转上一次修改的位置</td>
<td>last edit location</td>
</tr>
<tr>
<td>⌘+⌥+←</td>
<td>跳转上一次浏览的位置</td>
<td>back</td>
</tr>
<tr>
<td>⌘+⌥+→</td>
<td>撤销跳转上一次浏览的位置</td>
<td>forward</td>
</tr>
</tbody></table>
<h2 id="代码阅读"><a href="#代码阅读" class="headerlink" title="代码阅读"></a>代码阅读</h2><p><img data-src="/img/in-post/image-20200208011729084.png" alt=""></p>
<table>
<thead>
<tr>
<th>快捷键</th>
<th>中文描述</th>
<th>英文描述</th>
</tr>
</thead>
<tbody><tr>
<td>⌘ + b/点击</td>
<td>从定义跳转到使用/使用跳转到定义</td>
<td>Declaration or Usages</td>
</tr>
<tr>
<td>⌘ + ⌥ + b/点击</td>
<td>查看实现</td>
<td>Implemention</td>
</tr>
<tr>
<td>⇧ + ⌘/⌃ + b/点击</td>
<td>查看变量对应类型定义</td>
<td>Type Declaration</td>
</tr>
<tr>
<td>⌃ + h</td>
<td>查看类型层次</td>
<td>Type Hierarchy</td>
</tr>
<tr>
<td>⇧ + ⌘ + h</td>
<td>查看方法层次</td>
<td>Method Hierarchy</td>
</tr>
<tr>
<td>⌃ + ⌥ + h</td>
<td>查看调用层次</td>
<td>Call Hieratchy</td>
</tr>
<tr>
<td>⌥ + ⌘ + ⬆</td>
<td>查看上一个类</td>
<td>Previous Occurrence</td>
</tr>
<tr>
<td>⌥ + ⌘ + ⬇</td>
<td>查看下一个类</td>
<td>Next Occurrence</td>
</tr>
</tbody></table>
<h2 id="快速重构"><a href="#快速重构" class="headerlink" title="快速重构"></a>快速重构</h2><p><img data-src="/img/in-post/image-20200208010359074.png" alt=""></p>
<table>
<thead>
<tr>
<th>快捷键</th>
<th>中文描述</th>
<th>英文描述</th>
</tr>
</thead>
<tbody><tr>
<td>⇧+F6</td>
<td>重命名</td>
<td>Rename</td>
</tr>
<tr>
<td>⌘+⌥+v</td>
<td>抽取为局部变量</td>
<td>Variable</td>
</tr>
<tr>
<td>⌘+⌥+c</td>
<td>抽取为静态变量</td>
<td>Constant</td>
</tr>
<tr>
<td>⌘+⌥+f</td>
<td>抽取为成员变量</td>
<td>Field</td>
</tr>
<tr>
<td>⌘+⌥+p</td>
<td>抽取为形参</td>
<td>Parameter</td>
</tr>
<tr>
<td>⌘+⌥+m</td>
<td>抽取为方法</td>
<td>Method</td>
</tr>
</tbody></table>
<h2 id="快捷操作"><a href="#快捷操作" class="headerlink" title="快捷操作"></a>快捷操作</h2><p><img data-src="/img/in-post/image-20200208011130506.png" alt=""></p>
<table>
<thead>
<tr>
<th>快捷键</th>
<th>中文描述</th>
<th>英文描述</th>
</tr>
</thead>
<tbody><tr>
<td>⌘+delete</td>
<td>删除行</td>
<td>Delete</td>
</tr>
<tr>
<td>⌘+D</td>
<td>复制行</td>
<td>Duplicate Line</td>
</tr>
<tr>
<td>⌘+N</td>
<td>快捷生成代码</td>
<td>Generate</td>
</tr>
<tr>
<td>⌘+⌥+L</td>
<td>格式化代码</td>
<td>Reformat Code</td>
</tr>
<tr>
<td>⌘+⌥+T</td>
<td>快捷生成语法</td>
<td>Surround With</td>
</tr>
<tr>
<td>⌃+O</td>
<td>覆盖父类方法</td>
<td>Override Methods</td>
</tr>
<tr>
<td>⌃+I</td>
<td>实现父类方法</td>
<td>Implement Methods</td>
</tr>
<tr>
<td>⌘+7</td>
<td>查看类属性列表</td>
<td>Structure</td>
</tr>
<tr>
<td>⌘+⇧+U</td>
<td>大小写转换</td>
<td>Toggle Case</td>
</tr>
</tbody></table>
<h2 id="书签收藏"><a href="#书签收藏" class="headerlink" title="书签收藏"></a>书签收藏</h2><p><img data-src="/img/in-post/image-20200208012849703.png" alt=""></p>
<table>
<thead>
<tr>
<th>快捷键</th>
<th>中文描述</th>
<th>英文描述</th>
</tr>
</thead>
<tbody><tr>
<td>F3</td>
<td>定义书签</td>
<td>Toggle bookmarks</td>
</tr>
<tr>
<td>⌘+F3</td>
<td>显示书签列表</td>
<td>Show bookmarks</td>
</tr>
<tr>
<td>⌃+⇧+数字键</td>
<td>定义数字书签</td>
<td>Toggle bookmarks with Mnemonic</td>
</tr>
<tr>
<td>⌃+数字键</td>
<td>跳转到指定的数字书签</td>
<td>Go to Bookmark $num</td>
</tr>
<tr>
<td>⌥+⇧+F</td>
<td>加入收藏</td>
<td>Add to Favorites</td>
</tr>
<tr>
<td>⌘+2</td>
<td>显示收藏窗口 包括书签、收藏、断点</td>
<td>Favorites</td>
</tr>
</tbody></table>
<h2 id="快捷Debug"><a href="#快捷Debug" class="headerlink" title="快捷Debug"></a>快捷Debug</h2><table>
<thead>
<tr>
<th><strong>快捷键</strong></th>
<th><strong>中文描述</strong></th>
<th><strong>英文描述</strong></th>
</tr>
</thead>
<tbody><tr>
<td>F7</td>
<td>单步运行 进入方法体</td>
<td>Step Into</td>
</tr>
<tr>
<td>F8</td>
<td>单步运行 不进入方法体</td>
<td>Step Over</td>
</tr>
<tr>
<td>alt+F9</td>
<td>运行到光标</td>
<td>Run to Cursor</td>
</tr>
<tr>
<td>F9</td>
<td>运行到下一个断点</td>
<td>Resume</td>
</tr>
<tr>
<td>cmd+F8</td>
<td>添加普通断点</td>
<td>Toggle Line Breakpoint</td>
</tr>
<tr>
<td>cmd+shift+F8</td>
<td>查看/编辑断点</td>
<td>View Breakpoints</td>
</tr>
<tr>
<td>F2</td>
<td>修改变量值</td>
<td>Set Value</td>
</tr>
<tr>
<td>alt+F8</td>
<td>运行表达式求值</td>
<td>Evaluate Expression</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title>【工具类】FixedBitSet</title>
    <url>/2020/02/04/lucene-utils-fixedBitSet/</url>
    <content><![CDATA[<p><strong>源码位置：org/apache/lucene/util/FixedBitSet.java</strong></p>
<p>FixedBitSet类在Lucene中属于一个工具类(Util)，一个用途主要是存储文档号，用一个bit位来描述（存储）一个文档号。</p>
<p>特别<strong>适合存储连续并且没有重复的int类型的数值</strong>。最好情况可以用8个字节描述64个int类型的值。</p>
<p><img data-src="/img/in-post/image-20200204105429938.png" alt=""></p>
<p>如图，8个字节即8*8=64位，每一位（置1）表示一个文档号，可以连续存储0~63 这64个文档号。</p>
<p>下面通过源码解读的方式总结FixedBitSet的存储原理。</p>
<h1 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h1><pre><code class="java">  /**
   * Creates a new LongBitSet.
   * The internally allocated long array will be exactly the size needed to accommodate the numBits specified.
   * @param numBits the number of bits needed
   */
  public FixedBitSet(int numBits) {
    this.numBits = numBits;
    bits = new long[bits2words(numBits)];
    numWords = bits.length;
  }</code></pre>
<p>构造一个FixedBitSet对象，参数numBits用来确定需要多少bit位存储我们的int数值。</p>
<p>如果我们令numBits的值为300，实际就会分配64的整数倍的bit位。因为比300大的第一个64的倍数是320（64*5），所以实际可以存储[0~319]范围的数值。</p>
<p>最终根据320的值，我们获得一个long类型的bit[]数组，具体定义为<code>private final long[] bits</code>，具体bit[]数组初始化为大小5。bit[]数组的每一个元素时long类型，即64bit，所以5个元素一共有64*5=320个bit位。这就是为什么需要5位long数组。其中5位是通过<code>bits2words(numBits)</code>方法计算的，代码为：</p>
<pre><code class="java">  /** returns the number of 64 bit words it would take to hold numBits */
  public static int bits2words(int numBits) {
    return ((numBits - 1) &gt;&gt; 6) + 1; // I.e.: get the word-offset of the last bit and add one (make sure to use &gt;&gt; so 0 returns 0!)
  }</code></pre>
<h1 id="set-int-index-方法"><a href="#set-int-index-方法" class="headerlink" title="set(int index)方法"></a>set(int index)方法</h1><pre><code class="java">  public void set(int index) {
    assert index &gt;= 0 &amp;&amp; index &lt; numBits: &quot;index=&quot; + index + &quot;, numBits=&quot; + numBits;
    //将index根据64进行划分，比如 0~63都属于一个wordNum, 64~127属于另一个wordNum
    int wordNum = index &gt;&gt; 6;      // div 64
    //计算出当前文档号应该放到64个bit位(long类型)的哪一位
    long bitmask = 1L &lt;&lt; index;
    //bit[]是个long类型的数据
    bits[wordNum] |= bitmask;
  }</code></pre>
<h2 id="例子解析"><a href="#例子解析" class="headerlink" title="例子解析"></a>例子解析</h2><pre><code class="java">        FixedBitSet fixedBitSet = new FixedBitSet(300);
        fixedBitSet.set(3);
        fixedBitSet.set(67);
        fixedBitSet.set(70);
        fixedBitSet.set(179);
        fixedBitSet.set(195);
        fixedBitSet.set(313);</code></pre>
<h3 id="添加-3"><a href="#添加-3" class="headerlink" title="添加 3"></a>添加 3</h3><p>set的逻辑步骤为：</p>
<ol>
<li>计算wordNum的值：3&gt;&gt;6 ，即wordNum = 0， 说明3应该存放在bit[]数组下标为0的元素中。</li>
<li>计算出bitmask的值：即计算出在64个bit位中的偏移，bitmask=0b1000。</li>
<li>bitmask与bits[workNum]即bits[0]执行或操作。</li>
</ol>
<p>如图：</p>
<p><img data-src="/img/in-post/2-0785501.png" alt=""></p>
<h3 id="添加67"><a href="#添加67" class="headerlink" title="添加67"></a>添加67</h3><p>set的逻辑步骤为：</p>
<ol>
<li>计算wordNum的值：67&gt;&gt;6 ，即wordNum = 1， 说明3应该存放在bit[]数组下标为1的元素中。</li>
<li>计算出bitmask的值：即计算出在64个bit位中的偏移，bitmask=0b1000。</li>
<li>bitmask与bits[workNum]即bits[1]执行或操作。</li>
</ol>
<p><img data-src="/img/in-post/3-0785583.png" alt=""></p>
<h3 id="添加120"><a href="#添加120" class="headerlink" title="添加120"></a>添加120</h3><p>set的步骤为:</p>
<ol>
<li><p>计算wordNum的值：120 &gt;&gt; 6，即wordNum = 1，说明120应该放在bit[]数组下标为1的元素中。</p>
</li>
<li><p>计算出bitmask的值，即计算出在64个bit位中的偏移，bitmask=0b00000001_00000000_00000000_00000000_00000000_00000000_00000000_00000000。</p>
</li>
<li><p>与bit[1]的值执行或操作。</p>
<p><img data-src="/img/in-post/4-1005907.png" alt=""></p>
</li>
</ol>
<p>接下来添加179、195、313的过程就不总结了，步骤与上面的步骤都是一样的。直接给出添加所有文档号的数组数据。</p>
<p><img data-src="/img/in-post/5-1005990.png" alt=""></p>
<h1 id="boolean-get-int-index-方法"><a href="#boolean-get-int-index-方法" class="headerlink" title="boolean get(int index)方法"></a>boolean get(int index)方法</h1><p>get()方法可以实现随机访问，来确定index的值是否在bit[]数组中。</p>
<pre><code class="java">  public boolean get(int index) {
    assert index &gt;= 0 &amp;&amp; index &lt; numBits: &quot;index=&quot; + index + &quot;, numBits=&quot; + numBits;
    int i = index &gt;&gt; 6;               // div 64
    // signed shift will keep a negative index and force an
    // array-index-out-of-bounds-exception, removing the need for an explicit check.
    long bitmask = 1L &lt;&lt; index;
    return (bits[i] &amp; bitmask) != 0;
  }</code></pre>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul>
<li>通过set方法一些的例子，可以看出：如果我们<strong>存储连续的值，压缩效率很高</strong>。但是<strong>无法处理有相同值的情况</strong>。</li>
<li>FixedBitSet类还有一些其他方法，比如prevSetBit(int index)来找到第一个比index小的值和nextSetBit(int index)来找到第一个比index大的数，在Lucene中，常见FixedBitSet来存储文档号，并且通过preSetBit(int index)或nextSetBit(int index)来遍历文档号。</li>
</ul>
]]></content>
      <categories>
        <category>Lucene</category>
      </categories>
      <tags>
        <tag>Search</tag>
        <tag>Lucene</tag>
        <tag>Lucene工具类</tag>
      </tags>
  </entry>
  <entry>
    <title>【索引文件】.doc文件</title>
    <url>/2020/02/02/lucene-indexfile-doc/</url>
    <content><![CDATA[<p>这篇文章总结Lucene各个索引文件的作用和数据结构，为后续索引生成过程和存储分析打下基础。</p>
<h1 id="doc文件"><a href="#doc文件" class="headerlink" title="doc文件"></a>doc文件</h1><h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><p>索引文件.doc按块block的方式存放每一个<strong>term的文档号、词频</strong>，并且保存skip data来实现块之间的快速跳转，本篇只介绍.doc的数据结构，生成过程后续文章总结。</p>
<h2 id="doc文件的数据结构"><a href="#doc文件的数据结构" class="headerlink" title="doc文件的数据结构"></a>doc文件的数据结构</h2><p><img data-src="/img/in-post/1-20200202100530710.png" alt=""></p>
<p>TermFreqs保存了term的所有文档号、词频信息，TermFreqs中按块存储，使用SkipData实现这些块之间的快速跳转。</p>
<h3 id="TermFreqs"><a href="#TermFreqs" class="headerlink" title="TermFreqs"></a>TermFreqs</h3><p><img data-src="/img/in-post/2-20200202100922059.png" alt=""></p>
<ul>
<li><p><strong>PackedBlock</strong></p>
<p>每处理包含term的128篇文档，就将这些文档的信息处理为一个PackedBlock。</p>
<ul>
<li><p>PackedDocDeltaBlock</p>
<p>PackedDocDeltaBlock存放了128篇文档的<strong>文档号</strong>，计算相邻两个文档号的差值后，利用PackedInts压缩存储。</p>
</li>
<li><p>PackedFreqBlock</p>
<p>PackedFreqBlock存放了term分别在128文档中的<strong>词频</strong>，利用PackedInts压缩存储。</p>
</li>
</ul>
</li>
<li><p><strong>VIntBlocks &amp;&amp; VIntBlock</strong></p>
<p>如果包含term的文档号不足128个，那么将这些文档信息处理为一个VIntBlocks。（比如包含term的文档数量有200，那么前129篇文档的信息被处理为一个PackedBlock，剩余的72篇文档处理为72个VIntBlock，72个VIntBlock为一个VIntBlocks）</p>
<ul>
<li><p>DocDelta</p>
<p>当前文档号跟上一个文档号的差值。</p>
</li>
<li><p>Freq</p>
<p>term在当前文档的词频。</p>
</li>
</ul>
</li>
</ul>
<h3 id="SkipData"><a href="#SkipData" class="headerlink" title="SkipData"></a>SkipData</h3><ul>
<li>跳表的基本概念</li>
</ul>
<p><img data-src="/img/in-post/3-20200202102301234.png" alt=""></p>
<p>这是一般跳表的数据结构：在每一层中，每3个数据库就会在上一层中添加一个索引，实现了对数级别的时间复杂度。</p>
<p>关于跳表的详细介绍可以看后续文档索引文件生成——跳表。</p>
<p>下面介绍Lucene中跳表的数据结构。</p>
<p><img data-src="/img/in-post/5-20200202102703006.png" alt=""></p>
<ul>
<li><p><strong>SkipLevelLength</strong></p>
<p>当前层的跳表（skipList）数据长度，在读取的时候用来确定往后读取的一段数据区间。</p>
</li>
<li><p><strong>SkipLevel</strong></p>
<p>SkipLevel描述了当前层中的所有跳表真实数据。</p>
<ul>
<li><p>SkipDatum</p>
<p>当前层中每个跳表信息按块处理为一个SkipDatum。</p>
<ul>
<li><p>DocSkip</p>
<p>描述了当前SkipDatum指向的文档号（实际值是当前文档号与上一个SkipDatum的文档差值）</p>
</li>
<li><p>DocFPSkip</p>
<p>每当处理128篇文档，在level=0的跳表中就会<strong>生成一个SkipDatum</strong>，而DocFPSkip指向的就是存储这128篇文档的PackedBlock的起始位置。</p>
</li>
<li><p>PosFPSkip</p>
<p>PosFPSkip<strong>指向.pos文件中一个位置</strong>。这个位置是PackedPosBlock（每128个position信息处理为一个PackedPosBlock）的起始位置。</p>
</li>
<li><p>PosBlockOffset</p>
<p>PosBlockOffset描述的是上一条说的PackedPosBlock中的一个偏移位置。</p>
</li>
<li><p>PayLength</p>
<p>PayLength描述的是在.pay文件中的payload的信息，这段payload的信息跟上一条中位置信息是对应的。</p>
</li>
<li><p>PayFPSkip</p>
<p>PayFPSkip指向在了.pay文档中一个PackedPayBlock（每128个offset信息处理为一个PackedPayBlock）的起始位置。</p>
</li>
<li><p>SkipChildLevelPointer</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="多个域的doc文件的数据结构"><a href="#多个域的doc文件的数据结构" class="headerlink" title="多个域的doc文件的数据结构"></a>多个域的doc文件的数据结构</h2><p><img data-src="/img/in-post/6-20200202105358310.png" alt=""></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>.pos .pay .doc .tim .tip文件都是通过读取内存倒排表的过程中一起生成的，在处理完每个term的信息并写入.pos .pay .doc文件后，开始生成.tim .tip文件，下面更新这部分内容。</p>
]]></content>
      <categories>
        <category>Lucene</category>
      </categories>
      <tags>
        <tag>Search</tag>
        <tag>Lucene</tag>
        <tag>索引文件</tag>
      </tags>
  </entry>
  <entry>
    <title>【索引文件】.tim、.tip文件</title>
    <url>/2020/02/01/lucene-indexfile-tim-tip/</url>
    <content><![CDATA[<p>这篇文章总结Lucene各个索引文件的作用和数据结构，为后续索引生成过程和存储分析打下基础。</p>
<h1 id="tim、tip文件"><a href="#tim、tip文件" class="headerlink" title="tim、tip文件"></a>tim、tip文件</h1><h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><p> <strong>.tim(Term Dicitionary)</strong>文件</p>
<ul>
<li><p>存放每个term的<strong>TermStats</strong>，TermStats记录了<strong>包含该term的文档数量，term在这些文档中的词频总和</strong>；</p>
</li>
<li><p>另外还存放了term的<strong>TermMetadata</strong>，TermMetadata记录了该term在.doc .pos .pay文件中的起始位置信息，即保存了指向这些文档的索引；</p>
</li>
<li><p>还<strong>存放了term的Suffix</strong>，对于有部分相同前缀值的term，只需存放这些term不相同的后缀值，即Suffix。</p>
</li>
<li><p>另外还存放term所在域的信息等其他信息。</p>
</li>
</ul>
<p><strong>.tip（Term index）文件</strong></p>
<ul>
<li>存放了指向tim文件的索引来实现随机访问tim文件中的信息。</li>
<li>并且.tip文件还能用来快速判断某个term是否存在。</li>
</ul>
<p>参考类：<strong>BlockTreeTermsWriter</strong></p>
<h2 id="tim文件的数据结构"><a href="#tim文件的数据结构" class="headerlink" title="tim文件的数据结构"></a>tim文件的数据结构</h2><p>图1</p>
<p><img data-src="/img/in-post/1-20200202114003284.png" alt=""></p>
<p>在tim文件中<strong>NodeBlock</strong>中包含了至少25个entries，每个entries中包含了一个term(或者由相同前缀的term集合)的相关数据，<strong>FieldSummary</strong>记录了域的一些信息。</p>
<p><img data-src="/img/in-post/2-20200202114117992.png" alt=""></p>
<p><strong>NodeBlock有两种类型：OuterNode、InnerNode</strong>。</p>
<p>这两种类型的NodeBlock在数据结构上有细微的差别，先介绍OuterNode的数据，然后再介绍他们之间的差别以及为什么NodeBlock需要两种类型。</p>
<p><img data-src="/img/in-post/3-20200202192304527.png" alt=""></p>
<h3 id="OuterNode"><a href="#OuterNode" class="headerlink" title="OuterNode"></a><strong>OuterNode</strong></h3><p>OuterNode包含了所有term的一些信息，在Lucene 7.5.0版本的源码中，<strong>按照term的大小顺序处理</strong>，并且用3个RAMOutputStream对象，即suffixWriter、statsWriter、bytesWriter来记录一个term的<strong>Suffix信息、TermStats信息、TermMetadata信息</strong>。在所有的term处理结束后，将3个RAMOutputStream对象中的内容写入到.tim文件中。</p>
<ul>
<li><p>EntryCount</p>
<p>描述当前OuterNode包含多少个entries，即包含了多少个term的信息。</p>
</li>
<li><p>SuffixLength、StatsLength、MetaLength</p>
<p>这三个值分别描述了所有term的Suffix、TermStats、TermMetadata在.tim文件中的数据长度，在读取.tim时用来确定读取Suffix、TermStats、TermMetadata的范围区间。</p>
</li>
<li><p><strong>Suffix</strong></p>
<p><img data-src="/img/in-post/4-20200202181659592.png" alt=""></p>
<ul>
<li><p>Lenth：term的后缀长度</p>
</li>
<li><p>SuffixValue</p>
<p>term的后缀值，之前得到按照term的大小顺序进行处理的，如果一批term具有相同的前缀并且这批term的个数超过25个，那么这批term会被处理为一个NodeBlock，并且SuffixValue只存储除去相同前缀的后缀部分。</p>
</li>
</ul>
</li>
<li><p>TermStats</p>
<p><img data-src="/img/in-post/5-20200202182220121.png" alt=""></p>
<ul>
<li><p>DocFreq</p>
<p>DocFreq描述了包含当前term的文档个数。</p>
</li>
<li><p>TotalTermFreq</p>
<p>TotalTermFreq描述了term在文档中出现的总数，实际存储了与DocFreq的差值，目的是尽可能压缩存储，即使用差值存储。</p>
</li>
</ul>
</li>
<li><p>TermMetadata</p>
<p><img data-src="/img/in-post/6-20200202182624299.png" alt=""></p>
<ul>
<li><p>SingletonDocID</p>
<p>如果只有一篇文档包含当前term，那么SingletonDocID被赋值这篇文档号，如果不止一篇文档包含当前term，那么SingletonDocID不会写入到.tim文件中。</p>
</li>
<li><p>LastPosBlockOffset</p>
<p>如果term的词频大于BLOCK_SIZE即大于128个，那么在.pos文件中就会生成一个block，LastPosBlockOffset记录最后一个block结束位置，通过这个位置就能快速定位到term剩余的position信息，并且这些position信息的个数肯定是不满128个，可以看Lucene50PostingsWriter.java中finishTerm()的方法。</p>
</li>
<li><p>SkipOffset</p>
<p>用来描述当前term信息在.doc文件中跳表信息的起始位置。</p>
</li>
<li><p>DocStartFP</p>
<p>是当前term信息在.doc文件中的起始位置。</p>
</li>
<li><p>PosStartFP</p>
<p>当前term信息在.pos文件中的起始位置。</p>
</li>
<li><p>PayStartFP</p>
<p>当前term信息在.pay文件中的起始位置。</p>
</li>
</ul>
</li>
</ul>
<h3 id="InnerNode"><a href="#InnerNode" class="headerlink" title="InnerNode"></a><strong>InnerNode</strong></h3><p>给出一个场景，需要处理的term值为下面的情况：</p>
<p><img data-src="/img/in-post/7-20200202191811441.png" alt=""></p>
<p>在处理这一批的每一个term，将具有相同前缀”ab”的，并且个数超过25个的term先处理为一个OuterNode，接着前缀值”ab”作为一个term与剩余的term处理为一个InnerNode。如图：</p>
<p><img data-src="/img/in-post/8-20200202192014851.png" alt=""></p>
<p>由于InnerNode中的前缀为“ab”的所有term的Suffix、TermStats、TermMetadata已经存在.tim文件中，所有在InnerNode只要记录在.tim文件中的便宜位置，即上图中的红色标注的index。所以通过上图InnerNode数据结构与OuterNode数据结构的区别。</p>
<p><img data-src="/img/in-post/3-20200202192304527.png" alt=""></p>
<h3 id="FieldSummary"><a href="#FieldSummary" class="headerlink" title="FieldSummary"></a><strong>FieldSummary</strong></h3><p>图1只是单个域的.tim文件数据结构，下面是多个域的.tim数据结构：</p>
<p>图9 </p>
<p><img data-src="/img/in-post/9-20200202194536482.png" alt=""></p>
<p>下面是FieldSummary的数据结构。</p>
<p>图10</p>
<p><img data-src="/img/in-post/10.png" alt=""></p>
<p>图10中Field的个数与图9中Field一一对应。</p>
<ul>
<li><p>NumFields：描述.tim文件中有多少种域。</p>
</li>
<li><p>Field</p>
<ul>
<li><p>FieldNumber</p>
<p>记录当前域的编号（唯一），从0开始递增。数值越小说明该域更早地被添加进索引。</p>
</li>
</ul>
<ul>
<li><p>NumTerms</p>
<p>记录当前域中有多少种term。</p>
</li>
<li><p>RootCodeLength</p>
<p>描述了当前域中的term的FST数据的长度</p>
</li>
<li><p>RootCodeValue</p>
<p>描述当前域中的term的FST数据</p>
</li>
<li><p>SumTotalTermFreq</p>
<p>描述当前域中所有term在文档中的总词频。</p>
</li>
<li><p>SumDocFreq</p>
<p>描述了包含当前域中的所有term的文档数量。</p>
</li>
<li><p>DocCount</p>
<p>描述了有多少篇文档包含了当前域。</p>
</li>
<li><p>LongSize</p>
<p>只可能是1，2，3三种：</p>
<p>1：说明当前域只存储了doc、frequency</p>
<p>2：说明当前域存储了doc、frequency、positions</p>
<p>3：说明当前域存储了doc、frequency、position、offset</p>
</li>
<li><p>MinTerm</p>
<p>当前域中的最小的term</p>
</li>
<li><p>MaxTerm</p>
<p>当前域中的最大的term</p>
</li>
</ul>
</li>
</ul>
<h3 id="DirOffset"><a href="#DirOffset" class="headerlink" title="DirOffset"></a><strong>DirOffset</strong></h3><p>记录FieldSummary的信息在.tim文件中的起始位置。</p>
<h2 id="tip文件的数据结构"><a href="#tip文件的数据结构" class="headerlink" title="tip文件的数据结构"></a>tip文件的数据结构</h2><p><img data-src="/img/in-post/11.png" alt=""></p>
<h3 id="FSTIndex"><a href="#FSTIndex" class="headerlink" title="FSTIndex"></a>FSTIndex</h3><p>FSTIndex记录了NodeBlock在.tim文件中的一些信息，比如fp为NodeBlock在.tim文件中的起始位置，hasTerms描述NodeBlock中是否包含pendingTerm对象，isFloor表示是否为floor block，然后将这些信息用FST算法存储。</p>
<h3 id="IndexStartFP"><a href="#IndexStartFP" class="headerlink" title="IndexStartFP"></a>IndexStartFP</h3><p>描述了当前FSTIndex信息在.tip中的起始位置。</p>
<h3 id="DirOffset-1"><a href="#DirOffset-1" class="headerlink" title="DirOffset"></a>DirOffset</h3><p>描述了第一个IndexStartFP在.tip中的位置。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>tim 、tip文件是索引文件中最复杂的实现，如果要阅读这部分源码，必须先熟悉<a href="https://www.amazingkoala.com.cn/Lucene/yasuocunchu/2019/0220/35.html" target="_blank" rel="noopener"><strong>FST算法</strong></a>，并且源码<code>BlockTreeTermsWriter</code>中pushTerm(ByteRef text)方法可以简单理解成为她就是为了统计相同前缀的term的个数是否到达25(minItemsInBlock)。</p>
<p>另外tip文件的数据结构没有详细介绍，是因为这部分与FST紧密关联，理解了FST算法就自然知道<strong>FSTIndex</strong>。</p>
]]></content>
      <categories>
        <category>Lucene</category>
      </categories>
      <tags>
        <tag>Search</tag>
        <tag>Lucene</tag>
        <tag>索引文件</tag>
      </tags>
  </entry>
  <entry>
    <title>【索引文件】.nvd、.nvm文件</title>
    <url>/2020/01/31/lucene-indexfile-nvd-nvm/</url>
    <content><![CDATA[<p>这篇文章总结Lucene各个索引文件的作用和数据结构，为后续索引生成过程和存储分析打下基础。</p>
<h1 id="nvd、nvm文件"><a href="#nvd、nvm文件" class="headerlink" title="nvd、nvm文件"></a>nvd、nvm文件</h1><h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><p>nvd&amp;&amp;nvm用来存储域的标准化值（normalization values），这两个索引文件记录了每一篇文档中每一种域的标准化索引信息。在Lucene 7.5.0中，标准化值的计算实际就是统计一篇文档中某个域的域值，这个域值经过分词器处理后生成的term的个数，最后将term的个数通过intToByte4()的方法编码为一个byte类型的值。</p>
<p>标准化的过程不作介绍，可以查看BM25Similarity的computeNorm()方法。我们可以自定义自己的Similarity来实现定制化的计算域的标准化值的逻辑。</p>
<p><img data-src="/img/in-post/1-20200201134606149.png" alt=""></p>
<h2 id="nvd的数据结构"><a href="#nvd的数据结构" class="headerlink" title="nvd的数据结构"></a>nvd的数据结构</h2><p><img data-src="/img/in-post/2.png" alt=""></p>
<ul>
<li><p><strong>FieldData</strong></p>
<p>nvd文件在索引阶段按照添加域的顺序分块地存储每一种域的信息，FieldData描述了一种域的所有信息。</p>
<p>在上面的例子中，一共有3个FieldData块，分别描述”content”、”author”、”attachment”三种域的信息。</p>
<ul>
<li><p><strong>DocsWithFieldData</strong></p>
<p><img data-src="/img/in-post/3.png" alt=""></p>
<p>DocsWithFieldData的数据结构根据包含当前域的文档个数numDocsWithValue分三种情况：</p>
<ul>
<li><p>numDocsWithValue == 0<br>DocWithFieldData无数据，通过nvm文件中存放固定值来描述当前情况。</p>
</li>
<li><p>numDocsWithValue == maxDoc</p>
<p>maxDoc表示当前处理的文档个数，这种情况说明所有文档都包含当前域。<br>DocsWithFieldData无数据，通过nvm文件中同样存放固定值来描述当前情况。<br>在本文中,域”author”属于此情况。</p>
</li>
<li><p>numDocsWithValue &lt; maxDoc</p>
<p>这种情况说明并不是所有的文档都包含当前域，所以需要存储所有包含当前域的文档号。</p>
<p>使用IndexedDISI类来实现对文档号docID的存储，IndexedDISI类随后文章中再总结。</p>
<p>在索引阶段不同的添加document的方式会有不同数据结构的nvd文件产生，导致生成索引跟查询的性能各不相同。 在本文的例子中，域”content”、”attachment”的DocsWithFieldData属于当前情况。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li><strong>NormsData</strong></li>
</ul>
<p>  <img data-src="/img/in-post/4.png" alt=""></p>
<ul>
<li>Value</li>
</ul>
<pre><code>Value为当前域在每一篇文档中的标准化值</code></pre><h2 id="nvm的数据结构"><a href="#nvm的数据结构" class="headerlink" title="nvm的数据结构"></a>nvm的数据结构</h2><p><img data-src="/img/in-post/5.png" alt=""></p>
<ul>
<li><p><strong>FieldNumber</strong></p>
<p>域的编号，用来唯一标识一种域</p>
</li>
</ul>
<ul>
<li><p><strong>DocsWithFieldAddress &amp;&amp; DocsWithFieldLength</strong></p>
<p>如果numDocWithValue == maxDoc 或者 numDocWithValue == 0 , 那么DocWithFieldAddress跟DocsWithFieldLength会被设置为固定值。否则这两个值作为索引去映射nvd中的一块数据区域。</p>
</li>
</ul>
<p>  <img data-src="/img/in-post/6.png" alt=""></p>
<ul>
<li><p><strong>NumDocsWithField</strong></p>
<p>NumDocsWithField描述了包含当前域的文档个数。</p>
</li>
</ul>
<ul>
<li><p><strong>BytesPernNorm</strong></p>
<p>找出当前域在所有所属文档中的最大和最小的两个标准化值来判断存储一个标准化值最大需要的字节数，这里还是处于优化索引空间目的。由于最小值可能是负数，所以不能仅仅靠最大值判断标准化值需要的字节数。比如最小值min为-130（需要2个字节），最大值max 5(需要1个字节)，那测试需要根据min来决定需要字节的个数。</p>
</li>
</ul>
<ul>
<li><p><strong>NormsAddress</strong></p>
<p>NormsAddress作为索引映射nvd中一块数据区域，这块数据区域即当前域所在文档中的标准化值。</p>
</li>
</ul>
<p>  <img data-src="/img/in-post/7.png" alt=""></p>
<h2 id="nvm和nvd的映射关系图"><a href="#nvm和nvd的映射关系图" class="headerlink" title="nvm和nvd的映射关系图"></a>nvm和nvd的映射关系图</h2><p><img data-src="/img/in-post/8.png" alt=""></p>
<h2 id="集合图"><a href="#集合图" class="headerlink" title="集合图"></a>集合图</h2><p>把数据结构放在一起就是下面这样：</p>
<p><img data-src="http://www.amazingkoala.com.cn/uploads/lucene/%E7%B4%A2%E5%BC%95%E6%96%87%E4%BB%B6/pos&&pay/5.png" alt=""></p>
]]></content>
      <categories>
        <category>Lucene</category>
      </categories>
      <tags>
        <tag>Search</tag>
        <tag>Lucene</tag>
        <tag>索引文件</tag>
      </tags>
  </entry>
  <entry>
    <title>【索引文件】.pos、.pay文件</title>
    <url>/2020/01/31/lucene-indexfile-pos-pay/</url>
    <content><![CDATA[<p>这篇文章总结Lucene各个索引文件的作用和数据结构，为后续索引生成过程和存储分析打下基础。</p>
<h1 id="pos、pay文件"><a href="#pos、pay文件" class="headerlink" title="pos、pay文件"></a>pos、pay文件</h1><h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><p><strong>position</strong>在Lucene中描述的是一个term在一篇文档中的位置，并且存在一个或多个position。</p>
<p><strong>payload</strong>是一个自定义的元数据来描述term的某个属性，term在一篇文章中的多个位置可以一一对应多个payload，也可以只有部分位置带有payload。</p>
<p><strong>offset</strong>是一对整数值(a pair of integers)，即startOffset跟endOffset，它们分别描述了term的第一个字符跟最后一个在文档中的位置。</p>
<p>每一个term在所有文档中的position、payload、offset信息在IndexWriter.addDocument()的过程中计算出来，在内存在生成一张<strong>倒排表</strong>，最终持久化到磁盘时，通过读取倒排表，将<strong>position信息写入到.pos</strong>文件中，将<strong>payload、offset信息写入到.pay</strong>文件中。</p>
<p>下面总结.pos文件和.pay的数据结构，关于.pos、.pay的生成过程，在后续文章总结。</p>
<h2 id="pay文件的数据结构"><a href="#pay文件的数据结构" class="headerlink" title="pay文件的数据结构"></a>pay文件的数据结构</h2><p><img data-src="/img/in-post/1-20200201154718749.png" alt=""></p>
<p>在.pay文件中，TermPlayload、TermOffset分别记录一个term的payload、offset信息。</p>
<h3 id="TermPayload"><a href="#TermPayload" class="headerlink" title="TermPayload"></a>TermPayload</h3><p><img data-src="/img/in-post/2-20200201155325824.png" alt=""></p>
<ul>
<li><p><strong>PackedPayBlock</strong></p>
<p>每次处理一个term的128个position信息，就会将对应的128个payload信息（不一定每个position都会对应一个payload）处理为一个PackedPayBlock。即除了最后一个PackedPayBlock，其他PackedPayBlock中都包含了当前term的128个payload信息。</p>
<ul>
<li><p>PackedPayLengthBlock</p>
<p>PackedPayLengthBlock存放了128个payload的长度数据，并且使用了PackedInts进行了压缩。这里注意由于每一个payload的长度无法保证递增，只能使用<a href="https://www.amazingkoala.com.cn/Lucene/yasuocunchu/2019/1217/118.html" target="_blank" rel="noopener">!PackedInts</a>存储原始数据</p>
</li>
<li><p>SumPayLength</p>
<p>SumPayLength存放了这128个payload的数据长度（字节数），在读取.pay文件用来确定128个payload的真实数据</p>
</li>
<li><p>PayData</p>
<p>PayData中存放了128个payload的真实数据。</p>
</li>
</ul>
</li>
</ul>
<h3 id="TermOffset"><a href="#TermOffset" class="headerlink" title="TermOffset"></a>TermOffset</h3><p><img data-src="/img/in-post/3-20200201160951731.png" alt=""></p>
<ul>
<li><p><strong>PackedOffsetBlock</strong></p>
<p>跟TermPayload一样的是，都是每次处理一个term的128个position信息后，就会将对应的128个offset信息处理为一个block。</p>
<ul>
<li><p>PackedOffsetStartDeltaBlock</p>
<p>offset是一对整数值(a pair of intergers): startOffset和endOffset，分别描述第一个字符和最后一个字符在文档中位置。</p>
<p>PackedOffsetStartDeltaBlock存放128个offset的startOffset值，并且使用了PackedInts进行压缩存储。由于这128个startOffset是一个递增的值，所以实际存放了相邻两个offset的startOffset的差值。</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>PackedOffsetLengthBlock</p>
<p>PackedOffsetLengthBlock存放了128个offset的startOffset跟endOffset差值，同样使用PackedInts压缩存储。</p>
</li>
</ul>
<h2 id="pos文件的数据结构"><a href="#pos文件的数据结构" class="headerlink" title="pos文件的数据结构"></a>pos文件的数据结构</h2><p><img data-src="/img/in-post/4-20200201162107840.png" alt=""></p>
<p>在.pos文件中，TermPosition记录一个term的position信息。</p>
<h3 id="TermPosition"><a href="#TermPosition" class="headerlink" title="TermPosition"></a>TermPosition</h3><p><img data-src="/img/in-post/5-20200201162351662.png" alt=""></p>
<ul>
<li><p><strong>PackedPosBlock</strong></p>
<p>每次处理一个term的128个position信息，就会将这些position处理为一个PackedPosBlock。</p>
<ul>
<li>PackedPosDeltaBlock<br>PackedPosDeltaBlock存放了128个位置信息，计算相邻两个position的差距后，利用Packedints压缩存储。</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>VIntBlocks &amp;&amp; VIntBlock</strong></p>
<p>如果position的个数不足128个，那么将每一个position处理为一个VIntBlock。（比如说某个term有200个position，那么前128个position处理为一个PackedPosBlock，剩余72个position处理为72个VIntBlock）。</p>
<ul>
<li><p>PositionDelta</p>
<p>term的position信息，这是一个差值。PositionDelta的最后一位用来标识当前position是否有payload信息。</p>
</li>
</ul>
</li>
</ul>
<pre><code>* PayloadLength

  当前position对应的payload信息的长度，在读取.pos时，用来确定往后读取的一个字节区间。

* PayloadData

  当前position对应的payload真实数据。</code></pre><ul>
<li><p>OffsetDelta</p>
<p>当前position对应的offset的startOffset值，同样是个差值。</p>
</li>
<li><p>OffsetLength</p>
<p>当前position对应的offset的endOffset与startOffset的差值。</p>
</li>
</ul>
<h2 id="多个域的pay文件的数据结构"><a href="#多个域的pay文件的数据结构" class="headerlink" title="多个域的pay文件的数据结构"></a>多个域的pay文件的数据结构</h2><p><img data-src="/img/in-post/6-20200201164502459.png" alt=""></p>
<h2 id="多个域的pos文件的数据结构"><a href="#多个域的pos文件的数据结构" class="headerlink" title="多个域的pos文件的数据结构"></a>多个域的pos文件的数据结构</h2><p><img data-src="/img/in-post/7-20200201164528840.png" alt=""></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>.pos 、.pay、.doc、.tim 、.tip文件都是在<a href="https://www.amazingkoala.com.cn/Lucene/Index/2019/0716/74.html" target="_blank" rel="noopener">flush</a>阶段通过读取倒排表一起生成的，另外.doc跟.pos、.pay文件还有映射关系，后续总结.doc文件会涉及。</p>
]]></content>
      <categories>
        <category>Lucene</category>
      </categories>
      <tags>
        <tag>Search</tag>
        <tag>Lucene</tag>
        <tag>索引文件</tag>
      </tags>
  </entry>
  <entry>
    <title>【并发容器和框架】三、Java线程池的实现原理和使用</title>
    <url>/2019/12/23/java-concurrency-container-ThreadPool/</url>
    <content><![CDATA[<h1 id="1-Java线程池的实现原理"><a href="#1-Java线程池的实现原理" class="headerlink" title="1. Java线程池的实现原理"></a>1. Java线程池的实现原理</h1><p>线程池是日常开发中使用最多的并发框架（虽然在高并发场景下有的线程池要慎用），几乎所有需要异步或者并发的执行任务的程序都可以使用线程池。总结下，可以带来3个好处。</p>
<p>第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。</p>
<p>第二：提高响应速度。当任务到达时，任务可以不需要等线程创建就能立即执行。</p>
<p>第三：提高线程的可管理性。无限制创建线程会消耗系统资源、降低系统稳定性，使用线程池可以进行统一分配、调优和监控。</p>
<h2 id="1-1-线程池的实现原理"><a href="#1-1-线程池的实现原理" class="headerlink" title="1.1 线程池的实现原理"></a>1.1 线程池的实现原理</h2><p>当往线程池提交一个任务之后，线程池是如何处理这个任务的？下面来看线程池主要处理流程。</p>
<h3 id="1-1-1-主要处理流程"><a href="#1-1-1-主要处理流程" class="headerlink" title="1.1.1 主要处理流程"></a>1.1.1 主要处理流程</h3><p><img data-src="/img/in-post/1574908942078.png" alt=""></p>
<p>当提交一个新任务到线程池时，线程池的处理流程如下：</p>
<ul>
<li>1）线程池判断核心线程你的线程是否都在执行任务。如果不是，则创建一个新的工作线程来执行任务。如果核心线程池你的线程池都在执行任务，则进入下个流程。</li>
<li>2）线程池判断工作队列是否已满。如果工作队列没有满，这将新提交的任务存在这个工作队列里如果队列满了，则进入下一个流程。</li>
<li>3）线程池判断线程是否都处于工作状态。如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务。</li>
</ul>
<h3 id="1-1-2-execute执行流程"><a href="#1-1-2-execute执行流程" class="headerlink" title="1.1.2 execute执行流程"></a>1.1.2 execute执行流程</h3><p><img data-src="/img/in-post/1574910321047.png" alt=""></p>
<p>ThreadPoolExectuor执行execute方法分为4种情况。</p>
<ul>
<li>1）如果当前运行的线程&lt;corePoolSize，则创建新线程来执行任务（<strong>这一步将获取全局锁</strong>）。</li>
<li>2）如果运行的线程&gt;=corePoolSize，则将任务加入BlockingQueue。</li>
<li>3）如果BlockingQueue已满，则创建新的线程来处理任务（<strong>这一步需要获取全局锁</strong>）。</li>
<li>4）如果创建新线程将使当前运行的线程超出maxnumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。</li>
</ul>
<p>ThreadPoolExecutor采取上述步骤，是为在执行execute方法时，尽可能避免获取全局锁（严重的可伸缩瓶颈）。在ThreadPoolExector完成预热之后（当前运行的线程数大于等于corePoolSize），几乎所有的execute()方法都是执行步骤2，而步骤2不需要获取全局锁。</p>
<h3 id="1-1-3-execute源码分析"><a href="#1-1-3-execute源码分析" class="headerlink" title="1.1.3 execute源码分析"></a>1.1.3 execute源码分析</h3><pre><code class="java">    public void execute(Runnable command) {
        if (command == null)
            throw new NullPointerException();
        /*
         * Proceed in 3 steps:
         *
         * 1. If fewer than corePoolSize threads are running, try to
         * start a new thread with the given command as its first
         * task.  The call to addWorker atomically checks runState and
         * workerCount, and so prevents false alarms that would add
         * threads when it shouldn&#39;t, by returning false.
         *
         * 2. If a task can be successfully queued, then we still need
         * to double-check whether we should have added a thread
         * (because existing ones died since last checking) or that
         * the pool shut down since entry into this method. So we
         * recheck state and if necessary roll back the enqueuing if
         * stopped, or start a new thread if there are none.
         *
         * 3. If we cannot queue task, then we try to add a new
         * thread.  If it fails, we know we are shut down or saturated
         * and so reject the task.
         */
        int c = ctl.get();
      //1.
        if (workerCountOf(c) &lt; corePoolSize) {
            if (addWorker(command, true))
                return;
            c = ctl.get();
        }
        //2.
        if (isRunning(c) &amp;&amp; workQueue.offer(command)) {
            int recheck = ctl.get();
            if (! isRunning(recheck) &amp;&amp; remove(command))
                reject(command);
            else if (workerCountOf(recheck) == 0)
                addWorker(null, false);
        }
      //3.
        else if (!addWorker(command, false))
            reject(command);
    }</code></pre>
<ol>
<li><p>获取当前工作线程数，判断是否小于corePoolSize，如果小于corePoolSize，就尝试创建并运行线程。ctl是AtomicInteger类型，保存当前线程的状态。通过ctl.get()获取当前运行状态的线程数。ctl初始化：</p>
<p><code>private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));</code></p>
</li>
<li><p>如果当前工作线程数大于corePoolSize或者线程创建失败，就将当前任务加入工作队列。</p>
</li>
<li><p>如果当前线程池不处于运行中或任务无法放入线程池，并且当前线程数量小于最大允许的线程数量（addWorker中判断），则创建一个线程执行任务。否则抛出运行RejectedExecutionHandler。</p>
</li>
</ol>
<p>尝试创建并运行任务的核心主要是<code>addWorker</code>方法，该方法的源码如下：</p>
<pre><code class="java"> /**
     * Checks if a new worker can be added with respect to current
     * pool state and the given bound (either core or maximum). If so,
     * the worker count is adjusted accordingly, and, if possible, a
     * new worker is created and started, running firstTask as its
     * first task. This method returns false if the pool is stopped or
     * eligible to shut down. It also returns false if the thread
     * factory fails to create a thread when asked.  If the thread
     * creation fails, either due to the thread factory returning
     * null, or due to an exception (typically OutOfMemoryError in
     * Thread.start()), we roll back cleanly.
     *
     * @param firstTask the task the new thread should run first (or
     * null if none). Workers are created with an initial first task
     * (in method execute()) to bypass queuing when there are fewer
     * than corePoolSize threads (in which case we always start one),
     * or when the queue is full (in which case we must bypass queue).
     * Initially idle threads are usually created via
     * prestartCoreThread or to replace other dying workers.
     *
     * @param core if true use corePoolSize as bound, else
     * maximumPoolSize. (A boolean indicator is used here rather than a
     * value to ensure reads of fresh values after checking other pool
     * state).
     * @return true if successful
     */
    private boolean addWorker(Runnable firstTask, boolean core) {
        retry://1.CAS检查线程池
        for (;;) {//1.1CAS循环检查当前线程池运行状态
            int c = ctl.get();
            int rs = runStateOf(c);

            // Check if queue empty only if necessary.
            if (rs &gt;= SHUTDOWN &amp;&amp;
                ! (rs == SHUTDOWN &amp;&amp;
                   firstTask == null &amp;&amp;
                   ! workQueue.isEmpty()))
                return false;

            for (;;) {//1.2 检查当前线程池任务线程是否超过线程池大小(基本大小或者最大大小)
                int wc = workerCountOf(c);
                if (wc &gt;= CAPACITY ||
                    wc &gt;= (core ? corePoolSize : maximumPoolSize))
                    return false;
                if (compareAndIncrementWorkerCount(c))//1.3检查当前线程池状态原子性
                    break retry;
                c = ctl.get();  // Re-read ctl
                if (runStateOf(c) != rs)//1.4 double check线程池运行状态是否被修改过
                    continue retry;
                // else CAS failed due to workerCount change; retry inner loop
            }
        }

        boolean workerStarted = false;
        boolean workerAdded = false;
        Worker w = null;//2.尝试创建工作线程并启动
        try {
            w = new Worker(firstTask);//2.1 创建工作线程，包装了Thread
            final Thread t = w.thread;
            if (t != null) {
                final ReentrantLock mainLock = this.mainLock;//2.2 获取线程池全局锁，并加入workers集合
                mainLock.lock();
                try {
                    // Recheck while holding lock.
                    // Back out on ThreadFactory failure or if
                    // shut down before lock acquired.
                    int rs = runStateOf(ctl.get());

                    if (rs &lt; SHUTDOWN ||
                        (rs == SHUTDOWN &amp;&amp; firstTask == null)) {
                        if (t.isAlive()) // precheck that t is startable
                            throw new IllegalThreadStateException();
                        workers.add(w);
                        int s = workers.size();
                        if (s &gt; largestPoolSize)
                            largestPoolSize = s;
                        workerAdded = true;
                    }
                } finally {
                    mainLock.unlock();
                }
                if (workerAdded) {
                    t.start();
                    workerStarted = true;
                }
            }
        } finally {
            if (! workerStarted)
                addWorkerFailed(w);
        }
        return workerStarted;
    }</code></pre>
<p><strong>工作线程</strong>：线程池创建线程时，会将线程封装成工作线程Worker，Worker在执行完任务后，还会循环获取工作队列里的任务来执行。可以从Woker的源码run方法中看出：</p>
<pre><code class="java">    public void run() {
        runWorker(this);
    }
    /**
     * Main worker run loop.  Repeatedly gets tasks from queue and
     * executes them, while coping with a number of issues:
     *
     * 1. We may start out with an initial task, in which case we
     * don&#39;t need to get the first one. Otherwise, as long as pool is
     * running, we get tasks from getTask. If it returns null then the
     * worker exits due to changed pool state or configuration
     * parameters.  Other exits result from exception throws in
     * external code, in which case completedAbruptly holds, which
     * usually leads processWorkerExit to replace this thread.
     *
     * 2. Before running any task, the lock is acquired to prevent
     * other pool interrupts while the task is executing, and then we
     * ensure that unless pool is stopping, this thread does not have
     * its interrupt set.
     *
     * 3. Each task run is preceded by a call to beforeExecute, which
     * might throw an exception, in which case we cause thread to die
     * (breaking loop with completedAbruptly true) without processing
     * the task.
     *
     * 4. Assuming beforeExecute completes normally, we run the task,
     * gathering any of its thrown exceptions to send to afterExecute.
     * We separately handle RuntimeException, Error (both of which the
     * specs guarantee that we trap) and arbitrary Throwables.
     * Because we cannot rethrow Throwables within Runnable.run, we
     * wrap them within Errors on the way out (to the thread&#39;s
     * UncaughtExceptionHandler).  Any thrown exception also
     * conservatively causes thread to die.
     *
     * 5. After task.run completes, we call afterExecute, which may
     * also throw an exception, which will also cause thread to
     * die. According to JLS Sec 14.20, this exception is the one that
     * will be in effect even if task.run throws.
     *
     * The net effect of the exception mechanics is that afterExecute
     * and the thread&#39;s UncaughtExceptionHandler have as accurate
     * information as we can provide about any problems encountered by
     * user code.
     *
     * @param w the worker
     */
    final void runWorker(Worker w) {
        Thread wt = Thread.currentThread();
        Runnable task = w.firstTask;
        w.firstTask = null;
        w.unlock(); // allow interrupts
        boolean completedAbruptly = true;
        try {
            while (task != null || (task = getTask()) != null) {
                w.lock();
                // If pool is stopping, ensure thread is interrupted;
                // if not, ensure thread is not interrupted.  This
                // requires a recheck in second case to deal with
                // shutdownNow race while clearing interrupt
                if ((runStateAtLeast(ctl.get(), STOP) ||
                     (Thread.interrupted() &amp;&amp;
                      runStateAtLeast(ctl.get(), STOP))) &amp;&amp;
                    !wt.isInterrupted())
                    wt.interrupt();
                try {
                    beforeExecute(wt, task);
                    Throwable thrown = null;
                    try {
                        task.run();
                    } catch (RuntimeException x) {
                        thrown = x; throw x;
                    } catch (Error x) {
                        thrown = x; throw x;
                    } catch (Throwable x) {
                        thrown = x; throw new Error(x);
                    } finally {
                        afterExecute(task, thrown);
                    }
                } finally {
                    task = null;
                    w.completedTasks++;
                    w.unlock();
                }
            }
            completedAbruptly = false;
        } finally {
            processWorkerExit(w, completedAbruptly);
        }
    }

 /**
     * Performs blocking or timed wait for a task, depending on
     * current configuration settings, or returns null if this worker
     * must exit because of any of:
     * 1. There are more than maximumPoolSize workers (due to
     *    a call to setMaximumPoolSize).
     * 2. The pool is stopped.
     * 3. The pool is shutdown and the queue is empty.
     * 4. This worker timed out waiting for a task, and timed-out
     *    workers are subject to termination (that is,
     *    {ode allowCoreThreadTimeOut || workerCount &gt; corePoolSize})
     *    both before and after the timed wait, and if the queue is
     *    non-empty, this worker is not the last thread in the pool.
     *
     * @return task, or null if the worker must exit, in which case
     *         workerCount is decremented
     */
    private Runnable getTask() {
        boolean timedOut = false; // Did the last poll() time out?

        for (;;) {
            int c = ctl.get();
            int rs = runStateOf(c);

            // Check if queue empty only if necessary.
            if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) {
                decrementWorkerCount();
                return null;
            }

            int wc = workerCountOf(c);

            // Are workers subject to culling?
            boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize;

            if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut))
                &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) {
                if (compareAndDecrementWorkerCount(c))
                    return null;
                continue;
            }

            try {
                Runnable r = timed ?
                    workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) :
                    workQueue.take();
                if (r != null)
                    return r;
                timedOut = true;
            } catch (InterruptedException retry) {
                timedOut = false;
            }
        }
    }</code></pre>
<h1 id="2-线程池的使用"><a href="#2-线程池的使用" class="headerlink" title="2. 线程池的使用"></a>2. 线程池的使用</h1><h2 id="2-1-线程池的创建"><a href="#2-1-线程池的创建" class="headerlink" title="2.1 线程池的创建"></a>2.1 线程池的创建</h2><ul>
<li>多参数详细的构造方法：</li>
</ul>
<pre><code class="java">    public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue&lt;Runnable&gt; workQueue,
                              ThreadFactory threadFactory,
                              RejectedExecutionHandler handler) {
        if (corePoolSize &lt; 0 ||
            maximumPoolSize &lt;= 0 ||
            maximumPoolSize &lt; corePoolSize ||
            keepAliveTime &lt; 0)
            throw new IllegalArgumentException();
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.acc = System.getSecurityManager() == null ?
                null :
                AccessController.getContext();
        this.corePoolSize = corePoolSize;
        this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
    }</code></pre>
<p>另外还有分别提供默认ThreadFactory与RejectedExecutionHandler的三个构造方法；</p>
<p>默认ThreadFactory为DefaultThreadFactory</p>
<p>默认RejectedExecutionHandler为AbortPolicy</p>
<p><strong>参数解释：</strong></p>
<ul>
<li><p>corePoolSize（线程池的基本大小）</p>
<p>当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于线程池基本大小时就不再创建。</p>
</li>
<li><p>runnableTaskQueue（任务队列）</p>
<p>用于保存等待执行的任务的阻塞队列。可以选择：ArrayBlockingQueue、LinkedBlockingQueue、SynchronousQueue、PriorityBlockingQueue。</p>
</li>
<li><p>maximumPoolSize（线程池最大数量）</p>
<p>如果队列满了，并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。注：如果使用了无界任务队列这个参数就没什么用了（因为不可能到达这个参数的上限，全都在队列中排队）。</p>
</li>
<li><p>ThreadFactory（自定义创建线程的工厂）</p>
<p>用于设置创建线程的工厂。干预创建线程的过程，比如可以给每个创建的线程设置更有意义的名字。</p>
</li>
<li><p>RejectedExecutionHandler（饱和策略）</p>
<p>当队列和线程池都满了，说明线程池处于饱和状态，那么必须采取一种策略处理提交的新任务。默认实现策略是AbortPolicy。JDK 1.8依然用的是下面的4钟策略。</p>
<ul>
<li><p>AbortPolicy（默认） ：直接抛出异常</p>
<p>AbortPolicy执行策略的方法</p>
<pre><code class="java">        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
            throw new RejectedExecutionException(&quot;Task &quot; + r.toString() +
                                                 &quot; rejected from &quot; +
                                                 e.toString());
        }</code></pre>
</li>
<li><p>DiscardPolicy：不处理，丢弃掉</p>
<p>空实现</p>
<pre><code class="java">        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
        }</code></pre>
</li>
<li><p>DiscardOldestPolicy：丢弃队里里最近的一个任务，并执行当前任务</p>
<pre><code class="java">        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
            if (!e.isShutdown()) {
                e.getQueue().poll();
                e.execute(r);
            }
        }</code></pre>
</li>
<li><p>CallerRunsPolicy：只用调用者所在线程来运行任务</p>
<pre><code class="java">        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
            if (!e.isShutdown()) {
                r.run();
            }
        }</code></pre>
</li>
<li><p>当然也可以根据自己应用的场景去实现RejectedExecutionHandler接口自定义策略，比如笔者的项目中曾经实现这个策略用来控制客户端调用反压，用来限流控制。</p>
</li>
</ul>
</li>
<li><p>keepAliveTime(线程活动保持时间)</p>
<p>线程池的工作线程空闲后，保持存活的时间。所以如果任务很多并且每个任务执行的时间比较短，可以调大时间，提高线程的利用率。</p>
</li>
<li><p>TimeUnit(线程活动保持的时间单位)</p>
<p>DAYS、HOURS、分钟(MINUTES)、毫秒(MILLSECONDS)、微妙(MICROSECONDS，千分之一毫秒)和纳秒（NANOSECONDS，千分之一微秒）。</p>
</li>
</ul>
<h2 id="2-2-向线程池提交任务"><a href="#2-2-向线程池提交任务" class="headerlink" title="2.2 向线程池提交任务"></a>2.2 向线程池提交任务</h2><p><img data-src="/img/in-post/image-20191221231910407.png" alt=""></p>
<p><img data-src="/img/in-post/image-20191221232316027.png" alt=""></p>
<p>可以使用两个方法向线程池提交任务，分别是<strong>execute和submit方法</strong>。</p>
<p>submit可以有返回值，返回Future<T>,可以通过Future对象判断任务是否执行完成，并且可以通过future带超时或者不带超时的get()方法阻塞当前一段时间后立即返回。带超时的get()一旦超时会立即返回，可能任务还没执行完。</p>
<h2 id="2-3-关闭线程池"><a href="#2-3-关闭线程池" class="headerlink" title="2.3 关闭线程池"></a>2.3 关闭线程池</h2><p>调用线程池的shutdown或者shutdownNow方法来关闭线程池。</p>
<pre><code class="java">    /**
     * Initiates an orderly shutdown in which previously submitted
     * tasks are executed, but no new tasks will be accepted.
     * Invocation has no additional effect if already shut down.
     *
     * &lt;p&gt;This method does not wait for previously submitted tasks to
     * complete execution.  Use {@link #awaitTermination awaitTermination}
     * to do that.
     *
     * hrows SecurityException {@inheritDoc}
     */
    public void shutdown() {
        final ReentrantLock mainLock = this.mainLock;
        mainLock.lock();
        try {
            checkShutdownAccess();
            advanceRunState(SHUTDOWN);
            interruptIdleWorkers();
            onShutdown(); // hook for ScheduledThreadPoolExecutor
        } finally {
            mainLock.unlock();
        }
        tryTerminate();
    }


    /**
     * Attempts to stop all actively executing tasks, halts the
     * processing of waiting tasks, and returns a list of the tasks
     * that were awaiting execution. These tasks are drained (removed)
     * from the task queue upon return from this method.
     *
     * &lt;p&gt;This method does not wait for actively executing tasks to
     * terminate.  Use {@link #awaitTermination awaitTermination} to
     * do that.
     *
     * &lt;p&gt;There are no guarantees beyond best-effort attempts to stop
     * processing actively executing tasks.  This implementation
     * cancels tasks via {@link Thread#interrupt}, so any task that
     * fails to respond to interrupts may never terminate.
     *
     * hrows SecurityException {@inheritDoc}
     */
    public List&lt;Runnable&gt; shutdownNow() {
        List&lt;Runnable&gt; tasks;
        final ReentrantLock mainLock = this.mainLock;
        mainLock.lock();
        try {
            checkShutdownAccess();
            advanceRunState(STOP);
            interruptWorkers();
            tasks = drainQueue();
        } finally {
            mainLock.unlock();
        }
        tryTerminate();
        return tasks;
    }
</code></pre>
<pre><code class="java">    private void interruptIdleWorkers(boolean onlyOne) {
        final ReentrantLock mainLock = this.mainLock;
        mainLock.lock();
        try {
            for (Worker w : workers) {
                Thread t = w.thread;
                if (!t.isInterrupted() &amp;&amp; w.tryLock()) {
                    try {
                        t.interrupt();
                    } catch (SecurityException ignore) {
                    } finally {
                        w.unlock();
                    }
                }
                if (onlyOne)
                    break;
            }
        } finally {
            mainLock.unlock();
        }
    }</code></pre>
<p>调用interrupteWorkers遍历Worker中的每个工作线程将每个线程interrupt掉。所以无法响应中断的任务可能永远无法终止。</p>
<p><strong>但是shutdown和shutdownNow有什么区别呢？</strong></p>
<p>shutdownNow首先是将线程池的状态置为STOP，然后<strong>尝试停止所有的正在执行或暂停任务的线程</strong>，并返回等待执行任务的列表，而shutdown只是将线程池的状态设置成SHUTDOWN状态，然后<strong>中断所有没有在执行任务的线程</strong>。</p>
<p>当调用了这两个方法的其中一个，isShutdown就会返回true。当所有任务都已关闭后，才表示线程池关闭成功，这时调用isTerminated方法会返回true。</p>
<p>具体调用哪个关闭看自己的场景，如果任务不一定要执行完，则可以调用shutdownNow方法。</p>
<h2 id="2-4-合理地配置线程池"><a href="#2-4-合理地配置线程池" class="headerlink" title="2.4 合理地配置线程池"></a>2.4 合理地配置线程池</h2><p>要合理配置线程池，先要分析自己应用场景的任务特征，可以从以下角度分析：</p>
<ul>
<li><p>任务的性质：CPU密集型、IO密集型任务和混合型任务。</p>
<p>CPU密集型任务应配置尽可能小的线程，如配置Ncpu+1个线程的线程池。</p>
<p>IO密集型任务线程并不是一直在执行任务，则应配尽可能多的线程，如2*Ncpu。</p>
<p>混合型任务可以拆分将其分成一个CPU密集型任务和一个IO紧密型任务，只要这两个任务执行时间差不是太大，那么分解后执行的吞吐量将高于串行执行的吞吐量。如果时间差太大，则没必要进行拆分。</p>
</li>
<li><p>任务的优先级：高中低</p>
<p>优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。可以让优先级高的任务先执行。注意：如果一直有优先级高的任务提交到队列中，那么优先级低的任务可能永远不能执行。</p>
</li>
<li><p>任务的执行时间：长、中和短。</p>
<p>执行时间不同的任务可以交给不同规模的线程池来处理，或者使用优先级队列，让执行时间短的任务先执行。</p>
</li>
<li><p>任务的依赖性：是否依赖其他系统资源、如数据库连接。</p>
<p>依赖数据库连接池的任务，因为线程提交SQL后需要等待数据库返回结果，等待的时间越长，则空闲时间就越长，那么线程数应该设置得越大，这样才能更好地利用CPU。</p>
</li>
</ul>
<p><strong>建议使用有界队列</strong></p>
<p>有界队列能增加系统的稳定性和预警能力，可以根据需要把有界队列适当调大一点，比如几千。如果使用无界队列的话，假如出现运行任务异常，后续任务不断在队列排队挤压，因为队列无界会导致越来越大，最终撑满内存导致系统崩溃不可用，而不仅仅只是后台任务出现问题。</p>
<h2 id="2-5-线程池如何监控"><a href="#2-5-线程池如何监控" class="headerlink" title="2.5 线程池如何监控"></a>2.5 线程池如何监控</h2><p>方便出现问题时，根据线程池的使用状况快速定位问题。可以通过线程池提供的参数进行监控，属性有如下：</p>
<ul>
<li><p>taskCount 线程池需要执行的任务数量</p>
</li>
<li><p>completedTaskCount 线程池在运行过程中已完成的任务数量，小于或等于taskCount。</p>
</li>
<li><p>largestPoolSize  线程池里曾静创建过的最大线程数量。可以知道线程池是不是曾经满过。</p>
</li>
<li><p>getPoolSize 线程池的线程数量。 如果线程池不销毁的话，线程池里的线程互惠自动销毁，所以这个大小只增不减。</p>
</li>
<li><p>getActiveCount 获取活动的线程数</p>
<p>可以通过扩展线程池进行监控。通过集成线程池来自定义线程池，重写线程池的beforeExecute、afterExecute和terminated方法，也可以在任务执行前、执行后和关闭线程前执行一些代码来监控。例如监控任务的平均执行时间、最大执行时间和最小执行时间等。 </p>
<p>如：</p>
<pre><code class="java">     * @param r the runnable that has completed
     * @param t the exception that caused termination, or null if
     * execution completed normally
     */
    protected void afterExecute(Runnable r, Throwable t) { }
</code></pre>
</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发框架</tag>
        <tag>ThreadPool</tag>
      </tags>
  </entry>
  <entry>
    <title>【opendaylight】——MD-SAL RPC源码概览</title>
    <url>/2019/11/27/ODL-RPC-module/</url>
    <content><![CDATA[<h1 id="一、源码概览"><a href="#一、源码概览" class="headerlink" title="一、源码概览"></a>一、源码概览</h1><h2 id="1-总体模块概览"><a href="#1-总体模块概览" class="headerlink" title="1.总体模块概览"></a>1.总体模块概览</h2><p>OpenDaylight MD-SAL支持两种RPC服务，即BI RPC服务和BA RPC服务，在AC中常用的通过Yang定义RPC生成Java接口的方式是BA服务。在MD-SAL中服务的发现、注册都是基于BI服务来实现的，BA服务则统一转换成BI服务来处理。</p>
<p><img data-src="/img/in-post/1578029090431.png" alt=""></p>
<ul>
<li><p>sal-core-api：定义了BI RPC服务的注册、调用接口。</p>
</li>
<li><p>sal-broker-impl：实现了BI RPC服务的注册、调用。</p>
</li>
<li><p>sal-binding-api：定义了BA RPC服务的注册、调用接口。</p>
</li>
<li><p>sal-binding-broker-impl：实现了BA RPC服务的注册、调用，实际的注册、调用操作都通过adapter将BA服务封装成BI服务代理到BI RPC服务中心。</p>
</li>
<li><p>sal-remoterpc-connector：实现了多个ODL节点中BI RPC服务信息的同步，以及跨进程的服务调用。</p>
<h2 id="2-分模块实现"><a href="#2-分模块实现" class="headerlink" title="2.分模块实现"></a>2.分模块实现</h2><h3 id="BI-RPC和BA-RPC服务中心的实现"><a href="#BI-RPC和BA-RPC服务中心的实现" class="headerlink" title="BI RPC和BA RPC服务中心的实现"></a>BI RPC和BA RPC服务中心的实现</h3></li>
</ul>
<p><img data-src="/img/in-post/1578029209816.png" alt=""></p>
<ul>
<li><p>DOMRpcProviderService：定义了BI RPC服务的注册接口。</p>
</li>
<li><p>DOMRpcService：定义了BI RPC服务的调用和服务增删的监听接口。</p>
</li>
<li><p>DOMRpcAvailabilityListener：BI RPC服务新增和删除的监听接口。</p>
</li>
<li><p>DOMRpcRouter：实现了BI RPC服务的注册、调用和服务增加的监听回调。</p>
</li>
<li><p>RpcConsumerRegistry：定义了BA RPC服务的查询接口。</p>
</li>
<li><p>RouteChangePublisher：定义了BA RPC服务的变更监听接口。</p>
</li>
<li><p>RpcProviderRegistry：定义了BA RPC服务的注册接口。</p>
</li>
<li><p>BindingDOMRpcServiceAdapter：实现了BA RPC服务的查询，依赖DOMRpcService，将对BA RPC的调用转换为调用DOMRpcService。</p>
</li>
<li><p>BindingDOMRpcProviderServiceAdapter：依赖DOMRpcProviderService，将BA RPC封装为DOMRpcImplementation注册到DOMRpcProviderService。</p>
</li>
<li><p>HeliumRpcProviderRegistry：聚合BindingDOMRpcServiceAdapter</p>
</li>
<li><p>BindingDOMRpcProviderServiceAdapter提供完整的BA RPC服务的注册、查询功能。</p>
</li>
</ul>
<h3 id="BI-RPC服务跨进程注册和调用的实现"><a href="#BI-RPC服务跨进程注册和调用的实现" class="headerlink" title="BI RPC服务跨进程注册和调用的实现"></a>BI RPC服务跨进程注册和调用的实现</h3><p><img data-src="/img/in-post/1578029278164.png" alt=""></p>
<p>RPC跨进程注册和调用的主要类</p>
<ul>
<li><p>RpcManager：跨进程RPC的管理者，负责启动其他Actor，并在节点间同步。</p>
</li>
<li><p>RpcInvoker：处理跨进程调用过来的akka请求的Actor，调用本地的DOMRpcService。</p>
</li>
<li><p>RpcListener：监听本地DOMRpcService服务的变化，给RpcRegistry发消息刷新本地服务的注册信息。</p>
</li>
<li><p>RpcRegistry：维护DOMRpcService服务注册信息的Actor，启动Gossiper定期与其他节点交换注册信息，将本地服务新的变化同步给其他节点，并接收其他节点新的注册信息发送给RpcRegistrar刷新服务。</p>
</li>
<li><p>Gossiper：定期与其他节点交换注册信息，如果注册信息有变化则获取新的注册信息发送给RpcRegistry同步。</p>
</li>
<li><p>RpcRegistrar：接收RpcRegistry发送过来的远端节点的服务信息，调用本地的DOMRpcProviderService注册远端服务的代理，这样当本地需要使用这些服务时可以在本地DOMRpcService调用到这些服务的代理，将调用请求通过akka发送过去。</p>
</li>
</ul>
<h3 id="BA-RPC服务注册流程"><a href="#BA-RPC服务注册流程" class="headerlink" title="BA RPC服务注册流程"></a>BA RPC服务注册流程</h3><p>通过实现AbstractBindingAwareProvider可以获取到ProviderContext，通过ProviderContext可以注册BA RPC服务，ProviderContext则是调用RpcProviderRegistry服务实现BA RPC服务的注册。</p>
<h1 id="二、MD-SAL改进"><a href="#二、MD-SAL改进" class="headerlink" title="二、MD-SAL改进"></a>二、MD-SAL改进</h1><h2 id="1-异步RPC"><a href="#1-异步RPC" class="headerlink" title="1.异步RPC"></a>1.异步RPC</h2><p>通过Yang定义RPC生成Java接口都是返回Future对象的接口，即接口语义上由服务的提供方实现接口的异步调用，MD-SAL的RPC框架未实现接口的异步调用，但是实际在AC的服务实现中并未实现调用的异步执行，基本上都是在调用线程执行的操作然后返回ImmediateFuture，这样的服务实现在MD-SAL的RPC框架中存在两个问题：</p>
<ul>
<li>1、 调用本地的RPC服务以为返回的Future是异步的，实际上已经同步执行完。</li>
<li>2、 远程调用请求都是有RpcInvoker来处理，这是个Actor，内部请求都是单线程处理的，调用RPC服务实现成同步执行会导致所有的远程调用变成串行的，远程调用吞吐量会非常低。</li>
</ul>
<p>因此改造了RPC的调用，增加了异步调用机制，大致方案是通过定制的类似ODL ProviderContext的Activator在注册异步服务时为异步服务创建并关联一个独立的akka Routor，定制ODL RPC的框架代码，在存在关联的akka Routor时将请求发送给该Routor处理从而实现同步的服务实现转异步。调用流程如下：</p>
<p><img data-src="/img/in-post/1578029343307.png" alt=""></p>
<h2 id="2-路由增量同步"><a href="#2-路由增量同步" class="headerlink" title="2.路由增量同步"></a>2.路由增量同步</h2><p>MD-SAL RPC框架通过Gossip实现各节点服务信息的最终一致性，原生ODL的Gossip机制先广播各个节点服务信息的version，如果某个节点发现它缓存的其中一个节点的服务信息version较低时再发送请求获取该节点的全量服务信息进行同步。具体路由增量同步的详细优化见下一篇博客。</p>
]]></content>
      <categories>
        <category>opendaylight</category>
      </categories>
      <tags>
        <tag>odl</tag>
        <tag>rpc</tag>
      </tags>
  </entry>
  <entry>
    <title>【opendaylight】——MD-SAL服务总线RPC服务源码分析</title>
    <url>/2019/11/27/ODL-mdsal-codereview/</url>
    <content><![CDATA[<h1 id="1、RPC服务简单介绍"><a href="#1、RPC服务简单介绍" class="headerlink" title="1、RPC服务简单介绍"></a>1、RPC服务简单介绍</h1><p>ODL平台下MD-SAL服务总线支持两类RPC服务的注册与调用，分别是Global RPC和Routed RPC，其中，Global RPC是一个控制器节点内部本进程内的调用，Routed RPC支持在控制器集群内部不同控制器节点之间跨进程调用(当然也支持同一进程内调用)，这两类RPC服务都需要注册到MD-SAL服务总线上，本文档主要总结这两类RPC服务是怎么注册到MD-SAL服务总线上以及从服务总线上获取服务调用接口的主要流程。</p>
<p><img data-src="/img/in-post/1578029380086.png" alt=""></p>
<h1 id="2、注册RPC服务（Global-RPC）"><a href="#2、注册RPC服务（Global-RPC）" class="headerlink" title="2、注册RPC服务（Global RPC）"></a>2、注册RPC服务（Global RPC）</h1><p><img data-src="/img/in-post/1578029399834.png" alt=""></p>
<p>说明：</p>
<ul>
<li>1、BA方式启动时在onSessionInitiated中获取到ProviderContext，配置子系统启动时在createInstance中获取到RootBindingAwareBroker，其他业务通过调用对应的ProviderContext或者RootBindingAwareBroker的addRpcImplementation(Class<T>,T)方法将服务注册到MD-SAL的服务总线上，所有的服务都会在BindingDOMRpcProviderServiceAdapter中创建出一个实现了DOMRpcImplementation接口的BindingDOMRpcImplementationAdapter实例，实例内部保存了接口实际注册的实例以及接口所有RPC方法对应的一个RpcMethodInvoker的Map(存储在AbstractMappedRpcInvoker中)，并将BindingDOMRpcImplementationAdapter实例添加到DOMRpcRouter中的DOMRpcRoutingTable内，存储在一个全局的Map&lt;SchemaPath, AbstractDOMRpcRoutingTableEntry&gt;中value对应的GlobalDOMRpcRoutingTableEntry中Map&lt;YangInstanceIdentifier, List<DOMRpcImplementation>&gt; 内的List<DOMRpcImplementation>&gt; 中(一个RPC接口可能被注册多次，一个RP接口也可能绑定多个YangInstanceIdentifier)。</li>
<li>2、系统中之前未注册的RPC方法都会触发RpcListener的onRpcAvailable接口来将所有的RPC信息添加到本地的路由表信息(RpcRegistry中的localBucket)中，用于RPC集群节点之间的路由表信息同步。</li>
</ul>
<h1 id="3、注册RPC服务（Routed-RPC）"><a href="#3、注册RPC服务（Routed-RPC）" class="headerlink" title="3、注册RPC服务（Routed RPC）"></a>3、注册RPC服务（Routed RPC）</h1><p><img data-src="/img/in-post/1578029444552.png" alt=""></p>
<ul>
<li>说明：BA方式启动时在onSessionInitiated中获取到ProviderContext，配置子系统启动时在createInstance中获取到RootBindingAwareBroker，其他业务通过调用对应的ProviderContext或者RootBindingAwareBroker的addRoutedRpcImplementation(Class<T>, T)方法添加Routed RPC的实现，在HeliumRpcProviderRegistry中会直接返回一个CompositeRoutedRpcRegistration的实例,实例内存储了注册的RPC接口的相关信息。</li>
</ul>
<p><img data-src="/img/in-post/1578029474636.png" alt=""></p>
<ul>
<li>说明：和Global RPC注册的流程类似，在DOMRpcRoutingTable中的Map&lt;SchemaPath, AbstractDOMRpcRoutingTableEntry&gt;的value为RoutedDOMRpcRoutingTableEntry，所有没有注册过的Routed RPC的路由表信息也会更新到RoutingTable中。</li>
</ul>
<h1 id="4、RPC集群内部路由表信息同步（Gossiper）"><a href="#4、RPC集群内部路由表信息同步（Gossiper）" class="headerlink" title="4、RPC集群内部路由表信息同步（Gossiper）"></a>4、RPC集群内部路由表信息同步（Gossiper）</h1><p><img data-src="/img/in-post/1578029504176.png" alt=""></p>
<ul>
<li><p>说明：</p>
<p>①每个节点Gossiper创建时启动一个周期性给自己发送GossipTick消息的任务(延时1s，周期0.5s)(以节点A触发为例)；</p>
<p>②节点A从本地的BucketStore获取本次存储的各个RPC集群节点最新的路由表的版本(每个节点有RPC注册时都会以注册时的时间戳更新各个节点的路由表版本)；</p>
<p>③节点A将本地存储各个节点最新路由表版本发给RPC集群中任意一个节点(假设为节点B)；</p>
<p>④节点B收到节点A发过来的路由表版本信息后，向自己的BucketStore获取节点B存储的各个集群节点的最新路由表信息；</p>
<p>⑤节点B将自己存储的版本和节点A发过来的版本进行比较，对于节点B中存储着更新版本的节点，节点B向BucketStore获取自己存储的更新节点的路由表信息，节点B中存储的着旧版本的节点，将自己存储的版本发给A，由A再去比较，将更新的路由表再同步给自己；</p>
<p>⑥节点B将自己存储的新版本的路由表发给节点A；</p>
<p>⑦节点A将自己从节点B收到的路由表信息更新到自己存储的所有节点的路由表信息中去。</p>
</li>
</ul>
<h1 id="5、获取RPC服务"><a href="#5、获取RPC服务" class="headerlink" title="5、获取RPC服务"></a>5、获取RPC服务</h1><p><img data-src="/img/in-post/1578029520537.png" alt=""></p>
<ul>
<li>说明：BA方式启动时在onSessionInitiated中获取到ProviderContext，配置子系统启动时在createInstance中获取到RootBindingAwareBroker，其他业务通过调用对应的ProviderContext或者RootBindingAwareBroker的getRpcService(Class<T> service)从MD-SAL服务总线上获取接口服务实例。最终由BindingDOMRpcServiceAdapter来构造一个RpcServiceAdapter的实例，并由RpcServiceAdapter构造一个对应接口的动态代理作为属性存储下来，并返回生成的动态代理。RpcServiceAdapter的实例会存储在BindingDOMRpcServiceAdapter的一个高速缓存中，后面获取接口服务实例时先从缓存中获取，没有的话再构造。(Global RPC和Routed RPC获取服务的方式完全相同)。</li>
</ul>
<h1 id="6、Global-RPC服务调用"><a href="#6、Global-RPC服务调用" class="headerlink" title="6、Global RPC服务调用"></a>6、Global RPC服务调用</h1><p><img data-src="/img/in-post/1578029543412.png" alt=""></p>
<ul>
<li>说明：从MD-SAL上获取到的RPC服务的动态代理，调用具体的RPC接口时会触发RpcServiceAdapter的invoke (final Object proxy, final Method method, final Object[] args)，后面依次找到注册到MD-SAL服务总线上的实际服务实例，通过反射调用对应的接口。</li>
</ul>
<h1 id="7、Routed-RPC服务调用-注册服务节点调用"><a href="#7、Routed-RPC服务调用-注册服务节点调用" class="headerlink" title="7、Routed RPC服务调用 (注册服务节点调用)"></a>7、Routed RPC服务调用 (注册服务节点调用)</h1><p><img data-src="/img/in-post/1578029563999.png" alt=""></p>
<ul>
<li>说明：从MD-SAL上获取到的RPC服务的动态代理，调用具体的RPC接口时会触发RpcServiceAdapter的invoke (final Object proxy, final Method method, final Object[] args)，后面依次找到注册到MD-SAL服务总线上的实际服务实例(在RoutedDOMRpcRoutingTableEntry中先判断本地是否注册过该接口，如果注册过，则直接调用本地的服务实例)，通过反射调用对应的接口。</li>
</ul>
<h1 id="8、Routed-RPC服务调用-非注册服务节点调用"><a href="#8、Routed-RPC服务调用-非注册服务节点调用" class="headerlink" title="8、Routed RPC服务调用 (非注册服务节点调用)"></a>8、Routed RPC服务调用 (非注册服务节点调用)</h1><p><img data-src="/img/in-post/1578029582983.png" alt=""></p>
<ul>
<li>和注册服务节点的区别在于：在RoutedDOMRpcRoutingTableEntry 中没有找到本地注册的服务实例，然后调用RemoteRpcImplementation，由 RemoteRpcImplementation 根据RPC的路由信息查找全局同步的路由表信息，找到注册服务节点的RpcBroker (actor)，通过akka的消息机制向找到的actor发送RPC调用消息，再由注册服务节点的RpcBroker 按相同的流程找到具体的实现来调用。</li>
</ul>
]]></content>
      <categories>
        <category>opendaylight</category>
      </categories>
      <tags>
        <tag>odl</tag>
        <tag>rpc</tag>
      </tags>
  </entry>
  <entry>
    <title>【NLP】一、线性回归与随机梯度下降法</title>
    <url>/2019/11/27/NLP-Gradient-Descent/</url>
    <content><![CDATA[<p>在NLP的学习中，我们了解熵、信息熵、交叉熵的基础概念，通过将熵（信息量的度量）的计算转换为概率模型的计算，然后介绍了在一些语料库中的样本中，计算出一些词与其他词同时出现在一个句子或者短语的概率，引入了N-gramm的概念，但是N个词的N-gramm的概率非常难以计算而且计算出的概率很小，因此一般使用bigram model计算（即认为当前词只与前面那个词相关）但这种方式相对不够精确。</p>
<p>如果我们把一个词放在整改语料库里去看，并利用当前语料库的输入（one hot represetation）通过神经网络模型计算损失函数的最优解（参数众多），以此来预测其他词出现的情况，这里就会用到一个基础的线性回归的方法——随机梯度法的概念。神经网络是通用方法，而基础就是基于线性回归的方法，线性回归最基础的方法就是梯度下降，因此理解线性回归以及他的基本方法随机梯度下降非常重要。</p>
<p>本篇文章就以机器学习中常用的线性回归的基本方法——随机梯度下降进行总结。</p>
<p>下面就一个实际的线性回归问题：<strong>如何预测房价</strong>作为引入。</p>
<h1 id="一、问题：如何预测房价？"><a href="#一、问题：如何预测房价？" class="headerlink" title="一、问题：如何预测房价？"></a>一、问题：如何预测房价？</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p><img data-src="/img/in-post/image-20200102230850144.png" alt=""></p>
<p>已知一些面积对应的房价的样本数据，利用这些样本数据预测其他面积的房价。</p>
<p>这是一个监督学习的例子，因为例子中每个点都有明确的“正确答案”，如1000平的房子在170W美金，预测出的某个平方的房子也一定有明确的价钱。同时这也是监督学习中典型的回归问题，输出是一个具体指（当然另外一种典型的监督学习问题是分类，用来预测离散值的输出）。</p>
<h2 id="训练集"><a href="#训练集" class="headerlink" title="训练集"></a>训练集</h2><p><img data-src="/img/in-post/image-20200103005523817.png" alt=""></p>
<p><img data-src="/img/in-post/image-20200103005727295.png" alt=""></p>
<h1 id="二、模型定义"><a href="#二、模型定义" class="headerlink" title="二、模型定义"></a>二、模型定义</h1><p><img data-src="/img/in-post/image-20200103005804747.png" alt=""></p>
<p>可以用一个一元线性函数去拟合样本数据，利用拟合出的函数去预测其他未知数据。</p>
<p><strong>具体怎么拟合呢？</strong>下面看看怎么实现。</p>
<h1 id="三、如何实现"><a href="#三、如何实现" class="headerlink" title="三、如何实现"></a>三、如何实现</h1><p><img data-src="/img/in-post/image-20200103011806806.png" alt=""></p>
<p><img data-src="/img/in-post/image-20200103011906592.png" alt=""></p>
<p><img data-src="/img/in-post/image-20200103011919467.png" alt=""></p>
<p>即单个样本的最小问题转化为：</p>
<p><img data-src="/img/in-post/image-20200103012030839.png" alt=""></p>
<p>使此式的指最小，即通过假设函数h(x)计算出的值与实际样本中的y之间的差异最小的问题。</p>
<p>对所有样本来说，假设样本有M个点，即求i=1到i=M样本的差值的平方和。</p>
<p><img data-src="/img/in-post/image-20200103012351585.png" alt=""></p>
<h1 id="四、定义代价函数"><a href="#四、定义代价函数" class="headerlink" title="四、定义代价函数"></a>四、定义代价函数</h1><p><img data-src="/img/in-post/image-20200103012500164.png" alt=""></p>
<h1 id="五、代价函数的求解过程"><a href="#五、代价函数的求解过程" class="headerlink" title="五、代价函数的求解过程"></a>五、代价函数的求解过程</h1><h2 id="简化假设函数和代价函数求解"><a href="#简化假设函数和代价函数求解" class="headerlink" title="简化假设函数和代价函数求解"></a>简化假设函数和代价函数求解</h2><p><img data-src="/img/in-post/image-20200103012711613.png" alt=""></p>
<p>先列出假设函数和代价函数的定义，目标是使代价函数的最小。为了方便计算我们使用右边的简化版进行手动推倒。</p>
<ul>
<li><p>步骤一、</p>
<p><img data-src="/img/in-post/image-20200103012928258.png" alt=""></p>
</li>
<li><p>步骤二、</p>
</li>
</ul>
<p><img data-src="/img/in-post/image-20200103012954273.png" alt=""></p>
<ul>
<li><p>步骤三、</p>
<p><img data-src="/img/in-post/image-20200103013011186.png" alt=""></p>
</li>
<li><p>步骤四、五 发现计算出的代价函数值越来越大，即越来越不接近实际样本值。因此取步骤1的假设值。</p>
</li>
</ul>
<h2 id="恢复两个参数的假设函数和代价函数的版本"><a href="#恢复两个参数的假设函数和代价函数的版本" class="headerlink" title="恢复两个参数的假设函数和代价函数的版本"></a>恢复两个参数的假设函数和代价函数的版本</h2><p><img data-src="/img/in-post/image-20200103013416357.png" alt=""></p>
<p>其手动拟合的过程如下：</p>
<p><img data-src="/img/in-post/image-20200103013441570.png" alt=""></p>
<h1 id="六、随机梯度法"><a href="#六、随机梯度法" class="headerlink" title="六、随机梯度法"></a>六、随机梯度法</h1><p>上面讲了线性回归手动去尝试计算代价函数一次来求得假设函数的最优函数。实际在工程中是不可能没有规律的去尝试取不同的参数值计算的。必须满足一定的规律来求解，以保证收敛。</p>
<ul>
<li><p><strong>目标定义</strong></p>
<p><img data-src="/img/in-post/image-20200103013855639.png" alt=""></p>
</li>
<li><p><strong>求解过程</strong></p>
<p><img data-src="/img/in-post/image-20200103013918848.png" alt=""></p>
</li>
</ul>
<h2 id="随机梯度下降的公式推导"><a href="#随机梯度下降的公式推导" class="headerlink" title="随机梯度下降的公式推导"></a>随机梯度下降的公式推导</h2><p><img data-src="/img/in-post/image-20200103014119287.png" alt=""></p>
<p>将上文提到的代价函数带入随机梯度下降的公式中：</p>
<p><img data-src="/img/in-post/image-20200103014153175.png" alt=""></p>
<p><img data-src="/img/in-post/image-20200103014236092.png" alt=""></p>
<p><img data-src="/img/in-post/image-20200103014342482.png" alt=""></p>
<p><img data-src="/img/in-post/image-20200103014514092.png" alt=""></p>
<p>慢慢拟合</p>
<p><img data-src="/img/in-post/image-20200103014754500.png" alt=""></p>
<p>最后找到全局最小值，假设函数得出的数据很好的收敛了房价的价格数据。</p>
<p>得到了假设函数的参数后就可以使用实际的函数来预测房价了。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol>
<li><p>线性回归问题实际就是求代价函数的问题，通过代价函数的最优化去拟合得出最合适的假设函数。</p>
</li>
<li><p>求解代价函数的典型方法和最常用的就有随机梯度下降法，本例中使用的随机梯度下降叫：<strong>Batch梯度下降</strong>：即使用所有的样本数据。</p>
</li>
<li><p>当然像这种简单的线性回归也可以使用正规方程组求解代价函数J的最小值。梯度下降适合更大的数据集。</p>
<p>本文中也没有讲多元函数的随机梯度下降法。主要是通过简单的例子理解随机梯度下降。为理解神经网络以及在NPL中的相关应用做理论准备。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>随机梯度下降</tag>
        <tag>有监督</tag>
        <tag>线性回归</tag>
      </tags>
  </entry>
  <entry>
    <title>【并发容器和框架】四、Executor框架</title>
    <url>/2019/11/27/java-concurrency-container-Executor/</url>
    <content><![CDATA[<p>上文讲了，如果为每个任务创建一个新线程来执行，线程的创建和销毁要消耗大量的计算资源。Java的线程既是工作单元，也是执行机制。从JDK 5开始，把工作单元和执行机制分离开来。工作单元包括Runnable和Callable，而执行机制由Executor框架提供。</p>
<h1 id="1-Executor框架简介"><a href="#1-Executor框架简介" class="headerlink" title="1. Executor框架简介"></a>1. Executor框架简介</h1><h2 id="1-1-Executor框架的两级调度模型"><a href="#1-1-Executor框架的两级调度模型" class="headerlink" title="1.1 Executor框架的两级调度模型"></a>1.1 Executor框架的两级调度模型</h2><p>在HotSpot VM的线程模型中，Java线程被一对一映射为本地操作系统线程。Java线程启动时会创建一个本地操作系统线程;当该Java线程终止时，这个操作系统线程也会被回收。操作系统会调度所有线程并将它们分配给可用的CPU。</p>
<p>在上层，Java多线程程序通常应用分解为若干个任务，然后使用用户级的调度器（Executor框架）将这些任务映射为固定数量的线程；在底层，操作系统内核将这些线程映射到硬件处理器上。如这种两级调度模型示意图见下一节。</p>
<p>从图中可以看出，应用程序通过Executor框架控制上层的调度；而下层的调度由操作系统内核控制，下层的调度不受应用程序的控制。</p>
<h2 id="1-2-Executor框架的结构与成员"><a href="#1-2-Executor框架的结构与成员" class="headerlink" title="1.2 Executor框架的结构与成员"></a>1.2 Executor框架的结构与成员</h2><p><img data-src="/img/in-post/image-20191222214449679.png" alt=""></p>
<h3 id="1-2-1-Executor框架的结构"><a href="#1-2-1-Executor框架的结构" class="headerlink" title="1.2.1 Executor框架的结构"></a>1.2.1 Executor框架的结构</h3><p>Executor框架主要由3大部分：</p>
<ul>
<li><p>任务 </p>
<p>Runnable接口和Callable接口</p>
</li>
<li><p>任务的执行</p>
<p>任务执行的核心接口<strong>Executor</strong>，以及继承Executor的<strong>ExecutorService</strong>接口。Executor框架有两个关键类实现了ExecutorService（ThreadPoolExecutor和ScheduledThreadPoolExecutor）。</p>
<p><strong>ThreadPoolExecutor</strong>是<strong>线程池核心</strong>实现类，用来执行被提交的任务。</p>
<p><strong>ScheduledThreadPoolExecutor</strong>是一个实现类，可以在给定的延迟后运行命令，或者定期执行命令。ScheduledThreadPoolExecutor比Timer更灵活，功能更强大。</p>
</li>
<li><p>异步计算的结果</p>
<p>包括<strong>接口Future</strong>和实现Future接口的<strong>FutureTask类</strong>，代表异步结果。</p>
</li>
</ul>
<p>Executor接口和实现类图</p>
<p><img data-src="/img/in-post/image-20191222222820374.png" alt=""></p>
<p>FutureTask实现类图</p>
<p><img data-src="/img/in-post/image-20191222223317473.png" alt=""></p>
<h3 id="1-2-2-Executor框架的成员"><a href="#1-2-2-Executor框架的成员" class="headerlink" title="1.2.2 Executor框架的成员"></a>1.2.2 Executor框架的成员</h3><ul>
<li><p>（1）<strong>ThreadPoolExecutor</strong></p>
<p>ThreadPoolExecutor通常使用工厂类<strong>Executors</strong>来创建。Executors可以创建3种类型的ThreadPoolExecutor:SingleThreadExecutor、FixedThreadPool和CachedThreadPool。</p>
<ul>
<li><p>FixedThreadPool（固定线程数）</p>
<pre><code class="java">    public static ExecutorService newFixedThreadPool(int nThreads) {
        return new ThreadPoolExecutor(nThreads, nThreads,
                                      0L, TimeUnit.MILLISECONDS,
                                      new LinkedBlockingQueue&lt;Runnable&gt;());
    }</code></pre>
<p>适用需要限制当前线程数量的应用场景，它适用于负载比较中的服务器。</p>
</li>
<li><p>SingleThreadExecutor（单线程）</p>
<pre><code class="java">    public static ExecutorService newSingleThreadExecutor() {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue&lt;Runnable&gt;()));
    }</code></pre>
<pre><code class="java">    public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) {
        return new FinalizableDelegatedExecutorService
            (new ThreadPoolExecutor(1, 1,
                                    0L, TimeUnit.MILLISECONDS,
                                    new LinkedBlockingQueue&lt;Runnable&gt;(),
                                    threadFactory));
    }</code></pre>
<p>适用于需要保证顺序地执行各个任务；并且在任意时间点，不会有多个线程是活动的应用场景。</p>
</li>
<li><p>CachedThreadPool（按需创建线程）</p>
<pre><code class="java">    public static ExecutorService newCachedThreadPool() {
        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                      60L, TimeUnit.SECONDS,
                                      new SynchronousQueue&lt;Runnable&gt;());
    }</code></pre>
<p>大小无界的线程池，适用于执行很多的短期异步任务的小程序，或者负载比较轻的服务器。</p>
</li>
</ul>
</li>
<li><p>（2）<strong>ScheduledThreadPoolExecutor</strong></p>
<p>ScheduledThreadPoolExecutor通常使用工厂类Executors来创建。Executors可以创建2种类型的ScheduledThreadPoolExecutor，如下：</p>
<ul>
<li><p>ScheduledThreadPoolExecutor。包含如干个线程的ScheduledThreadPoolExecutor。</p>
<pre><code class="java">    public ScheduledThreadPoolExecutor(int corePoolSize) {
        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
              new DelayedWorkQueue());
    }</code></pre>
<p>适用于需要多个后台线程执行周期任务，同时需要限制后台线程数量的应用场景。</p>
</li>
<li><p>SingleThreadScheduledExecutor。只包含一个线程的ScheduledThreadPoolExecutor。</p>
<pre><code class="java">    public static ScheduledExecutorService newSingleThreadScheduledExecutor() {
        return new DelegatedScheduledExecutorService
            (new ScheduledThreadPoolExecutor(1));
    }</code></pre>
<p>适用于需要单个后台线程执行周期任务，同时需要保证顺序地执行各个任务的应用场景。</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>（3）<strong>Future接口</strong></p>
<p>实现Future接口的FuturetTask类用来表示异步计算的结果。</p>
<p><strong>ThreadPoolExecutor</strong>、<strong>ScheduledThreadPoolExecutor</strong>会返回一个FutureTask对象。</p>
<pre><code class="java">public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) </code></pre>
<pre><code class="java">public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) </code></pre>
<pre><code class="java"> public Future&lt;?&gt; submit(Runnable task)</code></pre>
</li>
</ul>
<ul>
<li><p>（4）<strong>Runnable接口和Callable接口</strong></p>
<p>提交ThreadPoolExecutor或ScheduledThreadPool执行。区别是：Runnable不会返回结果，而Callable可以返回结果。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发框架</tag>
        <tag>Executor</tag>
      </tags>
  </entry>
  <entry>
    <title>【Solr】-【Search】Json Facet使用总结</title>
    <url>/2019/11/27/solr-search-Json%20Facet/</url>
    <content><![CDATA[<h1 id="Faceted-Search"><a href="#Faceted-Search" class="headerlink" title="Faceted Search"></a>Faceted Search</h1><h2 id="Metric-Example"><a href="#Metric-Example" class="headerlink" title="Metric Example"></a>Metric Example</h2><pre><code class="java">curl http://192.168.3.13:31121/xxx/PATENT/query -d &#39;
  q=*:*&amp;
  json.facet={
    &quot;AVG_CITE_COUNT&quot;:&quot;avg(CITE_COUNT)&quot;,
    &quot;NUM_IN_COUNTRY&quot;:&quot;unique(IN_COUNTRY)&quot;,
    &quot;MEDIA_CLAIM_COUNT&quot;:&quot;percentile(CLAIM_COUNT,50)&quot;
  }
&#39;</code></pre>
<p>响应:</p>
<pre><code class="java">&quot;facets&quot;:{
    &quot;count&quot;:661044,
    &quot;MEDIA_CLAIM_COUNT&quot;:19.0,
    &quot;AVG_CITE_COUNT&quot;:13.03796393q=*:*&amp;4739052,
    &quot;NUM_IN_COUNTRY&quot;:185}</code></pre>
<h2 id="Bucketing-Facet-Example"><a href="#Bucketing-Facet-Example" class="headerlink" title="Bucketing Facet Example"></a>Bucketing Facet Example</h2><pre><code class="java">curl http://192.168.3.13:31121/xxx/PATENT/query -d &#39;
  q=*:*&amp;
  json.facet={
    categories:{
      type:terms,
      field:APD_YEARMONTHDAY,
      limit:10
    }
  }
&#39;</code></pre>
<p>响应：</p>
<pre><code class="java">  &quot;facets&quot;:{
    &quot;count&quot;:661044,
    &quot;categories&quot;:{
      &quot;buckets&quot;:[{
          &quot;val&quot;:20000524,
          &quot;count&quot;:1167},
        {
          &quot;val&quot;:20160923,
          &quot;count&quot;:935},
        {
          &quot;val&quot;:20151218,
          &quot;count&quot;:857},
        {
          &quot;val&quot;:20160331,
          &quot;count&quot;:838},
        {
          &quot;val&quot;:20160129,
          &quot;count&quot;:702},
        {
          &quot;val&quot;:20160630,
          &quot;count&quot;:595},
        {
          &quot;val&quot;:20160729,
          &quot;count&quot;:553},
        {
          &quot;val&quot;:20150210,
          &quot;count&quot;:459},
        {
          &quot;val&quot;:20161216,
          &quot;count&quot;:459},
        {
          &quot;val&quot;:20160527,
          &quot;count&quot;:454}]
    }}}</code></pre>
<h2 id="Making-a-Facet-Request"><a href="#Making-a-Facet-Request" class="headerlink" title="Making a Facet Request"></a>Making a Facet Request</h2><ol>
<li>we will often just present this <strong>facet command block</strong></li>
</ol>
<pre><code class="java">curl http://192.168.3.13:31121/xxx/PATENT/query -d &#39;
  q=*:*&amp;
  json.facet={
        x:&quot;avg(mul(CITE_COUNT,IN_COUNT))&quot;
  }
&#39;</code></pre>
<p>响应：</p>
<pre><code class="java">  &quot;facets&quot;:{
    &quot;count&quot;:661044,
    &quot;x&quot;:50.39590705893086}}</code></pre>
<ol start="2">
<li><p>Another option is to use the JSON Request API to provide the entire request in JSON.</p>
<pre><code class="java">curl http://192.168.3.13:31121/xxx/PATENT/query -d &#39;
  query:&quot;*:*&quot;,
  facet={
    categories:{
        x:&quot;avg(mul(CITE_COUNT,IN_COUNT))&quot;
    }
  }
&#39;</code></pre>
</li>
</ol>
<h1 id="Terms-Facet"><a href="#Terms-Facet" class="headerlink" title="Terms Facet"></a>Terms Facet</h1><pre><code class="java">curl http://192.168.17.3:31121/xxx/PATENT/query -d &#39;
  q=*:*&amp;
  json.facet={
    categories:{
      terms: {
        field:PBDT_YEARMONTH,
          limit:5
      }
    }
  }
&#39;</code></pre>
<p>响应：</p>
<pre><code class="java">  &quot;facets&quot;:{
    &quot;count&quot;:661052,
    &quot;categories&quot;:{
      &quot;buckets&quot;:[{
          &quot;val&quot;:201606,
          &quot;count&quot;:16628},
        {
          &quot;val&quot;:201706,
          &quot;count&quot;:16482},
        {
          &quot;val&quot;:201703,
          &quot;count&quot;:16374},
        {
          &quot;val&quot;:201612,
          &quot;count&quot;:15571},
        {
          &quot;val&quot;:201711,
          &quot;count&quot;:14237}]}}}</code></pre>
<p><img data-src="/img/in-post/1574840607065.png" alt=""></p>
<p><img data-src="/img/in-post/1574840626853.png" alt=""></p>
<h1 id="Query-Facet"><a href="#Query-Facet" class="headerlink" title="Query Facet"></a>Query Facet</h1><ul>
<li>The query facet produces a single bucket of documents that match the domain as well as specified query.</li>
</ul>
<p>An example of the simplest form of the query facet is “query”:”query string”.</p>
<pre><code class="java">curl http://192.168.17.3:31121/xxx/PATENT/query -d &#39;
         q=*:*&amp;
       json.facet={
            CITE_COUNT_FACET:{query:&quot;CITE_COUNT:[0 TO 100]&quot;}
       }&#39;</code></pre>
<p>响应：</p>
<pre><code class="java">  &quot;facets&quot;:{
    &quot;count&quot;:661052,
    &quot;CITE_COUNT_FACET&quot;:{
      &quot;count&quot;:411905}}}
</code></pre>
<ul>
<li>Expanded from allows for more parameters.</li>
</ul>
<pre><code class="java">curl http://192.168.17.3:31121/xxx/PATENT/query -d &#39;
        q=*:*&amp;
        json.facet={
              CITE_COUNT_FACET:{
                  type:query,
                  q:&quot;CITE_COUNT:[1 TO 100000]&quot;,
                  facet:{avg_cite_count:&quot;avg(CITE_COUNT)&quot;}
              }
        }         
&#39;</code></pre>
<p>响应：</p>
<pre><code class="java">  &quot;facets&quot;:{
    &quot;count&quot;:661052,
    &quot;CITE_COUNT_FACET&quot;:{
      &quot;count&quot;:419193,
      &quot;avg_cite_count&quot;:13.03594287118344}}}
</code></pre>
<h1 id="Range-Facet"><a href="#Range-Facet" class="headerlink" title="Range Facet"></a>Range Facet</h1><p>produces multiple buckets over a <strong>date field</strong> or <strong>numeric field</strong>.</p>
<ul>
<li>例子1：Data Field example</li>
</ul>
<pre><code class="java">curl http://192.168.17.3:31121/xxx/PATENT/query -d &#39;
         q=*:*&amp;
       json.facet={
           PBDT_YEARMONTH_RANGE_COUNT:{
                type:range,
                field:PBDT_YEARMONTH,
                start:201801,
                end: 201811,
                gap:2
           }
       }&#39;</code></pre>
<p>响应：</p>
<pre><code class="java">  &quot;facets&quot;:{
    &quot;count&quot;:661052,
    &quot;PBDT_YEARMONTH_RANGE_COUNT&quot;:{
      &quot;buckets&quot;:[{
          &quot;val&quot;:201801,
          &quot;count&quot;:23735},
        {
          &quot;val&quot;:201803,
          &quot;count&quot;:5556},
        {
          &quot;val&quot;:201805,
          &quot;count&quot;:2109},
        {
          &quot;val&quot;:201807,
          &quot;count&quot;:2016},
        {
          &quot;val&quot;:201809,
          &quot;count&quot;:1735}]}}}
</code></pre>
<ul>
<li>例子2：Numeric field example</li>
</ul>
<pre><code class="java">curl http://192.168.17.3:31121/xxx/PATENT/query -d &#39;
         q=*:*&amp;
       json.facet={
           cites_count:{
                type:range,
                field:CITE_COUNT,
                start:0,
                end: 100,
                gap:20
           }
       }&#39;</code></pre>
<p>响应：</p>
<pre><code class="java">  &quot;facets&quot;:{
    &quot;count&quot;:661052,
    &quot;cites_count&quot;:{
      &quot;buckets&quot;:[{
          &quot;val&quot;:0,
          &quot;count&quot;:377402},
        {
          &quot;val&quot;:20,
          &quot;count&quot;:19993},
        {
          &quot;val&quot;:40,
          &quot;count&quot;:7017},
        {
          &quot;val&quot;:60,
          &quot;count&quot;:3748},
        {
          &quot;val&quot;:80,
          &quot;count&quot;:3516}]}}}</code></pre>
<p><img data-src="/img/in-post/1574840759014.png" alt=""></p>
<p><img data-src="/img/in-post/1574840824861.png" alt=""></p>
<h1 id="Aggregation-Functions"><a href="#Aggregation-Functions" class="headerlink" title="Aggregation Functions"></a>Aggregation Functions</h1><p>Unlike all the facets discussed so far, Aggregation functions (also called facet functions, analytic functions,or metrics) do not partition data into buckets. Instead, they calculate something over all the documents inthe domain.</p>
<p><img data-src="/img/in-post/1574841746216.png" alt=""></p>
<p><img data-src="/img/in-post/1574841758042.png" alt=""></p>
<ul>
<li><p>例子1：</p>
<pre><code class="java">curl http://192.168.17.3:31121/xxx/PATENT/query -d &#39;
         q=*:*&amp;
       json.facet={
            &quot;avg_count&quot;:&quot;avg(sum(CITE_COUNT,CITED_COUNT))&quot;
       }&#39;</code></pre>
</li>
</ul>
<h1 id="Nested-Facets"><a href="#Nested-Facets" class="headerlink" title="Nested Facets"></a>Nested Facets</h1><ol>
<li><p>统计最近20年每一年的申请量（年份自动补全）</p>
</li>
<li><p>统计最近20年每一年的 Top 10 当前申请人+在该年的申请量</p>
</li>
<li><p>统计最近20年每一年的申请人数量（去重后的）</p>
</li>
<li><p>统计最近20年每一年中国专利的申请量</p>
<p>（为了方便显示，只显示2017~2018的数据）</p>
</li>
</ol>
<pre><code class="java"> curl http://192.168.17.3:31121/xxx/PATENT/query -d &#39;
         q=*:*&amp;
       json.facet={
           APD_YEAR_TOP_STATS:{
            type:range,
            field:APD_YEAR,
            start:2016,
            end:2019,
            gap:1,
            facet:{
                top_ancs:{
                    type:terms,
                    field:ANCS_FACET,
                    limit:3,
                    mincount:1
                },
                &quot;unique_an_num&quot;:&quot;unique(AN_FACET)&quot;,
                &quot;cn_patents_num&quot;:{ query:&quot;ANC_COUNTRY:CN&quot;}

            }
           }
       }&#39;</code></pre>
<pre><code class="java"> curl http://s-gateway-ci.k8s.zhihuiya.com/s-search-patent-solr/xxx/PATENT/query -d &#39;
         q=TTL:car&amp;
       json.facet={
           apd_year_trend:{
            type:range,
            field:APD_YEAR,
            start:2015,
            end:2020,
            gap:1,
            facet:{
                top_ancs:{
                    type:terms,
                    field:ANCS_FACET,
                    limit:3,
                    mincount:1
                },
                &quot;unique_an_num&quot;:&quot;unique(AN_FACET))&quot;,
                &quot;cn_patents_num&quot;:{ query:&quot;COUNTRY:CN&quot;}

            }
           }
       }&#39;</code></pre>
<p>响应：</p>
<pre><code class="java">&quot;facets&quot;:{
    &quot;count&quot;:661052,
    &quot;APD_YEAR_TOP_STATS&quot;:{
      &quot;buckets&quot;:[{
          &quot;val&quot;:2017,
          &quot;count&quot;:73078,
          &quot;top_ancs&quot;:{
            &quot;buckets&quot;:[{
                &quot;val&quot;:&quot;APPLE&quot;,
                &quot;count&quot;:5376},
              {
                &quot;val&quot;:&quot;ORACLE INT&quot;,
                &quot;count&quot;:1141},
              {
                &quot;val&quot;:&quot;ZTE&quot;,
                &quot;count&quot;:771}]},
          &quot;cn_patents_num&quot;:{
            &quot;count&quot;:7442},
          &quot;unique_an_num&quot;:33512},
        {
          &quot;val&quot;:2018,
          &quot;count&quot;:4188,
          &quot;top_ancs&quot;:{
            &quot;buckets&quot;:[{   
                &quot;val&quot;:&quot;APPLE&quot;,
                &quot;count&quot;:3434},
              {
                &quot;val&quot;:&quot;ORACLE INT&quot;,
                &quot;count&quot;:492},
              {
                &quot;val&quot;:&quot;애플인크&quot;,
                &quot;count&quot;:183}]},
          &quot;cn_patents_num&quot;:{
            &quot;count&quot;:92},
          &quot;unique_an_num&quot;:270}]}}}
</code></pre>
<h1 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h1><p>在分析源码之前，粗略问自己几个问题：</p>
<ol>
<li>facet在单机和集群模式下分别是怎么计算的？</li>
<li>facet agg在单机和集群模式下分别是怎么计算的？</li>
<li>集群模式下facet和agg是怎么合并数据的？</li>
</ol>
<p><img data-src="/img/in-post/1574851332886.png" alt=""></p>
<p><img data-src="/img/in-post/image-20191201191027108.png" alt=""></p>
]]></content>
      <categories>
        <category>Solr</category>
      </categories>
      <tags>
        <tag>Solr</tag>
        <tag>Json Facet</tag>
      </tags>
  </entry>
  <entry>
    <title>【并发容器和框架】二、Fork/Join框架</title>
    <url>/2019/11/06/java-concurrency-container-ForkJoin/</url>
    <content><![CDATA[<h1 id="1-什么是Fork-Join框架"><a href="#1-什么是Fork-Join框架" class="headerlink" title="1.什么是Fork/Join框架"></a>1.什么是Fork/Join框架</h1><p>Fork/Join框架是Java 7提供的一个并行执行任务的框架，是一个把大小任务分割成若干小任务，最终汇总每个小人物结果后得到大任务结果的框架。</p>
<p>Fork就是把一个大任务切分成若干个小任务并行执行，Join就是合并这些子任务的执行结果，最后得到这个大任务的结果。比如计算1+2….+1000，可以分割成10个子任务，每个子任务分别对1000个数进行求和，最终汇总这10个子任务的结果。流程如下：</p>
<p><img data-src="/img/in-post/image-20191108011932771.png" alt=""></p>
<h1 id="2-工作窃取算法"><a href="#2-工作窃取算法" class="headerlink" title="2.工作窃取算法"></a>2.工作窃取算法</h1><p>在需要做比较大的任务时，可以把任务分割成若干互不依赖的子任务，减少线程间的竞争。这些子任务被放到不同的队列，并为每个队列创建一个单独的线程来执行队列里的任务。有些线程执行任务比较快，就会”窃取”其他线程队里中的任务帮助干活。为了减少窃取与其他线程的之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列头拿任务，而窃取任务的线程永远从双端队列的尾部拿任务执行。</p>
<p><img data-src="/img/in-post/image-20191116171122073.png" alt=""></p>
<ul>
<li>工作窃取算法的优点：充分利用线程进行并行计算，减少了线程间的竞争。</li>
<li>工作窃取算法的缺点：在某些情况下还是存在竞争，比如双端队列里只有一个任务时。并且该算法会消耗了更多的系统资源，比如创建多个线程和多个多段队列。</li>
</ul>
<h1 id="3-Fork-Join框架的设计"><a href="#3-Fork-Join框架的设计" class="headerlink" title="3.Fork/Join框架的设计"></a>3.Fork/Join框架的设计</h1><p>如果自己设计，思考几个步骤：</p>
<ul>
<li>步骤1 <strong>分割任务</strong>。首先不停把大任务分割成子任务。</li>
<li>步骤2 <strong>执行任务并合并结果</strong>。分割的子任务分别放在双端队列里，然后几个启动线程分别从双端队里获取任务执行。子任务执行完的结构都同一放在一个队列里，启动一个线程从队列里拿数据，然后合并这些数据。</li>
</ul>
<p>下面来总结下Fork/Join用两个类来实现这个步骤：</p>
<ol>
<li>ForkJoinTask：必须首先创建ForkJoin任务，它<strong>提供fork和join操作的机制</strong>。一般实现它的两个子类：<ul>
<li>RecursiveAction：没有返回结果的任务。</li>
<li>RecursiveTask：有返回结果的任务。</li>
</ul>
</li>
<li>ForkJoinPool：ForkJoinTask需要通过ForkJoinPool来执行。</li>
</ol>
<p>任务分割出的子任务会添加到当前工作线程所维护的双端队列中，进入队列头部。当一个工作线程的队列里暂时没有任务时，它会随机从其他工作线程的队列的尾部获取一个任务。</p>
<h1 id="4-使用Fork-Join框架"><a href="#4-使用Fork-Join框架" class="headerlink" title="4.使用Fork/Join框架"></a>4.使用Fork/Join框架</h1><p>计算1+2+3+4</p>
<pre><code class="java">public class ForkJoinTest extends RecursiveTask {
    int start,end;
    int THRESHOLD=2;
    public ForkJoinTest(int start,int end) {
        this.start = start;
        this.end = end;
    }
    verride
    protected Integer compute() {
        int sum = 0;
        if (end - start &lt;= THRESHOLD) { //如果任务已经足够小，就开始计算
            for (int i = start ; i &lt;= end ; i++) {
                sum += i;
            }
        } else {
            //步骤1：任务切分
            int middle = (start + end)/2;
            ForkJoinTest leftTask = new ForkJoinTest(start,middle);
            ForkJoinTest rightTask = new ForkJoinTest(middle+1,end);

            //步骤2：执行子任务
            leftTask.fork();
            rightTask.fork();

            //步骤3: 等待任务执行完成，合并结果
            int leftResult = (int)leftTask.join();
            int rightResult = (int)rightTask.join();
            System.out.println(&quot;leftResult:&quot;+leftResult + &quot; rightResult:&quot;+rightResult);

            sum = leftResult + rightResult;
        }
        return sum;
    }

    public static void main(String[] args) throws ExecutionException, InterruptedException {
        ForkJoinPool pool = new ForkJoinPool();
        //生成一个计算任务，负责计算1+2+3+4
        ForkJoinTest fkTask = new ForkJoinTest(1,4);
        //执行一个任务
        ForkJoinTask&lt;ForkJoinTask&gt; future = pool.submit(fkTask);
        System.out.println(future.get());
    }
}</code></pre>
<p>输出：</p>
<p><img data-src="/img/in-post/image-20191117095904211.png" alt=""></p>
<p><img data-src="/img/in-post/image-20191117100947175.png" alt=""></p>
<h1 id="5-Fork-Join框架的实现原理"><a href="#5-Fork-Join框架的实现原理" class="headerlink" title="5.Fork/Join框架的实现原理"></a>5.Fork/Join框架的实现原理</h1><p>ForkJoinPool由：</p>
<p><strong>ForkJoinTask数组</strong></p>
<p><strong>ForkJoinWorkerThread数组</strong></p>
<p>组成，ForkJoinTask数组负责将存放程序提交给ForkJoinPool的任务</p>
<p>ForkJoinWorkerThread数组负责执行这些任务。</p>
<h2 id="ForkJoinTask的fork方法实现原理"><a href="#ForkJoinTask的fork方法实现原理" class="headerlink" title="ForkJoinTask的fork方法实现原理"></a>ForkJoinTask的fork方法实现原理</h2><pre><code class="java">    public final ForkJoinTask&lt;V&gt; fork() {
        Thread t;
        if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread)
            ((ForkJoinWorkerThread)t).workQueue.push(this);
        else
            ForkJoinPool.common.externalPush(this);
        return this;
    }</code></pre>
<p>当我们调用ForkJoinTask的fork方法时，程序会调用ForkJoinPool.WorkQueue的push方法，将任务存到workQueue。</p>
<pre><code class="java">        final void push(ForkJoinTask&lt;?&gt; task) {
            ForkJoinTask&lt;?&gt;[] a; ForkJoinPool p;
            int b = base, s = top, n;
            if ((a = array) != null) {    // ignore if queue removed
                int m = a.length - 1;     // fenced write for task visibility
                U.putOrderedObject(a, ((m &amp; s) &lt;&lt; ASHIFT) + ABASE, task);
                U.putOrderedInt(this, QTOP, s + 1);
                if ((n = s - b) &lt;= 1) {
                    if ((p = pool) != null)
                        p.signalWork(p.workQueues, this);
                }
                else if (n &gt;= m)
                    growArray();
            }
        }</code></pre>
<p>如果队列是空的，就唤醒其他任务。</p>
<h2 id="ForkJoinTask的join实现原理"><a href="#ForkJoinTask的join实现原理" class="headerlink" title="ForkJoinTask的join实现原理"></a>ForkJoinTask的join实现原理</h2><p>Join方法的主要作用是阻塞当前线程并等待获取结果。看下ForkJoinTask的join的方法实现。  </p>
<pre><code class="java">    public final V join() {
        int s;
        if ((s = doJoin() &amp; DONE_MASK) != NORMAL)
            reportException(s);
        return getRawResult();
    }</code></pre>
<p> 直接看doJoin方法</p>
<pre><code class="java">    /**
     * Implementation for join, get, quietlyJoin. Directly handles
     * only cases of already-completed, external wait, and
     * unfork+exec.  Others are relayed to ForkJoinPool.awaitJoin.
     *
     * @return status upon completion
     */
    private int doJoin() {
        int s; Thread t; ForkJoinWorkerThread wt; ForkJoinPool.WorkQueue w;
        return (s = status) &lt; 0 ? s :
            ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ?
            (w = (wt = (ForkJoinWorkerThread)t).workQueue).
            tryUnpush(this) &amp;&amp; (s = doExec()) &lt; 0 ? s :
            wt.pool.awaitJoin(w, this, 0L) :
            externalAwaitDone();
    }</code></pre>
<p>查看任务是否完成，如果已完成直接返回；如果没有执行完，则从任务数组里取出任务并执行并设置NORMAL或者EXCEPTIONAL状态。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>Fork/Join 只需要了解其使用方法和应用场景，以及基本的机制即可。总结</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发框架</tag>
        <tag>ForkJoin</tag>
      </tags>
  </entry>
  <entry>
    <title>【数据结构与算法】-【算法】排序</title>
    <url>/2019/10/30/Algorithms_AL_Sort/</url>
    <content><![CDATA[<p>本文将总结众多排序算法中的一小撮，也是最经典、最常用的：冒泡排序、插入排序、选择排序、归并排序、快速排序、计数排序、基数排序、桶排序。依据时间复杂度可以分为三类，我将按照三次来总结。</p>
<table>
<thead>
<tr>
<th>排序算法</th>
<th>时间复杂度</th>
<th>时候基于比较</th>
</tr>
</thead>
<tbody><tr>
<td>冒泡、插入、选择</td>
<td>O(n^2)</td>
<td>是</td>
</tr>
<tr>
<td>快排、归并</td>
<td>O(nlogn)</td>
<td>是</td>
</tr>
<tr>
<td>桶、计数、基数</td>
<td>O(n)</td>
<td>否</td>
</tr>
</tbody></table>
<h1 id="分析排序算法"><a href="#分析排序算法" class="headerlink" title="分析排序算法"></a>分析排序算法</h1><p>学习排序算法，除了要了解算法原理、代码实现、更重要的是学会如何评价、分析一个排序算法。那分析算法应该从哪几个方面入手？</p>
<h2 id="排序算法的执行效率"><a href="#排序算法的执行效率" class="headerlink" title="排序算法的执行效率"></a>排序算法的执行效率</h2><ol>
<li><p>最好情况、最坏情况、平均情况时间复杂度</p>
</li>
<li><p>时间复杂度的系数、常数、低阶</p>
<p>时间复杂度反映的是数据量很大的时候的一个增长趋势，所以它表示的时候会忽略系数、常数、低阶。但实际的软件开发中，我们排序的可能是10个、100个、1000个这样规模很小的数据，所以，在对同一阶时间复杂度的排序算法性能对比的时候，就要把常数、系数、低阶也考虑进来。</p>
</li>
<li><p>比较次数和交换（或移动）次数</p>
<p>基于比较的算法执行过程涉及两个操作，比较元素大小和元素交换或移动。在分析效率的时候，应该把比较次数和交换次数也考虑进去。</p>
</li>
</ol>
<h2 id="排序算法的内存消耗"><a href="#排序算法的内存消耗" class="headerlink" title="排序算法的内存消耗"></a>排序算法的内存消耗</h2><p>算法内存消耗可以通过空间复杂度衡量，排序算法也不例外。<strong>原地排序</strong>，就是特指空间复杂度是O（1）的排序算法。这篇文章马上要说的都是原地排序的算法。</p>
<h2 id="排序算法的稳定性"><a href="#排序算法的稳定性" class="headerlink" title="排序算法的稳定性"></a>排序算法的稳定性</h2><p>针对排序算法还有个重要指标就是<strong>稳定性</strong>。是说，如果待排序的序列存在值相等，经过排序后，相等元素之间的原有的先后顺序不变。</p>
<h1 id="冒泡排序-Bubble-Sort）"><a href="#冒泡排序-Bubble-Sort）" class="headerlink" title="冒泡排序(Bubble Sort）"></a>冒泡排序(Bubble Sort）</h1><h2 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h2><p>冒泡排序只会操作相邻的两个数据。每次冒泡都会对相邻的两个元素比较，看时候满足大小关系要求。如果不满足就相互交换。一次冒泡会至少让一个元素移动到最终的位置（序列的顶端，所以叫冒泡）。重复n次，就完成了n个数据的排序。</p>
<h2 id="算法过程"><a href="#算法过程" class="headerlink" title="算法过程"></a>算法过程</h2><p>举例：4、5、6、3、2、1，按照从小到大排序。</p>
<p>第一次冒泡的详细过程是这样的：</p>
<p><img data-src="/img/in-post/1572576124096.png" alt=""></p>
<p>第一次把最大值6冒泡到最顶端。进行6次这样的冒泡所有的数据都会在自己正确的位置上。</p>
<p><img data-src="/img/in-post/1572576917159.png" alt=""></p>
<p>再来看下冒泡次数，看有没有优化的空间，当每一次比较过程中，发现已经没有泡可以冒了，说明所有的数据都已经在自己正确的位置上到达完全有序。因此可以减少冒泡的次数。看下这个例子：</p>
<p><img data-src="/img/in-post/1572576988715.png" alt=""></p>
<h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><pre><code class="java">
// 冒泡排序，a表示数组，n表示数组大小
public void bubbleSort(int[] a, int n) {
  if (n &lt;= 1) return;

 for (int i = 0; i &lt; n; ++i) {
    // 提前退出冒泡循环的标志位
    boolean flag = false;
    for (int j = 0; j &lt; n - i - 1; ++j) {
      if (a[j] &gt; a[j+1]) { // 交换
        int tmp = a[j];
        a[j] = a[j+1];
        a[j+1] = tmp;
        flag = true;  // 表示有数据交换      
      }
    }
    if (!flag) break;  // 没有数据交换，提前退出
  }
}</code></pre>
<h2 id="算法总结"><a href="#算法总结" class="headerlink" title="算法总结"></a>算法总结</h2><ol>
<li><p>冒泡排序是原地排序算法吗？</p>
<p>是的</p>
<p>只涉及相邻数据的交换操作，只需要常年级的临时空间，所以它的时间复杂度为O（1），是一个原地排序算法。</p>
</li>
<li><p>冒泡排序是稳定的排序算法？</p>
<p>是的</p>
<p>在交换过程中改变元素的先后顺序。为保证稳定，相邻元素如果大小相等就不交换。</p>
</li>
<li><p>冒泡排序的时间复杂度？</p>
<p><img data-src="/img/in-post/1572577527431.png" alt=""></p>
<p>平均时间复杂度是多少？</p>
<p>分析：对于n个数据，有n!的排列方式。不同的排序方式冒泡的执行时间不同。平均情况下，需要n*(n-1)/4次交换操作，比较操作肯定比交换操作多，所以平均复杂度是O(n^2)。</p>
</li>
</ol>
<h1 id="插入排序（Insertion-Sort）"><a href="#插入排序（Insertion-Sort）" class="headerlink" title="插入排序（Insertion Sort）"></a>插入排序（Insertion Sort）</h1><h2 id="算法思想-1"><a href="#算法思想-1" class="headerlink" title="算法思想"></a>算法思想</h2><p><img data-src="/img/in-post/1572578440093.png" alt=""></p>
<p>插入排序的思想就是遍历数组找到数据应该插入的位置将其插入即可。</p>
<p>将数组的数据分为两个区域：<strong>已排序区间</strong>、<strong>未排序区间</strong>。初始状态，已排序区间只有一个数组的第一个元素，算法的核心思想就是取未排序区间中的元素，在已排序的区间中找到合适的位置将其插入，并保持排序区间数据一直有序。重复这个过程，直到为排序区间元素是空。算法结束。</p>
<h2 id="算法过程-1"><a href="#算法过程-1" class="headerlink" title="算法过程"></a>算法过程</h2><p>举例：4、5、6、1、3、2</p>
<p><img data-src="/img/in-post/1572578840689.png" alt=""></p>
<p>满有序度是n*(n-1)/2=15，初始有序度是5，所以逆有序度是10。插入排序中，数据移动的个数总和等于10=3+3+4。</p>
<p><img data-src="/img/in-post/1572579775584.png" alt=""></p>
<h2 id="算法实现-1"><a href="#算法实现-1" class="headerlink" title="算法实现"></a>算法实现</h2><pre><code class="java">// 插入排序，a表示数组，n表示数组大小
public void insertionSort(int[] a, int n) {
  if (n &lt;= 1) return;

  for (int i = 1; i &lt; n; ++i) {
    int value = a[i];
    int j = i - 1;
    // 查找插入的位置
    for (; j &gt;= 0; --j) {
      if (a[j] &gt; value) {
        a[j+1] = a[j];  // 数据移动
      } else {
        break;
      }
    }
    a[j+1] = value; // 插入数据
  }
}</code></pre>
<h2 id="算法总结-1"><a href="#算法总结-1" class="headerlink" title="算法总结"></a>算法总结</h2><ol>
<li><p>插入排序是原地排序吗？<br> 是的，空间复杂度是O（1）</p>
</li>
<li><p>插入排序是稳定的排序算法吗？</p>
<p>是的，在插入排序过程中，对于值相同的元素，可以选择前面的后面出现的元素插入到前面元素的后面，这样就保持顺序不变了。</p>
</li>
<li><p>插入排序的时间复杂度是多少？</p>
<p>最好：O（n）</p>
<p>最坏：O（n^2）</p>
<p>平均：O（n^2）</p>
<p>数组中插入一个元素的时间复杂度是O（n），循环n次，所以是O（n^2）</p>
</li>
</ol>
<h1 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h1><h2 id="算法思想-2"><a href="#算法思想-2" class="headerlink" title="算法思想"></a>算法思想</h2><p>选择排序的思想和插入排序类似，也很已排序区间和未排序区间。但是选择排序每次都会从未排序区间找到最小元素，将其放到已排序区间的末尾。</p>
<p><img data-src="/img/in-post/1572580828378.png" alt=""></p>
<p>算法过程</p>
<p>见上图</p>
<h2 id="算法实现-2"><a href="#算法实现-2" class="headerlink" title="算法实现"></a>算法实现</h2><p>   代码待更新</p>
<h2 id="算法总结-2"><a href="#算法总结-2" class="headerlink" title="算法总结"></a>算法总结</h2><ol>
<li><p>空间复杂度 O（1）</p>
</li>
<li><p>是否稳定：</p>
<p>不稳定，选择排序是一种不稳定的排序算法。每次选择都要找剩余为排序元素中的最小值，并和前面的元素交换位置，这样就破坏了稳定性。比如5、8、5、2、8、9，第一次找到最小元素2，与第一个5交换了位置，这样第一个5就跑到了中间5的后面，这样就破坏了稳定性。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>排序</tag>
      </tags>
  </entry>
  <entry>
    <title>【并发容器和框架】一、CocurrentHashMap的实现原理与使用</title>
    <url>/2019/10/27/java-concurrency-container-ConcurrentHashMap/</url>
    <content><![CDATA[<h1 id="为什么引入ConcurrentHashMap"><a href="#为什么引入ConcurrentHashMap" class="headerlink" title="为什么引入ConcurrentHashMap"></a>为什么引入ConcurrentHashMap</h1><p>在并发编程中使用HashMap可能导致程序死循环。而使用线程安全的HashTable效率又非常低下，基于以上两个原因，便有了ConcurrentHash的出现。</p>
<ul>
<li><p>线程不安全的HashMap</p>
<p>在多线程环境下，使用HashMap进行put操作会引起死循环，是因为多线程会导致HashMap的Entry链表形成环形数据结构，一旦形成环形数据结构，Entry的next节点永远不为空，就会产生死循环获取Entry，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap。</p>
</li>
<li><p>效率低下的的HashTable</p>
<p>HashTable容器使用synchronized来保证线程安全，但在线程竞争激烈的情况下HashTable的效率非常低下。</p>
</li>
<li><p>ConcurrentHashMap的锁分段技术可有效提升并发率</p>
<p>HashTable在高并发下的效率低下的原因是因为所有访问HashTable的线程必须竞争同一把锁，假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争。</p>
<p>存储数据时分成一段段存储，每一段分配一把锁，这样当一个线程访问其中一个段数据时，其他段数据依然可以被其他线程访问。</p>
</li>
</ul>
<p>  分段锁是JDK1.7及其之前的实现技术，JDK1.8并没有使用分段锁技术。</p>
<h1 id="JDK-1-7的ConcurrentHashMap"><a href="#JDK-1-7的ConcurrentHashMap" class="headerlink" title="JDK 1.7的ConcurrentHashMap"></a>JDK 1.7的ConcurrentHashMap</h1><p>ConcurrentHashMap的设计一直在演进中，JDK 1.7和JDK 1.8的ConcurrentHashMap实现存在巨大的差异，公司现在使用的是JDK 1.8，因此我们着重分析JDK 1.8，在此之前1.7也先介绍下。</p>
<h2 id="JDK-1-7的ConcurrentHashMap的结构"><a href="#JDK-1-7的ConcurrentHashMap的结构" class="headerlink" title="JDK 1.7的ConcurrentHashMap的结构"></a>JDK 1.7的ConcurrentHashMap的结构</h2><p>主要结构由：</p>
<ul>
<li>分离锁 <strong>Segment</strong>、Segment内部集成一个<strong>HashEntry</strong>的数组。<ul>
<li>Segment是一种可重入锁，一个ConcurrentHashMap包含一个Segment数组，一个Segment包含一个HashEntry数组。Segment的结构与HashMap类似是一种数组和链表的结构。</li>
<li>每个HashEntry是一个链表结构的元素。</li>
</ul>
</li>
<li>HashEntry内部使用volatile的value字段来保证可见性，也利用了不可变对象的机制以改进利用Unsafe提供的底层能力，比如volatile access，直接完成部分操作，以优化性能，毕竟Unsafe中的很多操作是JVM intrinsic优化过的。</li>
</ul>
<p><img data-src="/img/in-post/image-20191030234301439.png" alt=""></p>
<h2 id="JDK-1-7-ConcurrentHashMap初始化"><a href="#JDK-1-7-ConcurrentHashMap初始化" class="headerlink" title="JDK 1.7 ConcurrentHashMap初始化"></a>JDK 1.7 ConcurrentHashMap初始化</h2><h3 id="1-初始化segment数组"><a href="#1-初始化segment数组" class="headerlink" title="1. 初始化segment数组"></a>1. 初始化segment数组</h3><p>先看源码：</p>
<pre><code class="java">    public ConcurrentHashMap(int initialCapacity,
                             float loadFactor, int concurrencyLevel) {
        if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0)
            throw new IllegalArgumentException();
        if (concurrencyLevel &gt; MAX_SEGMENTS)
            concurrencyLevel = MAX_SEGMENTS;
        // Find power-of-two sizes best matching arguments
        int sshift = 0;
        int ssize = 1;
        while (ssize &lt; concurrencyLevel) {
            ++sshift;
            ssize &lt;&lt;= 1;
        }
        this.segmentShift = 32 - sshift;
        this.segmentMask = ssize - 1;
        if (initialCapacity &gt; MAXIMUM_CAPACITY)
            initialCapacity = MAXIMUM_CAPACITY;
        int c = initialCapacity / ssize;
        if (c * ssize &lt; initialCapacity)
            ++c;
        int cap = MIN_SEGMENT_TABLE_CAPACITY;
        while (cap &lt; c)
            cap &lt;&lt;= 1;
        // create segments and segments[0]
        Segment&lt;K,V&gt; s0 =
            new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor),
                             (HashEntry&lt;K,V&gt;[])new HashEntry[cap]);
        Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize];
        UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0]
        this.segments = ss;
    }</code></pre>
<p>Segments的长度ssize由concurrencyLevel计算得到。为了能通过按位与的散列算法来定位segment数组的索引，必须保证segments数组的长度是2的N次方，所以必须计算出一个大于等于concurrencyLevel的最小的2的N次方值作为segments的长度。假如concurrencyLevel等于14、15或16，ssize都会等于16，即容器里锁的个数也是16。</p>
<h3 id="2-初始化segmentShift和segmentMask"><a href="#2-初始化segmentShift和segmentMask" class="headerlink" title="2. 初始化segmentShift和segmentMask"></a>2. 初始化segmentShift和segmentMask</h3><p>这两个全局变量是用来定位segment的散列算法里使用的，sshift等于ssize从1向左移位的次数。concurrencyLevel默认等于16，所以sshift等于4。</p>
<ul>
<li>segmentShift用与定位参与散列运算的位数，segmentShift等于32减sshift，所以等于28（之所以是32是因为hash()的最大输出是32）。</li>
<li>segmentMask是散列运算的掩码，等于ssize减1，即15，掩码的二进制各位都是1.因为ssize的最大值都是65536，所以segmentShift最大值是16，segmentMask最大值是65535，对应的二进制是16位，每个位都是1。</li>
</ul>
<h3 id="3-初始化每个segment"><a href="#3-初始化每个segment" class="headerlink" title="3. 初始化每个segment"></a>3. 初始化每个segment</h3><p>cap是每个segment里的HashEntry数组的长度，它等于initialCapacity/ssize的倍数c。</p>
<p>segment的容量threshold=(int)cap*loadFactor，默认情况下initialCapacity等于16，loadfactor等于0.75。</p>
<p><strong>可以看到这里的segment元素就类似于原先HashMap的结构，segment的每个元素内都存有类似HashMap的数组链表结构</strong>(如上图)。</p>
<h2 id="如何定位Segment"><a href="#如何定位Segment" class="headerlink" title="如何定位Segment"></a>如何定位Segment</h2><p>ConcurrentHashMap使用分段锁Segment来保护不同段的数据，那么在插入和获取元素时，必须先通过散列算法来定位到Segment。</p>
<pre><code class="java">   private static int hash(int h) {
        // Spread bits to regularize both segment and index locations,
        // using variant of single-word Wang/Jenkins hash.
        h += (h &lt;&lt;  15) ^ 0xffffcd7d;
        h ^= (h &gt;&gt;&gt; 10);
        h += (h &lt;&lt;   3);
        h ^= (h &gt;&gt;&gt;  6);
        h += (h &lt;&lt;   2) + (h &lt;&lt; 14);
        return h ^ (h &gt;&gt;&gt; 16);
    }</code></pre>
<p>首先会使用Wang/Jekins hash的变种算法对元素的hashCode进行一次再散列，之所进行再散列是为了避免散列冲突，使元素均匀地分布在不同的Segment上，从而提高容器的存取效率。ConcurrentHashMap通过以上hash算法对hashCode计算出的hash值以后再通过以下散列算法定位segment。</p>
<pre><code class="java">    private Segment&lt;K,V&gt; segmentForHash(int h) {
        long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE;
        return (Segment&lt;K,V&gt;) UNSAFE.getObjectVolatile(segments, u);
    }</code></pre>
<p>默认情况下segmentShift为28，segmentMask为15，再散列后的数最大是32位二进制数据。</p>
<p>向右无符号移动28位，相当于让高4位参与到散列运算中，<code>(h &gt;&gt;&gt; segmentShift) &amp; segmentMask</code>的运算结构是4、15、7和8，可以看到散列值没有发生冲突。</p>
<h2 id="JDK-1-7-ConcurrentHashMap的操作"><a href="#JDK-1-7-ConcurrentHashMap的操作" class="headerlink" title="JDK 1.7 ConcurrentHashMap的操作"></a>JDK 1.7 ConcurrentHashMap的操作</h2><p>主要介绍get 、put、size操作。</p>
<h3 id="get操作"><a href="#get操作" class="headerlink" title="get操作"></a>get操作</h3><pre><code class="java">    public V get(Object key) {
        Segment&lt;K,V&gt; s; // manually integrate access methods to reduce overhead
        HashEntry&lt;K,V&gt;[] tab;
        int h = hash(key.hashCode());
        long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE;
        if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp;
            (tab = s.table) != null) {
            for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile
                     (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE);
                 e != null; e = e.next) {
                K k;
                if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k)))
                    return e.value;
            }
        }
        return null;
    }</code></pre>
<p>get的高效之处在于，整个get过程不加锁，主要通过UNSAFE的getObjectVolatile方法获取值，即直接获取volatile的值。</p>
<p><code>UNSAFE.getObjectVolatile(tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE)</code>获取HashEntry数组节点表示的链表元素时定位的<code>(tab.length - 1) &amp; h)</code>直接使用的是再散列后的值，而定位segment是通过再散列的值的高位来定位的。</p>
<p>其目的是避免两次散列后的值一样，虽然元素Segment里散列开了，但却没有在HashEntry里散列开来。</p>
<h3 id="put操作"><a href="#put操作" class="headerlink" title="put操作"></a>put操作</h3><p>在操作共享变量时必须加锁。put方法首先定位到Segment，然后在Segment里进行插入操作。</p>
<pre><code class="java">    public V put(K key, V value) {
        Segment&lt;K,V&gt; s;
        if (value == null)
            throw new NullPointerException();
        int hash = hash(key.hashCode());
        int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask;
        if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject          // nonvolatile; recheck
             (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) //  in ensureSegment
            s = ensureSegment(j);
        return s.put(key, hash, value, false);
    }</code></pre>
<p>Segment的插入操作：</p>
<pre><code class="java">        final V put(K key, int hash, V value, boolean onlyIfAbsent) {
            HashEntry&lt;K,V&gt; node = tryLock() ? null :
                scanAndLockForPut(key, hash, value);
            V oldValue;
            try {
                HashEntry&lt;K,V&gt;[] tab = table;
                int index = (tab.length - 1) &amp; hash;
                HashEntry&lt;K,V&gt; first = entryAt(tab, index);
                for (HashEntry&lt;K,V&gt; e = first;;) {
                    if (e != null) {
                        K k;
                        if ((k = e.key) == key ||
                            (e.hash == hash &amp;&amp; key.equals(k))) {
                            oldValue = e.value;
                            if (!onlyIfAbsent) {
                                e.value = value;
                                ++modCount;
                            }
                            break;
                        }
                        e = e.next;
                    }
                    else {
                        if (node != null)
                            node.setNext(first);
                        else
                            node = new HashEntry&lt;K,V&gt;(hash, key, value, first);
                        int c = count + 1;
                        if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY)
                            rehash(node);
                        else
                            setEntryAt(tab, index, node);
                        ++modCount;
                        count = c;
                        oldValue = null;
                        break;
                    }
                }
            } finally {
                unlock();
            }
            return oldValue;
        }</code></pre>
<ol>
<li><p>是否需要扩容</p>
<p>在插入元素要判断<code>c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY</code>是否超过阈值，超过需要对数组扩容rehash。这扩容方式比HashMap更合理，HashMap是在插入元素后看是否达到容量扩容的，而如果后续没有新元素了，那这次扩容就变多余了，而ConcurrentHashMap是在插入元素前判断的。</p>
</li>
<li><p>如何扩容</p>
<p>在扩容的时候，首先会创建一个容量是原来两倍的数组，然后将原有数组里的元素进行再散列后插入到新数组里。为了高效，ConcurrentHashMap不会对整个容器进行扩容，而只对某个segment进行扩容。</p>
</li>
</ol>
<h3 id="size操作"><a href="#size操作" class="headerlink" title="size操作"></a>size操作</h3><pre><code class="java">    public int size() {
        // Try a few times to get accurate count. On failure due to
        // continuous async changes in table, resort to locking.
        final Segment&lt;K,V&gt;[] segments = this.segments;
        int size;
        boolean overflow; // true if size overflows 32 bits
        long sum;         // sum of modCounts
        long last = 0L;   // previous sum
        int retries = -1; // first iteration isn&#39;t retry
        try {
            for (;;) {
                if (retries++ == RETRIES_BEFORE_LOCK) {
                    for (int j = 0; j &lt; segments.length; ++j)
                        ensureSegment(j).lock(); // force creation
                }
                sum = 0L;
                size = 0;
                overflow = false;
                for (int j = 0; j &lt; segments.length; ++j) {
                    Segment&lt;K,V&gt; seg = segmentAt(segments, j);
                    if (seg != null) {
                        sum += seg.modCount;
                        int c = seg.count;
                        if (c &lt; 0 || (size += c) &lt; 0)
                            overflow = true;
                    }
                }
                if (sum == last)
                    break;
                last = sum;
            }
        } finally {
            if (retries &gt; RETRIES_BEFORE_LOCK) {
                for (int j = 0; j &lt; segments.length; ++j)
                    segmentAt(segments, j).unlock();
            }
        }
        return overflow ? Integer.MAX_VALUE : size;
    }</code></pre>
<p>直接统计每个Segment下的count值，显然不安全。又或者把segment的put、remove、clean方法全部锁住，但是这种方式非常低效。</p>
<p>CountHashMap的做法是：</p>
<p>线程尝试2次不锁住Segment的方式来统计个Segment大小，如果统计过程中，容器count值发生改变，则再采用加锁的方式来统计所有Segment的大小。</p>
<p>那么，ConcurrentHashMap是如何判断在统计的时候容器是否发生了变化了呢？答案是，跟之前一样使用modCount变量，在put、remove和clean方法里操作元素前都会讲变量modCount进行加1，那么在统计size前后比较modeCount是否发生变化，从而得知容器大小是否发生改变。</p>
<h1 id="JDK-1-8-之后的ConcurrentHashMap"><a href="#JDK-1-8-之后的ConcurrentHashMap" class="headerlink" title="JDK 1.8+之后的ConcurrentHashMap"></a>JDK 1.8+之后的ConcurrentHashMap</h1><p>在JDK1.8之后，ConcurrentHashMap发生了那些变化呢？</p>
<ul>
<li>总体结构上，它的内部存储变得与HashMap结构非常类似，同样是大的桶(数组)，然后内部也是一个个所谓的链表结构(bin)，同步的粒度更细致一些。</li>
<li>其内部仍然有Segment定义，但仅仅是位了保证序列化时的兼容性而已，不再有任何结构上的用处。</li>
<li>因为不再使用Segment，初始化操作大大简化，改为lazy-load形式，这样可以有效避免初始开销，解决了老版本很多人抱怨的这一点。</li>
<li>数据存储利用volatile来保证可见性。</li>
<li>使用CAS等操作，在特定场景下进行无锁并发操作。</li>
<li>使用Unsafe、LongAdder之类的底层手段，进行极端情况的优化。</li>
</ul>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><pre><code class="java">    static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {
        final int hash;
        final K key;
        volatile V val;
        volatile Node&lt;K,V&gt; next;

                //其他代码略
    }</code></pre>
<p>这里不在介绍get和构造函数了，直接来看put的源码是怎么实现的。</p>
<h2 id="put操作-1"><a href="#put操作-1" class="headerlink" title="put操作"></a>put操作</h2><pre><code class="java">    final V putVal(K key, V value, boolean onlyIfAbsent) {
        if (key == null || value == null) throw new NullPointerException();
        int hash = spread(key.hashCode());
        int binCount = 0;
        for (Node&lt;K,V&gt;[] tab = table;;) {
            Node&lt;K,V&gt; f; int n, i, fh;
            if (tab == null || (n = tab.length) == 0)
                tab = initTable();
            else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) {
              //(1)利用CAS进行无锁线程安全操作，如果修改元素数组链表的对应元素为空，曾使用cas设置数组的元素作为链表的头元素
                if (casTabAt(tab, i, null,
                             new Node&lt;K,V&gt;(hash, key, value, null)))
                    break;                   // no lock when adding to empty bin
            }
            else if ((fh = f.hash) == MOVED)
                tab = helpTransfer(tab, f);
            else {
                V oldVal = null;
                synchronized (f) { //(2)
                    if (tabAt(tab, i) == f) {//double check f
                        if (fh &gt;= 0) {
                            binCount = 1;
                            for (Node&lt;K,V&gt; e = f;; ++binCount) {
                                K ek;
                                if (e.hash == hash &amp;&amp;
                                    ((ek = e.key) == key ||
                                     (ek != null &amp;&amp; key.equals(ek)))) {
                                    oldVal = e.val;
                                    if (!onlyIfAbsent)
                                        e.val = value;
                                    break;
                                }
                                Node&lt;K,V&gt; pred = e;
                                if ((e = e.next) == null) {
                                    pred.next = new Node&lt;K,V&gt;(hash, key,
                                                              value, null);
                                    break;
                                }
                            }
                        }
                        else if (f instanceof TreeBin) { //树化节点
                            Node&lt;K,V&gt; p;
                            binCount = 2;
                            if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,
                                                           value)) != null) {
                                oldVal = p.val;
                                if (!onlyIfAbsent)
                                    p.val = value;
                            }
                        }
                    }
                }
                if (binCount != 0) {
                    if (binCount &gt;= TREEIFY_THRESHOLD)//(3)超过树化阈值
                        treeifyBin(tab, i);
                    if (oldVal != null)
                        return oldVal;
                    break;
                }
            }
        }
        addCount(1L, binCount);
        return null;
    }</code></pre>
<ul>
<li>(1) 利用CAS进行无锁线程安全操作，如果修改元素数组链表的对应元素为空，曾使用cas设置数组的元素作为链表的头元素</li>
<li>(2) 根据如果当前链表的头节点也就是table数组元素f非空，那么对f加锁并插入f对应的链表中。当然如果f是树化节点TreeBin，则以树化的方式插入。这里tabAt调用了两次一次是判断是不是空的时候，一次是重新定位判断是不是f本身，都是为了避免f已经被人修改的线程安全问题。</li>
<li>(3)如果当前链表长度Bin的大小大于树化的阈值TREEIFY_THRESHOLD(默认8)则进行树化。</li>
</ul>
<p>这里有几处优化，如：</p>
<ul>
<li>一处是当链表对应头节点组成的数组元素是空的时候需要调用<code>tab = initTable();</code>来初始化当前新增元素作为链表数组的一个元素。</li>
</ul>
<pre><code class="java">    private final Node&lt;K,V&gt;[] initTable() {
        Node&lt;K,V&gt;[] tab; int sc;
        while ((tab = table) == null || tab.length == 0) {
            if ((sc = sizeCtl) &lt; 0)
                Thread.yield(); // lost initialization race; just spin
            else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
                try {
                    if ((tab = table) == null || tab.length == 0) {
                        int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY;
                        @SuppressWarnings(&quot;unchecked&quot;)
                        Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];
                        table = tab = nt;
                        sc = n - (n &gt;&gt;&gt; 2);
                    }
                } finally {
                    sizeCtl = sc;
                }
                break;
            }
        }
        return tab;
    }
</code></pre>
<p>这里用了<code>compareAndSwapInt</code> 并且使用volatile变量SIZECTL控制数组容量这个共享变量的线程安全。</p>
<ul>
<li>第二处是在定位hash位置处的链表头节点元素时：</li>
</ul>
<pre><code class="java">static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) {
    return (Node&lt;K,V&gt;)U.getObjectAcquire(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);
}</code></pre>
<p>通过使用Unsafe进行优化，避免间接调用的开销。</p>
<h2 id="size操作-1"><a href="#size操作-1" class="headerlink" title="size操作"></a>size操作</h2><pre><code class="java">    public int size() {
        long n = sumCount();
        return ((n &lt; 0L) ? 0 :
                (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE :
                (int)n);
    }</code></pre>
<p>其中sumCount源码如下：</p>
<pre><code class="java">    /**
     * A padded cell for distributing counts.  Adapted from LongAdder
     * and Striped64.  See their internal docs for explanation.
     */
    @sun.misc.Contended static final class CounterCell {
        volatile long value;
        CounterCell(long x) { value = x; }
    }

    final long sumCount() {
        CounterCell[] as = counterCells; CounterCell a;
        long sum = baseCount;
        if (as != null) {
            for (int i = 0; i &lt; as.length; ++i) {
                if ((a = as[i]) != null)
                    sum += a.value;
            }
        }
        return sum;
    }</code></pre>
<p>这里的计数用到了CounterCell这个类，数据一致性是怎么保证的？</p>
<p>对于CounterCell的操作，是基于<code>java.util.concurrent.atomic.LongAdder</code>进行的，是一种利用空间换时间的更高效的方法了，利用了Striped64内部的复杂逻辑。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://my.oschina.net/pingpangkuangmo/blog/817973" target="_blank" rel="noopener">* jdk1.8的HashMap和ConcurrentHashMap </a></p>
<p><a href="https://www.wanaright.com/2018/09/30/java10-concurrenthashmap-no-segment-lock/" target="_blank" rel="noopener">Java8之后的ConcurrentHashMap, 舍弃分段锁</a></p>
<p><a href="https://cloud.tencent.com/developer/article/1509556" target="_blank" rel="noopener">java8的ConcurrentHashMap为何放弃分段锁</a> 这篇文章讲到了jdk 1.7分段锁的劣势</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发容器</tag>
        <tag>ConcurrentHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title>【数据结构与算法】-【数据结构篇】链表</title>
    <url>/2019/10/22/Algorithms_DS_DS_Link/</url>
    <content><![CDATA[<h1 id="五花八门的链表结构"><a href="#五花八门的链表结构" class="headerlink" title="五花八门的链表结构"></a>五花八门的链表结构</h1><p>相比数组，线性表中的链表是一种稍复杂的数据结构。</p>
<p>先看<strong>底层的存储结构</strong>，</p>
<p>数组需要一块<strong>连续的内存空间</strong>，对内存要求比较高。如果没有连续的足够内存会申请失败。</p>
<p>链表相反，<strong>不需要一块连续的内存空间</strong>，通过“指针”将一组<strong>零散的内存块</strong>串联起来。</p>
<p><img data-src="/img/in-post/1571713260510.png" alt=""></p>
<p>常用的链表主要有：<strong>单链表、双向链表、循环链表（包括双向循环链表）</strong>。</p>
<h1 id="单链表"><a href="#单链表" class="headerlink" title="单链表"></a>单链表</h1><p><img data-src="/img/in-post/1571715568453.png" alt=""></p>
<p><img data-src="/img/in-post/1571715598599.png" alt=""></p>
<h1 id="循环链表"><a href="#循环链表" class="headerlink" title="循环链表"></a>循环链表</h1><p><img data-src="/img/in-post/1571715622681.png" alt=""></p>
<h1 id="双向链表"><a href="#双向链表" class="headerlink" title="双向链表"></a>双向链表</h1><p><img data-src="/img/in-post/1571715634978.png" alt=""></p>
<h2 id="双向循环链表"><a href="#双向循环链表" class="headerlink" title="双向循环链表"></a>双向循环链表</h2><p><img data-src="/img/in-post/1571715676227.png" alt=""></p>
<h1 id="链表VS数组比拼"><a href="#链表VS数组比拼" class="headerlink" title="链表VS数组比拼"></a>链表VS数组比拼</h1>]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title>【线程互斥篇】六、无锁方案-原子操作的实现原理</title>
    <url>/2019/09/01/2019-9-01-java-concurrency-mutex-atomic/</url>
    <content><![CDATA[<h1 id="原子性问题"><a href="#原子性问题" class="headerlink" title="原子性问题"></a>原子性问题</h1><p>在计算机硬件优化导致的3大BUG源头中，其中有一大源头就是原子性的问题，见<a href="[http://zhoulei.site/2019/04/11/java-concurreny-concept-3Bug/#bug%E7%9A%84%E6%BA%90%E5%A4%B4%E4%BA%8C%E7%BA%BF%E7%A8%8B%E5%88%87%E6%8D%A2%E5%B8%A6%E6%9D%A5%E7%9A%84%E5%8E%9F%E5%AD%90%E6%80%A7%E9%97%AE%E9%A2%98](http://zhoulei.site/2019/04/11/java-concurreny-concept-3Bug/#bug的源头二线程切换带来的原子性问题)">线程切换带来的原子性问题</a>，解决原子性问题的一大方案是<strong>1）有锁方案：synchronized或者互斥锁Lock</strong>，当然这种锁有一个缺陷：需要加锁、解锁、本身加锁、释放锁性能消耗大，而且拿不到锁的线程还会进入阻塞状态，进而触发线程切换，线程切换对性能的消耗也很大。</p>
<p>当然还有一种<strong>2）无锁方案就是CAS自旋来实现变量的并发操作的原子操作</strong>。下面就来详细讲下CPU的原子操作并引入CAS指令到Java中来实现Java的原子操作，并且Java提供了Atomic包的多个原子操作的封装。</p>
<p>下面这篇博客是要来说清楚Java解决原子性问题</p>
<h1 id="原子操作的实现原理"><a href="#原子操作的实现原理" class="headerlink" title="原子操作的实现原理"></a>原子操作的实现原理</h1><h2 id="术语定义"><a href="#术语定义" class="headerlink" title="术语定义"></a>术语定义</h2><table>
<thead>
<tr>
<th>术语名称</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td>缓存行</td>
<td>缓存的最小操作单元</td>
</tr>
<tr>
<td>比较并交换</td>
<td>CAS操作需要输入两个数值，一个旧值(期望操作前的值)和一个新值，在操作期间先比较旧值有没有发生变化，如果没有发生变化，才交换成新值，发生了则不交换</td>
</tr>
<tr>
<td>CPU流水线</td>
<td>CPU流水线的工作方式就像工业生产上的装配流水线，在CPU中由5<del>6个不同功能的电路单元组成一条指令处理流水线，然后将一条X86指令分成5</del>6步后再由这些电路单元分别执行，这样就能实现在一个CPU时钟周期完成一条指令，因此提高了CPU的运算速度。</td>
</tr>
<tr>
<td>内存顺序冲突</td>
<td>内存顺序冲突一般是由假共享引起的，假共享是指多个CPU同时修改同一个缓存行的不同部分而引起其中一个CPU的操作无效，当出现这个内存顺序冲突时，CPU必须清空流水线</td>
</tr>
</tbody></table>
<h2 id="CPU如何实现原子操作"><a href="#CPU如何实现原子操作" class="headerlink" title="CPU如何实现原子操作"></a>CPU如何实现原子操作</h2><p>32位IA-32 CPU使用基于<strong>缓存加锁、总线加锁</strong>的方式实现多处理器之间的原子操作。</p>
<ul>
<li>首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节数，其他处理器不能访问这个字节的内存地址。</li>
<li>Pentium 6和最新处理器能自动保证<strong>单</strong>处理器对同一个缓存行里进行16/32/64位的操作是原子的</li>
</ul>
<p>但是复杂的内存处理器是不能自动保证其原子性的，比如跨总线宽度、跨多个缓存行和跨页表的访问。但是处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。</p>
<h3 id="总线锁定与缓存锁定"><a href="#总线锁定与缓存锁定" class="headerlink" title="总线锁定与缓存锁定"></a>总线锁定与缓存锁定</h3><ol>
<li><p>使用总线锁保证原子性</p>
<p>经典的i++读改写操作就不是原子的，就是因为共享变量在多个处理器同时操作时，同时从各自的缓存中读取变量i，分别进行加1操作，然后分别写入系统内存中。那么，<strong>想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量，CPU2不能操作缓存了该变量内存地址的缓存。</strong></p>
<p>处理器使用总线锁就是来解决这个问题的。<strong>所谓总线锁就是使用处理器提供的一个LOCK#信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占贡献内存</strong>。</p>
</li>
<li><p>使用缓存锁保证原子性</p>
<p>同一个时刻，只需要保证对某个内存地址的操作是原子性即可，但总线锁定把CPU和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以开销比较大。</p>
</li>
</ol>
<p>   目前处理器在某些场合下使用缓存锁定代替总线锁来进行优化。频繁使用的内存会缓存在处理器的L1、L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，而不需要声明总线锁。</p>
<p>   在Pentium 6和目前的处理中可以使用”缓存锁定”的方式来实现复杂的原子性。所谓”缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在Lock期间被锁定，那么当它执行锁操作写回到内存时，处理器不在总线上声明LOCK#信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性。</p>
<ul>
<li>针对以上两种机制：Intel处理器提供了很多Lock前缀的指令来实现。例如，位测试和修改指令：BTS\BTR\BTC；交换指令XADD\CMPXCHG以及其他一些操作数和逻辑指令(如ADD、OR)等，被这些指令操作的内存区域就会加锁。</li>
</ul>
<ul>
<li><p>有两种情况下处理器不会使用缓存锁定</p>
<p>第一种情况：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行时，则处理器会调动总线锁定。</p>
<p>第二种情况：有些处理器不支持缓存锁定。对于Intel 486和Pentium处理器，就算锁定的内存区域在处理器的缓存行也会调用总线锁定。</p>
</li>
</ul>
<h2 id="Java如何实现原子操作——使用CAS自旋实现原子操作"><a href="#Java如何实现原子操作——使用CAS自旋实现原子操作" class="headerlink" title="Java如何实现原子操作——使用CAS自旋实现原子操作"></a>Java如何实现原子操作——使用CAS自旋实现原子操作</h2><ul>
<li><p>非线程安全问题代码：在多线程并发时，count共享变量存在可见性与count++的原子性问题</p>
<pre><code class="java">public class Test {
  long count = 0;
  void add10K() {
    int idx = 0;
    while(idx++ &lt; 10000) {
      count += 1;
    }
  }
}</code></pre>
</li>
</ul>
<ul>
<li><p>线程安全代码：使用无锁方案——引入原子类实现累加的线程安全</p>
<p>将count类型换成java的原子类型AtomicLong</p>
<pre><code class="java">public class Test {
  AtomicLong count = 
    new AtomicLong(0);
  void add10K() {
    int idx = 0;
    while(idx++ &lt; 10000) {
      count.getAndIncrement();
    }
  }
}</code></pre>
</li>
</ul>
<p>基于CPU支持的Lock前缀的指令，可以通过总线锁定或缓存锁定两种机制来实现共享变量的原子操作，<strong>Java通过CPU级别的CAS(比较并交换操作)来实现基于CAS操作自旋的方式，来实现原子操作</strong>。</p>
<h3 id="CPU的CAS指令"><a href="#CPU的CAS指令" class="headerlink" title="CPU的CAS指令"></a>CPU的CAS指令</h3><p>下面看下，CPU的CAS指令相关概念：</p>
<blockquote>
<p>cmpxchg是汇编指令<br>作用：比较并交换操作数.<br>如：CMPXCHG r/m,r 将累加器AL/AX/EAX/RAX中的值与首操作数（目的操作数）比较，如果相等，第2操作数（源操作数）的值装载到首操作数，zf置1。如果不等， 首操作数的值装载到AL/AX/EAX/RAX并将zf清0<br>该指令只能用于486及其后继机型。第2操作数（源操作数）只能用8位、16位或32位寄存器。第1操作数（目地操作数）则可用寄存器或任一种存储器寻址方式。这篇文章给了两种汇编使用示例，连接如下：<a href="https://blog.csdn.net/xiuye2015/article/details/53406432" target="_blank" rel="noopener">https://blog.csdn.net/xiuye2015/article/details/53406432</a></p>
</blockquote>
<blockquote>
<p>CAS的全称为Compare-And-Swap，是一条CPU的原子指令，其作用是让CPU比较后原子地更新某个位置的值，经过调查发现，其实现方式是基于硬件平台的汇编指令，就是说CAS是靠硬件实现的，JVM只是封装了汇编调用，那些AtomicInteger类便是使用了这些封装后的接口。</p>
<p>——<a href="https://blog.csdn.net/u011277123/article/details/90699065" target="_blank" rel="noopener">https://blog.csdn.net/u011277123/article/details/90699065</a></p>
</blockquote>
<p>CAS实际就是系统原语，由若干机器指令构成，具有不可分割的特性，其实就是汇编指令cmpxchg。</p>
<p><strong>CAS有3个操作数：</strong></p>
<ul>
<li><p>需要读写内存位置V，</p>
</li>
<li><p>进行比较的预期值A</p>
</li>
<li><p>要修改的新值B。</p>
</li>
</ul>
<p>举例：下面以计算count++为例(当前count为56)：</p>
<p>  <img data-src="/img/in-post/image-20191017233523441.png" alt=""></p>
<p>线程T1和线程T2同时去更新共享变量此时共享变量值为56，T1先更新比较当前内存值与预期的值一致，则内存中设置变量为57，此时T2本地内存得到的是56并且准备更新到57，此时将预期的56与内存中57比较，不相等（已经被T1更新过了）则返回更新失败，并且更新本地预期值57并继续循环尝试更新（<strong>称为”自旋“</strong>，就是当更新失败时使用当前新值作为预期值循环尝试更新，直到成功）内存值为58直到更新成功。</p>
<p>就是指当两者进行比较时，如果相等，则证明共享数据没有被修改，替换成新值，然后继续往下运行；如果不相等，说明共享数据已经被修改，放弃已经所做的操作，然后重新执行刚才的操作。容易看出 CAS 操作是基于共享数据不会被修改的假设，当同步冲突出现的机会很少时，这种假设能带来较大的性能提升。</p>
<p>假如底层不调用CPU的CAS指令的话，自己去模拟实现，其过程代码原理是这样的：</p>
<pre><code class="java">class SimulatedCAS{
  volatile int count;
  // 实现 count+=1
  addOne(){
    do {
      newValue = count+1; //①
    }while(count !=
      cas(count,newValue) //②
  }
  // 模拟实现 CAS，仅用来帮助理解
  synchronized int cas(
    int expect, int newValue){
    // 读目前 count 的值
    int curValue = count;
    // 比较目前 count 值是否 == 期望值
    if(curValue == expect){
      // 如果是，则更新 count 的值
      count= newValue;
    }
    // 返回写入前的值
    return curValue;
  }
}
</code></pre>
<h3 id="看Java如何实现原子的count-1"><a href="#看Java如何实现原子的count-1" class="headerlink" title="看Java如何实现原子的count+1"></a>看Java如何实现原子的count+1</h3><p>以AtomicLong为例，使用getAndIncrement来代替count++，其源码【JDK8】如下：</p>
<pre><code class="java">    public final long getAndIncrement() {
        return unsafe.getAndAddLong(this, valueOffset, 1L);
    }
</code></pre>
<p>其会调用unsafe的getAndLong方法，代码如下：</p>
<pre><code class="java">    public final long getAndAddLong(Object var1, long var2, long var4) {
        long var6;
        do {
            var6 = this.getLongVolatile(var1, var2);
        } while(!this.compareAndSwapLong(var1, var2, var6, var6 + var4));

        return var6;
    }</code></pre>
<p>可以看到这个unsafe的getAndAddLong的方法使用了自旋来确保线程更新数据成功，这里面有两个重要的native方法：</p>
<ol>
<li><p>this.getLongVolatile(var1, var2)</p>
<p>这个方法是为了获取当前更新的最新值（通过方法名可以看到这个方法获取的共享变量更新对于各线程是可见的），并且作为下一次更新的预期值(所谓预期，就是值没有被其他线程修改该)。</p>
</li>
<li><p>this.compareAndSwapLong(var1, var2, var6, var6 + var4) </p>
<p>这个值用来判断当前cas更新是否成功，这个方法是将此次需要累加的var4(这里计算+1的话就是1)，并且返回是否更新成功，如果返回false更新失败，则当前线程继续尝试更新，直到更新成功(自旋)。</p>
</li>
</ol>
<h1 id="CAS实现原子操作同时带来的三大问题"><a href="#CAS实现原子操作同时带来的三大问题" class="headerlink" title="CAS实现原子操作同时带来的三大问题"></a>CAS实现原子操作同时带来的三大问题</h1><h2 id="1）ABA问题"><a href="#1）ABA问题" class="headerlink" title="1）ABA问题"></a>1）ABA问题</h2><p>当上面T1和T2操作的时候，假如还有一个线程T3，在T1将值改为56时，在T2准备计算值之前又有T3将值-1改为了56，此时T2检测出值没有发生变化，事实上值被T3修改过，这就是所谓的”ABA”问题。这对于数值型计算问题来说没什么问题，如果对引用类型的变量更新就可能导致部分字段已经被更新了而其他线程却没检测。</p>
<h3 id="解决方案——版本号"><a href="#解决方案——版本号" class="headerlink" title="解决方案——版本号"></a>解决方案——版本号</h3><p>ABA问题的解决思路是使用版本号。在变量前面追加上版本号，每次更新的时候把版本号加1，那么A-&gt;B-&gt;就会变成1A-&gt;2B-3a。从JDK 1.5开始，JDK的Atomic包里提供了类AtomicMarkableReference和AtomicStampedReference：</p>
<p>AtomicStampedReference在实现CAS时方法时新增了版本号：</p>
<pre><code class="java">    public boolean compareAndSet(V   expectedReference,
                                 V   newReference,
                                 int expectedStamp,
                                 int newStamp) {
        Pair&lt;V&gt; current = pair;
        return
            expectedReference == current.reference &amp;&amp;
            expectedStamp == current.stamp &amp;&amp;
            ((newReference == current.reference &amp;&amp;
              newStamp == current.stamp) ||
             casPair(current, Pair.of(newReference, newStamp)));
    }</code></pre>
<p>AtomicMarkableReference在解决ABA时，实现更简单，在参数中增加了一个Boolean值：</p>
<pre><code class="java">boolean compareAndSet(
  V expectedReference,
  V newReference,
  boolean expectedMark,
  boolean newMark)
}</code></pre>
<h2 id="2）循环时间长开销大"><a href="#2）循环时间长开销大" class="headerlink" title="2）循环时间长开销大"></a>2）循环时间长开销大</h2><p>自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能够支持处理器提供的pause指令，那么效率会有一定的提升。pause指令有两个作用：第一，它可以延迟流水线执行指令，使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零；第二，它可以避免在退出循环时因内存顺序冲突而引起CPU流水线被清空，从而提高CPU的执行效率。</p>
<h2 id="3）只能保证一个共享变量的原子操作"><a href="#3）只能保证一个共享变量的原子操作" class="headerlink" title="3）只能保证一个共享变量的原子操作"></a>3）只能保证一个共享变量的原子操作</h2><p>当对一个共享变量执行操作时，可以使用循环CAS的方式来保证原子操作，但对多个共享变量操作时，循环CAS就没办法原子性，这时候可以用锁。还有技巧就是，可以把多个共享变量合并成一个共享变量来操作。当然从java 1.5开始可以使用AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一共变量里进行CAS操作。</p>
<h1 id="Java原子类型"><a href="#Java原子类型" class="headerlink" title="Java原子类型"></a>Java原子类型</h1><p>主要有原子化的基本数据类型、原子性的对象引用类型，原子化数组，原子化对象属性更新器，原子化的累加器。详细见：</p>
<p><a href="https://time.geekbang.org/column/article/90515?utm_term=zeusNPTKC&amp;utm_source=appsocial&amp;utm_medium=geektime&amp;utm_campaign=156-presell&amp;utm_content=banner0211" target="_blank" rel="noopener">https://time.geekbang.org/column/article/90515?utm_term=zeusNPTKC&amp;utm_source=appsocial&amp;utm_medium=geektime&amp;utm_campaign=156-presell&amp;utm_content=banner0211</a></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>在多线对某个共享变量进行操作时，特别是对数值进行加减等基本数值操作时，可以使用Java的原子类型替换普通变量。</p>
<p>Java的原子类型的原子性的实现原理主要是通过调用CPU的CAS指令来实现，而指令本身就是原子的，因此保证了共享变量的原子性更新。<strong>同时原子类型也具有可见性</strong>。</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
        <tag>互斥</tag>
        <tag>原子操作</tag>
      </tags>
  </entry>
  <entry>
    <title>【线程互斥篇】五、无锁方案-不可变性final与内存语义</title>
    <url>/2019/08/23/2019-8-23-java-concurrency-mutex-final/</url>
    <content><![CDATA[<h1 id="不可变性模型与final"><a href="#不可变性模型与final" class="headerlink" title="不可变性模型与final"></a>不可变性模型与final</h1><p>见<a href="https://zhoulei17.github.io/2019/05/15/java-concurreny-how-to-dev-objshare/" target="_blank" rel="noopener">并发线程共享变量的安全性问题</a>，前面讲了解决并发共享变量的问题除了采用互斥访问外使用volatile、原子类来解决可见性与原子等特定问题场景下的方案。其中，synchronized、lock方案是有锁方案，而volatile、Atomic方案为无锁方案，还有一种无锁方案是使用对象不可变特性避免线程不安全，也能在一定场景下解决并发线程安全问题。在这篇文章中的<a href="https://zhoulei17.github.io/2019/05/15/java-concurreny-how-to-dev-objshare/#4不变性final" target="_blank" rel="noopener">不变性章节</a>也说明了通过使对象不可变解决共享变量同步的问题。</p>
<p>其中文章<a href="https://time.geekbang.org/column/article/92856" target="_blank" rel="noopener">利用不可变模式解决并发问题</a>通过例子很好的总结了final的应用。</p>
<h1 id="final的内存语义"><a href="#final的内存语义" class="headerlink" title="final的内存语义"></a>final的内存语义</h1><p>和前面介绍的锁和volatile相比，对final域的读和写更像是普通的变量的变量访问。下面将介绍final域的内存语义。</p>
<h2 id="final域的重排序规则"><a href="#final域的重排序规则" class="headerlink" title="final域的重排序规则"></a>final域的重排序规则</h2><p>对于final域，编译器和处理器要遵守两个重排序规则。</p>
<ol>
<li>在构造函数内对一个final域的写入，与随后对这个被构造对象的引用赋值给一个引用变量，这两个操作不能重排序。</li>
<li>初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。</li>
</ol>
<p>通过如下示例代码说明这两个规则：</p>
<p><img data-src="/img/in-post/image-20190828002822718.png" alt=""></p>
<p>假设一个线程A执行writer()方法，随后另一个线程B执行reader()方法。下面通过这两个线程的交互来说明这两个规则。</p>
<h2 id="写final域的重排序规则-M-lt-gt"><a href="#写final域的重排序规则-M-lt-gt" class="headerlink" title="写final域的重排序规则 M&lt;@:&gt;"></a>写final域的重排序规则 M&lt;@:&gt;</h2><p>写final域的重排序规则禁止把final域的写重排序到构造函数之外。这个规则包含两方面：</p>
<ol>
<li>JMM禁止编译器把final域的重排序到构造函数之外。</li>
<li>编译器会在final域的写之后，构造函数return之前，插入StoreStore屏障。这个屏障禁止处理器把final域的写重排序到构造函数之外。</li>
</ol>
<p>如果线程B读对象引用与读对象的成员域之间没有重排序。如下图为可能的读取顺序。</p>
<p><img data-src="/img/in-post/1566963176995.png" alt=""></p>
<p>写普通域操作被编译器重排序到构造函数之外，因此线程B错误地读取了普通变量i初始化之前的值。</p>
<p>而写final域的操作，被写final重排序规则”限定”在了构造函数之内，线程B正确地读取了final变量初始化之后的值。</p>
<h2 id="读final域的重排序规则"><a href="#读final域的重排序规则" class="headerlink" title="读final域的重排序规则"></a>读final域的重排序规则</h2><p>读final域的重排序规则是，在一个线程中，<strong>初次读对象引用与初次读该对象包含的final域，JMM禁止处理器重排序这两个操作(注意，这个规则仅仅针对处理器)</strong>。编译器会在读final域操作的前面插入LoadLoad屏蔽。</p>
<p>初次读对象引用与初次读该对象包含的final域，这两个操作之间存在间接依赖关系。<strong>由于编译器遵守间接依赖关系，因此编译器不会重排序这两个操作。大多数处理器也会遵守间接依赖，也不会重排序这两个操作</strong>。也有少数处理器允许对存在间接依赖关系的操作做重排序（比如alpha处理器），这个规则就是专门用来针对这种处理器的。</p>
<p>reader()方法包含3个操作。</p>
<ul>
<li><p>初次读引用变量obj</p>
</li>
<li><p>初次读引用变量obj指向对象的普通域j</p>
</li>
<li><p>初次读引用变量obj指向对象的final域i</p>
</li>
</ul>
<p>假设写线程A没有发生任何重排序，同时程序在不遵守间接依赖的处理器上执行，如下图是一种可能的执行时序</p>
<p><img data-src="/img/in-post/1566961981214.png" alt=""></p>
<p>图中，读对象的普通域操作被处理器重排序到读对象引用之前。读普通域时，该域还没有被线程A写入，这就是一个错误的读取操作。而读final域的重排序规则会把读对象的final域的操作“限定”在读对象引用之后，此时该final域应被A线程初始化过，这是一个正确的读取操作。</p>
<h2 id="final域为引用类型"><a href="#final域为引用类型" class="headerlink" title="final域为引用类型"></a>final域为引用类型</h2><p><img data-src="/img/in-post/image-20190829234658132.png" alt=""></p>
<p>本例final域为一个引用类型，它引用了一个int型的数组对象。对于引用类型，写final域的重排序规则对编译器和处理器增加约束：</p>
<ul>
<li>在构造函数内对一个final引用的对象成员的写入，与随后在构造函数外把这个被构造对象引用赋值给一个引用变量，这两个操作之间不能重排序。</li>
</ul>
<ul>
<li><p>分析：</p>
<p>执行顺序：A-&gt;B-&gt;C.</p>
<p>1 是对final域的写入</p>
<p>2 是对这个final域引用对象的成员域的写入</p>
<p>3 是把被构造对象的引用赋值给某个引用变量。</p>
<p>这里前面提到过 <strong>1 和 3 不能重排序</strong>，<strong>2 和 3 也不能重排序</strong> 。</p>
<p><strong>线程C至少可以看到步骤2的写入（即下标0的值为1），而写线程B的写入C线程可能看到也可能看不到，JMM不保证线程B的写入对读线程C可见，因为写线程B和读线程C之间存在数据竞争，此时的执行结果不可预知。</strong></p>
</li>
</ul>
<p>  如果想要确保读线程C看到写线程B对数组元素的写入，写线程和读线程C之间需要使用同步原语(lock 或 volatile)来确保可见性。</p>
<h2 id="为什么final引用不能从构造函数内”逸出”"><a href="#为什么final引用不能从构造函数内”逸出”" class="headerlink" title="为什么final引用不能从构造函数内”逸出”"></a>为什么final引用不能从构造函数内”逸出”</h2><p>写final域的重排序规则可以确保：在引用变量为任意线程可见之前，该引用变量指向的对象的final域已经在构造函数中被正确初始化了。</p>
<p><strong>但是这是由一个前提的：</strong></p>
<p>在构造函数内部，不能让这个被构造对象的引用被其他线程可见，也就是对象引用不能在构造函数中”逸出”。</p>
<p><img data-src="/img/in-post/image-20190830004643511.png" alt=""></p>
<p>如下为可能的执行流程：</p>
<p><img data-src="/img/in-post/image-20190830011040657.png" alt=""></p>
<p> 执行reader()可能没办法看到i=1，因为1 和 2 可能重排序。实际的操作可能是这样的：</p>
<p><img data-src="/img/in-post/image-20190830011646795.png" alt=""></p>
<p>上图可以看到：在构造函数返回前，被构造对象的引用不能为其他线程所见，因为此时的final域可能还没有被初始化。在构造函数返回后，任意线程都讲保证能看到final域正确初始化之后的值。</p>
<h2 id="final语义在处理器中的实现"><a href="#final语义在处理器中的实现" class="headerlink" title="final语义在处理器中的实现"></a>final语义在处理器中的实现</h2><p>以X86处理器为例，说明final语义在处理器中的具体实现。</p>
<p>上面提到，</p>
<p>写final域的重排序规则会要求编译器在final域的写之后，构造函数return之前插入一个StoreStore屏障。</p>
<p>读final域的重排序规则要求编译器在读final域的操作前面插入一个LoadLoad屏障。</p>
<p>由于X86处理器不会对写-写操作重排序，所以在X86处理器中，写final域需要的StoreStore屏障会被省略掉。</p>
<p>同样，由于X86处理器不会对存在间接依赖关系的操作做重排序，所以在X86处理器中，读final域需要的LoadLoad屏障也会被省略掉。</p>
<p><strong>也就说，X86处理器中，final域的读/写不会插入任何内存屏障！</strong></p>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
        <tag>互斥</tag>
        <tag>可见性</tag>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title>【线程互斥篇】四、无锁方案-volatile原理与内存语义</title>
    <url>/2019/08/16/2019-8-16-java-concurrency-mutex-volatile/</url>
    <content><![CDATA[<p>在jdk 1.6之前，synchronized一直被称为重量级锁，随着jdk 1.6对synchronized进行各种优化后，有些情况并不那么重了。</p>
<p>Jdk 1.6为了减少锁获得和释放带来的性能消耗而引入的<strong>偏向锁和轻量级锁，以及锁的存储结构和升级过程</strong>。</p>
<h1 id="volatile的应用"><a href="#volatile的应用" class="headerlink" title="volatile的应用"></a>volatile的应用</h1><p>synchronized和volatile在并发编程中扮演着重要角色，volatile是轻量级锁的synchronized，它在多处理器中保证了共享变量的”可见性”。可见性的意思是当一个线程修改共享变量时，另外一个线程能读到这个修改的值。如果volaitle变量修饰符使用恰当，它比synchronized的使用和执行成本更低，因为<strong>它不会引起线程上下文的切换和调度</strong>。下面将深入分析在硬件层面intel处理器是如何实现volatile的，通过深入分析能帮助我们更好的使用volatile变量。</p>
<h2 id="volatile的定义与实现原理"><a href="#volatile的定义与实现原理" class="headerlink" title="volatile的定义与实现原理"></a>volatile的定义与实现原理</h2><p>Java语言规范第3版中对volatile的定义如下：Java编程语言允许线程访问共享变量，为了确保共享变量能够准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。Java语言提供了volatile，在某些情况下比锁更加方便。</p>
<p>如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的。</p>
<p>在了解volatile实现原理之前，先看下与其实现原理相关的CPU术语与说明。</p>
<table>
<thead>
<tr>
<th>术语</th>
<th align="left">术语描述</th>
</tr>
</thead>
<tbody><tr>
<td>内存屏障(memory barriers)</td>
<td align="left">是一组处理器指令，用于实现对内存操作的顺序限制</td>
</tr>
<tr>
<td>缓冲行(cache line)</td>
<td align="left">缓存中可以分配的最小存储单元。处理器填写缓线时会加载整个缓存线，需要使用多个主内存读周期</td>
</tr>
<tr>
<td>原子操作(atomic operations)</td>
<td align="left">不可中断的一个或一系列操作</td>
</tr>
<tr>
<td>缓存行填充(cache line fill)</td>
<td align="left">当处理器识别到从内存中读取操作数是可缓存的，处理器读取整个缓存行到适当的缓存（L1 L2 L3的或所有）</td>
</tr>
<tr>
<td>缓存命中(cache hit)</td>
<td align="left">如果进行高速缓存行填充操作的内存位置仍然是下次处理器访问的地址时，处理器从缓存中读取操作数，而不是从内存读取</td>
</tr>
<tr>
<td>写命中(write hit)</td>
<td align="left">当处理器将操作数写回到一个内存缓存的区域时，它首先会检查这个缓存的内存地址是否在缓存行中，如果存在一个有效的缓存行，则处理器将这个操作数写回到缓存，而不是写回到内存，这个操作被称为写命中</td>
</tr>
<tr>
<td>写缺失(write misses the cache)</td>
<td align="left">一个有效的缓存行被写入到不存在的内存区域</td>
</tr>
</tbody></table>
<p><strong>volatile是如何来保证可见性的呢？</strong></p>
<p>通过JIT编译器生成的汇编指令查看对volatile进行写操作时，CPU会做什么事情。</p>
<p>Java代码如下</p>
<pre><code class="java">instance = new Singleton() //instance是volatile变量</code></pre>
<p>转成汇编变量如下</p>
<pre><code class="java">0x01a3de1d: movb $0×0,0×1104800(%esi);0x01a3de24: lock addl $0×0,(%esp);</code></pre>
<p>有volatile变量修饰的共享变量进行写操作的时候会多出第二行汇编代码，通过查IA-32架构软件开发者手册可知，Lock前缀的指令在多核处理器下会引发两件事情。</p>
<ol>
<li><p><strong>将当前的处理器缓存行的数据写回到系统内存。</strong></p>
</li>
<li><p><strong>这个写回内存的操作会使在其他CPU里的缓存了该内存地址的数据无效。</strong></p>
</li>
</ol>
<p>为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存（L1、L2或其他）后再进行操作，但操作完全不知道何时会写到内存。</p>
<p>如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作依然会有问题。</p>
<p>所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现<strong>缓存一致性协议</strong>，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存中。</p>
<p>下面来具体讲解volatile的两条实现原则。</p>
<ol>
<li><p><strong>Lock前缀指令会引起处理器缓存回写到内存。</strong></p>
<p>在最近的处理器，LOCK信号一般不锁总线，而是锁缓存，毕竟锁总线开销比较大。在P6和目前的处理器中，如果访问的内存区域已经缓存在处理器内部，则不会声明LOCK#信号。相反，它会锁定这块内存区域的缓存并写回到内存，并使用<strong>缓存一致性机制</strong>来确保修改的原子性，此操作被称为<strong>“缓存锁定”</strong>，缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据。</p>
</li>
<li><p><strong>一个处理器的缓存回写到内存会导致其他处理器的缓存无效。</strong></p>
<p>IA-32处理器和Intel 64位处理器使用MESI(修改、独占、共享、无效)控制协议去维护内部缓存和其他处理器的一致性。在多核处理器系统中进行操作的时候，IA-32和Intel 64处理器能嗅探其他处理器访问系统内存和它们的内部缓存。<strong>处理器使用嗅探技术保证它的内部缓存、系统内存和其他处理器的缓存的数据在总线上保持一致。</strong>例如，在Pentium和P6 family处理器中，如果通过嗅探一个处理器来检测其他处理器打算写内存地址，而这个地址当前处于共享状态，那么正在嗅探的处理器将使它的缓存行无效。下次访问相同内存地址时，强制执行缓存行填充。</p>
</li>
</ol>
<h1 id="volatile的内存语义"><a href="#volatile的内存语义" class="headerlink" title="volatile的内存语义"></a>volatile的内存语义</h1><p>当声明共享变量为volatile后，对这个变量的读/写就会很特别。为了揭开volatile的神秘面纱，下面将介绍volatile的内存语义及volatile内存语义的实现。</p>
<h2 id="volatile的特性（与单变量读-写操作的锁等价）"><a href="#volatile的特性（与单变量读-写操作的锁等价）" class="headerlink" title="volatile的特性（与单变量读/写操作的锁等价）"></a>volatile的特性（与单变量读/写操作的锁等价）</h2><p>理解volatile特性的好方法是把对volatile变量的单个读/写看成是使用同一个锁对这些单个读/写操作做了同步。通过具体例子来说明：</p>
<p><img data-src="/img/in-post/image-20190817181448552.png" alt=""></p>
<p>假设多个线程同时调用上面代码，那么程序等价于：</p>
<p><img data-src="/img/in-post/image-20190817202148385.png" alt=""></p>
<ul>
<li><strong>可见性</strong>：锁的happens-before规则保证释放锁和获取锁的两个线程之间的内存可见性，这意味着对一个volatile变量的读，总是能看到(任意线程)对这个volatile变量最后的写入。</li>
<li><strong>原子性</strong>：锁的语义决定了临界区代码执行具有原子性。这意味着，即使是64位long型和double型变量，只要它是volatile变量，对该变量的读/写就具有原子性。</li>
</ul>
<p>简而言之，volatile变量具有下列特性：</p>
<ul>
<li>可见性。对一个volatile变量的读，总是能看到(任意线程)对这个volatile变量最后的写入。</li>
<li>原子性。对任意单个volatile变量的读/写具有原子性，<strong>但类似于volatile++这种复合操作不具有原子性</strong>。</li>
</ul>
<h2 id="volatile写-读建立的happens-before关系"><a href="#volatile写-读建立的happens-before关系" class="headerlink" title="volatile写-读建立的happens-before关系"></a>volatile写-读建立的happens-before关系</h2><p>上面讲的是volatile变量自身的特性，volatile对线程可见性的影响比volatile自身的特性更为重要。</p>
<p>从JSR-133开始(即JDK5开始)，volatile变量的写-读可以实现线程之间的通信。</p>
<p>从内存语义的角度来说，volatile的写-读操作与锁的释放-获取有相同的内存效果：volatile写和锁的释放有相同的内存语义；volatile的读与锁的获取有相同的内存语义。</p>
<p>看下面代码：</p>
<p><img data-src="/img/in-post/image-20190818004141004.png" alt=""></p>
<p>假设线程A执行writer()方法之后，线程B执行reader()方法。根据happens-before规则，这个过程建立的happens-before关系可以分为3类：</p>
<ol>
<li>根据程序次序规则，1 happens-before 2；2 happens-before 4。</li>
<li>根据volatile规则，2 happens-before 3。</li>
<li>根据happens-before的传递性规则，1 happens-before 4。</li>
</ol>
<h2 id="volatile写-读的内存语义"><a href="#volatile写-读的内存语义" class="headerlink" title="volatile写-读的内存语义"></a>volatile写-读的内存语义</h2><h3 id="volatile写的内存语义"><a href="#volatile写的内存语义" class="headerlink" title="volatile写的内存语义"></a><strong>volatile写的内存语义</strong></h3><p>当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。如图为共享变量的状态示意图：</p>
<p><img data-src="/img/in-post/image-20190818134132783.png" alt=""></p>
<p>如图所示，线程A在写flag变量后，本地内存A中被线程A更新过的两个共享变量的值被刷新到主存中。此时，本地内存和主内存中的共享变量的值是一致的。</p>
<h3 id="volatile读的内存语义"><a href="#volatile读的内存语义" class="headerlink" title="volatile读的内存语义"></a><strong>volatile读的内存语义</strong></h3><p>当读一个volatile变量时，JMM会把线程对应的本地设置为无效。线程接下来将从主内存中读取共享变量。线程B的读取操作将导致本地内存B与主内存中的共享变量的值一致。</p>
<p>如果把volatile读写两个步骤综合起来看，写线程A在写这个volatile变量之前所有可见的共享变量的值都将立即变得对后续读变量的读线程B可见。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>线程A写一个volatile变量，实质是线程A向接下来读这个volatile变量的某个线程发出了(其共享变量所做修改的)消息。</li>
<li>线程B读一个volatile变量，实质上是线程B接收了之前某个线程发出的(在写这个volatile变量之前对共享变量所做修改的)消息。</li>
<li>线程A写一个volatile，随后线程B读这个volatile变量，这个过程实质上是线程A通过主存向线程B发送消息。如图：</li>
<li><img data-src="/img/in-post/image-20190818145024747.png" alt=""></li>
</ul>
<h1 id="volatile内存语义的实现"><a href="#volatile内存语义的实现" class="headerlink" title="volatile内存语义的实现"></a>volatile内存语义的实现</h1><p>下面来看看JMM如何实现volatile写/读的内存语义。</p>
<p>前面提到重排序分为编译器重排序和处理器重排序。为了实现volatile内存语义，JMM会分别限制这两种类型的重排序类型。</p>
<h2 id="volatile重排序规则"><a href="#volatile重排序规则" class="headerlink" title="volatile重排序规则"></a>volatile重排序规则</h2><p>下表为JMM针对编译制定的volatile重排序规则表。</p>
<p><img data-src="/img/in-post/image-20190818160018149.png" alt=""></p>
<p>可以看出：</p>
<ul>
<li><strong>当第二个线程的操作是volatile写时，不管第一个线程操作是什么，都不能重排序</strong>。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。</li>
<li><strong>当第一个线程的操作是volatile读时，不管第二个线程操作是什么，都不能重排序</strong>。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。</li>
<li><strong>当第一个操作操作是volatile写，第二个操作是volatile读时，不能重排序</strong>。</li>
</ul>
<h2 id="volatile内存语义的实现-1"><a href="#volatile内存语义的实现-1" class="headerlink" title="volatile内存语义的实现"></a>volatile内存语义的实现</h2><p><strong>为了实现volatile的内存语义，编译器在生成字节码时，会在指令中插入内存屏障来禁止特定类型的处理器排序</strong>。</p>
<p>JMM采取<strong>保守策略</strong>：</p>
<ul>
<li>在每个volatile写操作的前面插入一个StoreStore屏障。</li>
<li>在每个volatile写操作的后面插入一个StoreLoad屏障。</li>
<li>在每个volatile读操作的后面插入一个LoadLoad屏障。</li>
<li>在每个volatile读操作的后面插入一个LoadStore屏障。</li>
</ul>
<h3 id="volatile写屏障"><a href="#volatile写屏障" class="headerlink" title="volatile写屏障"></a>volatile写屏障</h3><p>下面保守策略下，volatile写插入内存屏障后生成的指令序列：</p>
<p><img data-src="/img/in-post/1566441407226.png" alt=""></p>
<p><strong>StoreStore屏障可以保证在volatile写之前，其前面所有普通写已经对任意处理器可见</strong>。这是因为StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存。</p>
<p><strong>StoreLoad屏障是避免volatile写与后面可能有的volatile读/写操作重排序。</strong></p>
<h3 id="volatile读屏障"><a href="#volatile读屏障" class="headerlink" title="volatile读屏障"></a>volatile读屏障</h3><p>下面是保守策略下，volatile读插入内存屏障指令</p>
<p><img data-src="/img/in-post/1566445477243.png" alt=""></p>
<p><strong>LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序</strong>。</p>
<p><strong>LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序</strong>。</p>
<h3 id="实际执行会去屏障"><a href="#实际执行会去屏障" class="headerlink" title="实际执行会去屏障"></a>实际执行会去屏障</h3><p>上述的volatile写和volatile读的内存屏障插入策略非常保守。在实际执行时，只要不改变volatile写-读的内存语义，编译器可以根据具体情况省去不必要的屏障。下面通过具体示例代码说明。</p>
<p><img data-src="/img/in-post/1566453133583.png" alt=""></p>
<p><img data-src="/img/in-post/1566453176152.png" alt=""></p>
<p>最后的StoreLoad屏蔽不能省略。因为第二个volatile写之后，方法立即return。此时编译器可能无法准确判定后面是否会有volatile读或写，为了安全起见，编译器会常在这里插入StoreLoad屏障。</p>
<h3 id="X86继续优化"><a href="#X86继续优化" class="headerlink" title="X86继续优化"></a>X86继续优化</h3><p>上面的优化针对任意处理器平台，由于不同的处理器有着不同“松紧度”的处理器内存模型，内存屏障的插入还可以根据具体的处理器内存模型继续优化。已X86为例，前面保守策略下的volatile读和写，在X86处理器平台可以优化成：</p>
<p><img data-src="/img/in-post/1566453672658.png" alt=""></p>
<p>X86处理器仅会对写-读操作做重排序。X86不会对读-读、读-写、写-写操作做重排序，因此X86处理器中会省略掉这3种操作类型对应的内存屏障。因此，在X86中，JMM仅需要在volatile写后面插入一个StoreLoad屏障即可正确实现volatile写-读的内存语义。</p>
<h1 id="JSR-133为什么要增强volatile的内存语义"><a href="#JSR-133为什么要增强volatile的内存语义" class="headerlink" title="JSR-133为什么要增强volatile的内存语义"></a>JSR-133为什么要增强volatile的内存语义</h1><p>在JSR-133之前的旧Java内存模型，虽然不允许volatile变量之前的重排序，但允许volatile变量与普通变量之间的重排序。如：</p>
<p><img data-src="/img/in-post/1566454869434.png" alt=""></p>
<p>在旧的内存模型中，当1和2之间没有数据依赖时，1和2之间就可能被重排序（3和4类似）。其结果就是：读线程B执行4时，不一定能看到A在执行1时对共享变量的修改。</p>
<p>因此，在旧的内存模型中，volatile的写-读没有锁释放-获取 锁具有的内存语义。为了提供一种比锁更轻量级的线程之间的通信，JSR-133专家决定增强volatile的内存语义：严格限制编译器和处理器对volatile变量与普通变量的重排序，<strong>确保volatile的写-读和锁的释放-获取</strong>具有相同的内存语义。从编译器重排序规则和处理器内存屏障插入策略来看，只要volatile变量与普通变量之间可能会破坏volatile的内存语义，这种重排序就会被编译器重排序规则和处理器内存屏障插入策略禁止。</p>
<p>由于volatile仅仅保证对单个volatile变量的读/写具有原子性，而锁的互斥性可以确保整个临界区代码的执行具有原子性。在功能上，锁比volatile更强大；在可伸缩性和执行性能上，volatile更有优势。但是如果想在代码中用volatile替代锁，一定要谨慎！</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
        <tag>互斥</tag>
        <tag>可见性</tag>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title>【线程互斥篇】三、有锁方案-synchronized的实现原理与应用</title>
    <url>/2019/08/11/2019-8-11-java-concurrency-mutex-synchronized/</url>
    <content><![CDATA[<p>在jdk 1.6之前，synchronized一直被称为重量级锁，随着jdk 1.6对synchronized进行各种优化后，有些情况并不那么重了。</p>
<p>Jdk 1.6为了减少锁获得和释放带来的性能消耗而引入的<strong>偏向锁和轻量级锁，以及锁的存储结构和升级过程</strong>。</p>
<h1 id="synchronized基础"><a href="#synchronized基础" class="headerlink" title="synchronized基础"></a>synchronized基础</h1><p>再来总结一下synchronized实现同步的基础：Java中的每一个对象都可以作为锁。具体可以使用一下3中形式：</p>
<ul>
<li>对于普通同步方法，锁是当前实例对象。</li>
<li>对于静态同步方法，锁是当前类的Class对象。</li>
<li>对于同步方法块，锁是synchronized括号中配置的对象。</li>
</ul>
<p>当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。</p>
<p><strong>那么锁到底存在哪里?</strong></p>
<p><strong>锁里面会存储什么信息呢</strong></p>
<h1 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h1><p>从JVM规范中可以看到，synchronized在JVM理的实现原理：</p>
<p>JVM基于进入和退出Monitor对象来实现方法同步和代码同步，但两者的实现细节不一样。代码同步快使用monitorenter和monitorexit指令实现的，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明。但是，方法的同步同样可以使用这两个指令来实现。</p>
<p>monitorenter指令是在编译后插入同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都一个monitor与之关联。当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象锁对应的monitor所有权，即尝试获得对象的锁。</p>
<h2 id="Java对象头与锁记录（Mark-Word）存储"><a href="#Java对象头与锁记录（Mark-Word）存储" class="headerlink" title="Java对象头与锁记录（Mark Word）存储"></a>Java对象头与锁记录（Mark Word）存储</h2><p><strong>synchronized用的锁是存在Java对象头里的。</strong>如果对象是数组类型，则虚拟用3个字宽(Word)存储对象头，如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，1字宽等于4字节，即32bit。</p>
<p><strong>Java对象头的长度</strong></p>
<table>
<thead>
<tr>
<th>长度</th>
<th>内存</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>32/64bit</td>
<td>Mark Word</td>
<td>存储对象的hashCode或锁信息等</td>
</tr>
<tr>
<td>32/64bit</td>
<td>Class Metadata Address</td>
<td>存储到对象类型数据的指针</td>
</tr>
<tr>
<td>32/32bit</td>
<td>Array length</td>
<td>数组的长度(如果当前对象是数组)</td>
</tr>
</tbody></table>
<p><strong>Java对象头Mark Word的存储结构</strong></p>
<table>
<thead>
<tr>
<th>锁状态</th>
<th>25bit</th>
<th>4bit</th>
<th>1bit</th>
<th>21bit</th>
</tr>
</thead>
<tbody><tr>
<td>无所状态</td>
<td>对象的hashcode</td>
<td>对象分代年龄</td>
<td>0</td>
<td>01</td>
</tr>
</tbody></table>
<p><strong>Mark Word的状态变化</strong></p>
<p><img data-src="/img/in-post/image-20190813233457663.png" alt=""></p>
<p>在<strong>64位虚拟机下，Mark Word是64bit大小的</strong>，其存储结构如下：</p>
<p><img data-src="/img/in-post/image-20190813233510488.png" alt=""></p>
<h2 id="锁的升级与对比"><a href="#锁的升级与对比" class="headerlink" title="锁的升级与对比"></a>锁的升级与对比</h2><p>JAVA 1.6为了减少获得锁和释放锁带来的性能消耗，引入了”偏向锁”和”轻量级锁”，在JAVA 1.6中，锁一共有4钟状态，级别从低到高分别是：</p>
<p><strong>无锁状态——&gt;偏向锁状态——&gt;轻量级锁状态——&gt;重量级锁状态</strong></p>
<p>这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，这意味着偏向锁升级成轻量级锁后不能降级成偏向锁。</p>
<p><strong>这种锁升级不能降级的策略，目的是位提高获得锁和释放锁的效率。</strong></p>
<h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>HotSpot的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。</p>
<p>当一个线程访问同步块时，会<strong>对象头和栈帧中的锁记录</strong>里存储偏向的线程ID，以后该线程进入和退出同步块时不需要进行CAS操作来加锁和解锁，</p>
<ol>
<li>只需简单地测试下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。</li>
<li>如果测试失败，则需再测试一下Mark Word中偏向锁的标识是否设置成1(表示当前是偏向锁)：如果没有设置，则使用CAS竞争锁；</li>
<li>如果设置了，则尝试使用CAS将对象的偏向锁指向当前线程。</li>
</ol>
<ul>
<li><p>偏向锁的撤销</p>
<p><strong>偏向锁使用了一种等到竞争出现才释放锁的机制</strong>，所以当其他线程尝试竞争偏向锁时，持有偏向的线程才会释放。</p>
<p>偏向锁的撤销，需要等待全局安全点(在这个时间点上没有正在执行的字节码)。</p>
<ol>
<li>它首先会暂停拥有偏向锁的线程，然后检查偏向锁的线程是否活着。</li>
<li>如果线程不处于活动状态，则将对象头设置成无锁状态。</li>
<li>如果线程依然活着，则拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。</li>
</ol>
</li>
<li><p>偏向锁的获得和撤销流程(上面文字描述比较啰嗦，看下图比较清楚)</p>
<p><img data-src="/img/in-post/image-20190813233803954.png" alt=""></p>
</li>
</ul>
<ul>
<li><p>关闭偏向锁</p>
<p>Java 6 Java 7里是默认启用的，但是在应用程序启动几秒之后才激活，如有必要可以使用JVM参数关闭延迟-XX:BiasedLockingStartupDelay=0。</p>
<p>如果确定应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，那么程序默认会进入轻量级状态。</p>
</li>
</ul>
<h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><ul>
<li><p>轻量级锁加锁</p>
<p>线程在执行同步块之前,JVM会现在当前线程的栈帧中创建用于存储记录的空间，并将对象头中的Mard Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。</p>
</li>
<li><p>轻量级锁级解锁</p>
<p>轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。</p>
<p><img data-src="/img/in-post/image-20190814002145432.png" alt=""></p>
</li>
</ul>
<p>因为自旋会消耗CPU，为了避免无用的自旋(比如获得锁的线程被阻塞住了)，一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放之后会唤醒这些线程，被唤醒的线程就会进行新一轮的争夺之战。</p>
<h2 id="锁的优缺点对比"><a href="#锁的优缺点对比" class="headerlink" title="锁的优缺点对比"></a>锁的优缺点对比</h2><table>
<thead>
<tr>
<th>锁</th>
<th>优点</th>
<th>缺点</th>
<th>使用场景</th>
</tr>
</thead>
<tbody><tr>
<td>偏向锁</td>
<td>加锁和解锁不需要额外的消耗，和执行非同步方法相比仅存在纳秒级差距</td>
<td>线程之间存在锁竞争，会带来额外的锁撤销的消耗</td>
<td>使用于只有一个线程访问同步块场景</td>
</tr>
<tr>
<td>轻量级锁</td>
<td>竞争的线程不会阻塞，提高了线程的响应速度</td>
<td>如果始终得不到锁竞争的线程，使用自旋会消耗CPU</td>
<td>追求响应时间，同步块执行速度非常快</td>
</tr>
<tr>
<td>重量级锁</td>
<td>线程竞争不使用自旋，不会消耗CPU</td>
<td>线程阻塞，响应事假缓慢</td>
<td>追求吞吐量，同步快执行速度较长</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
        <tag>互斥</tag>
        <tag>synchronized</tag>
      </tags>
  </entry>
  <entry>
    <title>【线程互斥篇】二、有锁方案-读写锁ReadWriteLock——快速使用一个完备的缓存</title>
    <url>/2019/07/31/2019-7-31-java-concurrency-Mutex-readwritelock/</url>
    <content><![CDATA[<h1 id="读—写锁"><a href="#读—写锁" class="headerlink" title="读—写锁"></a>读—写锁</h1><p>ReentrantLock实现了一种标准的互斥锁：每次最多只有一个线程持有ReentLock，但对于数据完整性来说，互斥通常是一种过于强硬的加强规则，因此也就不必要的限制了并发性。不仅仅限制了”写/写”冲突和”写/读”冲突，但同样也避免了”读/读”冲突。</p>
<p>如果是”读/读”场景，允许多个线程同时访问数据，会提高性能。只要每个线程都能确保读到最新的数据，并且在读取数据时不会有其他线程修改数据，就不会发生问题。</p>
<p>总结，读-写锁：</p>
<blockquote>
<ol>
<li>允许多个线程同时读共享变量</li>
<li>只允许一个线程写共享变量</li>
<li>如果一个写线程正在执行写操作，此时禁止读线程读共享变量。</li>
<li>如果有线程在读共享变量，此时禁止写线程写共享变量。</li>
</ol>
</blockquote>
<p>尽管这两个锁看上去是彼此独立的，但读取锁和写入锁只是读——写锁对象的不同视图。</p>
<pre><code class="java">public interface ReadWriteLock{
  Lock readLock()；
  Lock writeLock();    
}</code></pre>
<p>在读—写锁实现的加锁策略中，允许多个读操作同时进行，但每次中允许一个写操作。与Lock一样，ReadWriteLock可以采用多种不同的实现方式，这些方式在性能、调度保证、获取优先性、公平性以及加锁语义等方面可能有所不同。</p>
<h1 id="性能方面"><a href="#性能方面" class="headerlink" title="性能方面"></a>性能方面</h1><p>读—写锁是一种性能优化措施，在一些特定的情况下能实现更高的并发性。在实际情况中，对于在多处理器系统上被频繁读取的数据，读-写锁能够提高性能。而在其他情况下，读-写的性能比独占锁要略差一点，这是因为它们复杂度更高。当然还要结合程序来分析，所以一般不是非得使用在读多的场景下，还是使用直接使用独占锁。</p>
<h1 id="读写锁的使用"><a href="#读写锁的使用" class="headerlink" title="读写锁的使用"></a>读写锁的使用</h1><h2 id="快速实现一个缓存"><a href="#快速实现一个缓存" class="headerlink" title="快速实现一个缓存"></a>快速实现一个缓存</h2><pre><code class="java">public class Cache&lt;K, V&gt; {

    final Map&lt;K, V&gt; m = new HashMap&lt;&gt;();
    final ReadWriteLock rwl = new ReentrantReadWriteLock();
    final Lock r = rwl.readLock();
    final Lock w = rwl.writeLock();

    //读缓存
    V get(K key) {
        r.lock();
        try {
            return m.get(key);
        } finally {
            r.unlock();
        }
    }

    //写缓存
    V put(K key,V v) {
        w.lock();
        try {
            return m.put(key, v);
        } finally {
            w.unlock();
        }
    }
}
</code></pre>
<h2 id="实现缓存的按需加载"><a href="#实现缓存的按需加载" class="headerlink" title="实现缓存的按需加载"></a>实现缓存的按需加载</h2><pre><code class="java">class Cache2&lt;K, V&gt; {
    final Map&lt;K, V&gt; m = new HashMap&lt;&gt;();
    final ReadWriteLock rwl = new ReentrantReadWriteLock();
    final Lock r = rwl.readLock();
    final Lock w = rwl.writeLock();

    V get(K key) {
        V v = null;
        // 读缓存
        r.lock(); // ①
        try {
            v = m.get(key); // ②
        } finally {
            r.unlock(); // ③
        }
        // 缓存中存在，返回
        if (v != null) { // ④
            return v;
        }
        // 缓存中不存在，查询数据库
        w.lock(); // ⑤
        try {
            // 再次验证
            // 其他线程可能已经查询过数据库
            v = m.get(key); // ⑥
            if (v == null) { // ⑦
                // 查询数据库
                // v= 省略代码无数
                m.put(key, v);
            }
        } finally {
            w.unlock();
        }
        return v;
    }
}</code></pre>
<p>代码⑥⑦处，重新验证了一次缓存中是否存在，为什么再次验证，是为了多线程高并发场景下重复查询数据库的问题：加入线程T1、T2、T3同时竞争写锁，其中T1获得写锁并查询数据库后写入缓存，释放写锁，此时T2立即获得写锁，此时如果不再验证一次那么就会再读一遍数据库，T3类似，那么就会存在重复读数据库的性能问题。</p>
<h1 id="读写锁的升级与降级"><a href="#读写锁的升级与降级" class="headerlink" title="读写锁的升级与降级"></a>读写锁的升级与降级</h1><pre><code class="java">// 读缓存
r.lock();         ①
try {
  v = m.get(key); ②
  if (v == null) {
    w.lock();
    try {
      // 再次验证并更新缓存
      // 省略详细代码
    } finally{
      w.unlock();
    }
  }
} finally{
  r.unlock();     ③
}
</code></pre>
<p>在上面按需加载缓存的例子中，在①处获取读锁，在③处释放读锁，那是否可以在②处的下面增加验证缓存并更新缓存呢。</p>
<p>看上去没什么问题，先获取读锁，然后再升级为写锁，即<strong>锁升级</strong>。<strong>可惜ReadWriteLock并不支持这种升级</strong>。在上面的示例中，读锁还没有释放，此时再获取写锁，会导致写锁永久等待，最终导致相关线程都被阻塞，永远也没有机会呗唤醒。锁的升级是不允许的。</p>
<p>不过虽然锁的升级是不允许的，但是锁的降级却是允许的。如下面这个ReentrantReadWriteLock的官方示例，略做了改动。</p>
<pre><code class="java">class CachedData {
  Object data;
  volatile boolean cacheValid;
  final ReadWriteLock rwl =
    new ReentrantReadWriteLock();
  // 读锁  
  final Lock r = rwl.readLock();
  // 写锁
  final Lock w = rwl.writeLock();

  void processCachedData() {
    // 获取读锁
    r.lock();
    if (!cacheValid) {
      // 释放读锁，因为不允许读锁的升级
      r.unlock();
      // 获取写锁
      w.lock();
      try {
        // 再次检查状态  
        if (!cacheValid) {
          data = ...
          cacheValid = true;
        }
        // 释放写锁前，降级为读锁
        // 降级是可以的
        r.lock(); ①
      } finally {
        // 释放写锁
        w.unlock(); 
      }
    }
    // 此处仍然持有读锁
    try {use(data);} 
    finally {r.unlock();}
  }
}
</code></pre>
<p>在代码①处，获取读锁的时候线程还是持有写锁的，这种<strong>锁的降级是支持的</strong>。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>读写锁类似于ReentrantLock，也支持公平模式和非公平模式。读写和写锁都实现了java.util.concurrent.locks.Lock接口，所以除了支持lock()方法外，tryLock()、lockInterruptibly()等方法也都是支持的。</p>
<p>需要注意的是，只有写锁支持条件变量，读锁是不支持条件变量的，读锁调用newCondition()会抛出UnsupportedOperationException异常。</p>
<p>今天我们用ReadWriteLock实现了一个简单的缓存，这个缓存虽然解决了缓存初始化问题，但是没有解决数据与源头数据同步的问题，这里的数据同步指的是缓存数据和源头数据的一致性。解决数据同步问题的一个最简单的方案就是超时机制。所谓超时机制指的是加载进缓存的数据不是长久有效的，而是有时效的，当缓存的数据超过时效，也就是超时之后，这条数据在缓存中就失效了。而访问缓存中失效的数据，会触发缓存重新从源头把数据加载进缓存。</p>
<p>当然也可以在源头数据发生变化时，快速反馈给缓存，但这就要依赖具体的场景了。例如MySQL作为数据源头，可以通过实时地解析binlog来识别数据是否发生变化，如果发生了变化就将最新的数据推送给缓存。另外，还有一些方案采取的是数据库和缓存双写的方案。</p>
<p>总之，采用哪个方案还要看具体场景。</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
        <tag>互斥</tag>
        <tag>ReadWriteLock</tag>
      </tags>
  </entry>
  <entry>
    <title>【线程互斥篇】一、有锁方案-锁Lock(并发包中的管程)</title>
    <url>/2019/07/29/2019-7-29-java-concurrency-Mutex-lock/</url>
    <content><![CDATA[<h1 id="管程与Lock"><a href="#管程与Lock" class="headerlink" title="管程与Lock"></a>管程与Lock</h1><p>JDK并发包中内容很多，核心的是其对管程的实现。理论上利用管程几乎可以实现所有的并发工具。在前面写的博客管程中的管程文章。<a href="https://zhoulei17.github.io/2019/05/09/java-concurreny-java-monitor/" target="_blank" rel="noopener">管程——并发编程的万能钥匙</a>,<a href="[https://zhoulei17.github.io/2019/05/09/java-concurreny-system-courrenency/#%E7%AE%A1%E7%A8%8B](https://zhoulei17.github.io/2019/05/09/java-concurreny-system-courrenency/#管程)">从操作系统角度看并发</a>,中已经介绍了管程，可以跳过去看。</p>
<p>本篇文中提到的并发编程领域，有两个核心问题：<strong>互斥与同步(即协作)</strong>，这两大问题，管程都是能够解决的。</p>
<p><strong>Java SDK并发包通过Lock和Condition两个接口来实心管程，其中Lock用于解决互斥问题，Condition用于解决同步问题。</strong></p>
<p><strong>问题：为什么Java本身提供了sychronized也是管程的一种实现，既然已经提供了管程的实现，为什么还要提供Lock这种显式锁的方式？</strong>显然不是重复造轮子，那区别在哪里？</p>
<h1 id="再造管程的理由"><a href="#再造管程的理由" class="headerlink" title="再造管程的理由"></a>再造管程的理由</h1><p>在Java 1.5中sychronized性能不如SDK里面的Lock，但1.6版本后，synchronized做了很多优化，将性能追了上来，所以1.6之后的版本又有人推荐使用了synchronized了。可见性能并不是再造管程的理由。</p>
<p>在死锁的破坏条件中有一个方案：<strong>破坏不可抢占条件</strong>，这个条件在synchronized是不能解决的。因为synchronized申请资源的时候，如果申请不到，线程直接进入阻塞状态，啥都干不了，也释放不了线程已经占用的资源。但我们的希望是：</p>
<blockquote>
<p>对于”不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。</p>
</blockquote>
<p>如果重新设计一把互斥锁去解决这个问题，应该有三种方案：</p>
<ol>
<li><strong>能够响应中断</strong>。sychronized的问题是，持有锁A后，如果尝试获取锁B失败，那么线程就进入阻塞状态，一旦发生死锁，就没有任何机会唤醒阻塞的线程。但如果阻塞状态的线程能够响应中断，也就是说给阻塞的线程发送中断信号，能够唤醒它，那它就有机会释放曾经持有的锁A。<strong>这样就破坏了不可抢占条件了</strong>；</li>
<li><strong>支持获取锁超时</strong>。如果线程在一段时间之内没有获取到锁，不是进入阻塞状态，而是返回一个错误，那这个线程也有机会释放曾经持有的锁。<strong>这样也能破坏不可抢占条件</strong>。</li>
<li><strong>非阻塞地获取锁。</strong>如果尝试获取锁失败，并不进入阻塞状态，而是直接返回，那这个线程也有机会释放曾经持有的锁。<strong>这样也能破坏不可抢占条件</strong>。</li>
</ol>
<p>这三种方案可以弥补sychronized的缺陷。这三个方案就是”重复造轮子”的主要原因，体现在在API上，就是Lock接口的三个方法。</p>
<h1 id="Lock的三个方法"><a href="#Lock的三个方法" class="headerlink" title="Lock的三个方法"></a>Lock的三个方法</h1><pre><code class="java">public interface Lock {

    void lock();
        //支持中断的API
    void lockInterruptibly() throws InterruptedException;
        //支持非阻塞获取锁的API，如果获取到锁返回true，否则false直接返回，同样可以响应中断
    boolean tryLock();
        //支持超时的API
    boolean tryLock(long time, TimeUnit unit) throws InterruptedException;

    void unlock();

    Condition newCondition();
}
</code></pre>
<h1 id="如何保证可见性"><a href="#如何保证可见性" class="headerlink" title="如何保证可见性"></a>如何保证可见性</h1><p>已经知道Java里线程的可见性是通过Hapeens-Before规则保证的，而synchronized之所有能够保证可见性，也是因为有一条synchronized相关的规则：</p>
<p>synchronized的解锁顺序Happens-Before于后续对这个锁的加锁。那Java SDK里Lock靠什么保证可加性呢？例如下面代码：</p>
<pre><code class="java">class X {
  private final Lock rtl =
  new ReentrantLock();
  int value;
  public void addOne() {
    // 获取锁
    rtl.lock();  
    try {
      value+=1;
    } finally {
      // 保证锁能释放
      rtl.unlock();
    }
  }
}
</code></pre>
<p>现在T1对value进行+=1操作，那后续的线程T2能够看见value的正确结果吗？答案是肯定的。</p>
<p>Java SDK里面的锁实现非常复杂，这里先不展开后续接收互斥相关的内容时会详细说明，先简单介绍下保证可见性的原理：</p>
<p>它是<strong>利用了volatile相关的Happens-Before规则</strong>。Java SDK里面的ReentrantLock内部持有一个state(在父类AQS[AbstractQueuedSynchronizer])中，获取锁的时候会读取state的值；解锁的时候也会读取state的值(简化后的代码如下面所示)。也就是说，在执行value+=1之前，程序先读写一次volatile变量state，在执行value+=1之后，又读写一次volatile变量state。</p>
<p>根据相关的Happens-Before规则：</p>
<ol>
<li><strong>顺序性规则</strong>：对于线程T1，value+=1 Happens-Before释放锁的操作unlock()；</li>
<li><strong>volatile变量规则</strong>：由于state=1会先读取state，所以线程T1的unlock()操作Happens-Before线程T2的lock()操作。</li>
<li><strong>传递性规则</strong>：线程T1的value+=1 Happens-Before线程T2的lock()操作。</li>
</ol>
<pre><code class="java">class SampleLock {
  volatile int state;
  // 加锁
  lock() {
    // 省略代码无数
    state = 1;
  }
  // 解锁
  unlock() {
    // 省略代码无数
    state = 0;
  }
}</code></pre>
<p>所以后续线程T2能够看到value正确的结果。</p>
<h1 id="什么是可重入锁"><a href="#什么是可重入锁" class="headerlink" title="什么是可重入锁"></a>什么是可重入锁</h1><p>Lock的主要实现ReentrantLock，也叫<strong>可重入锁</strong>。<strong>即，线程可以重复获取同一把锁。</strong></p>
<pre><code class="java">class X {
  private final Lock rtl =
  new ReentrantLock();
  int value;
  public int get() {
    // 获取锁
    rtl.lock();         ②
    try {
      return value;
    } finally {
      // 保证锁能释放
      rtl.unlock();
    }
  }
  public void addOne() {
    // 获取锁
    rtl.lock();  
    try {
      value = 1 + get(); ①
    } finally {
      // 保证锁能释放
      rtl.unlock();
    }
  }
}</code></pre>
<p>当线程T1执行到①时，已经获取到锁rt1，当在①处调用get()方法时，会在②再次对锁rt1执行加锁操作。此时，如果锁rt1是可重入得，那么线程T1可以再次加锁成功；如果rt1是不可重入的，那么T1此时会被阻塞。</p>
<h1 id="公平锁与非公平锁"><a href="#公平锁与非公平锁" class="headerlink" title="公平锁与非公平锁"></a>公平锁与非公平锁</h1><p>在使用ReentrantLock这个类有两个构造函数，一个是无参的，一个是传入fair参数的构造函数。fair代表锁的公平策略，如果传入true就表示需要构造一个公平锁，反之则表示要构造一个非公平锁。</p>
<pre><code class="java">// 无参构造函数：默认非公平锁
public ReentrantLock() {
    sync = new NonfairSync();
}
// 根据公平策略参数创建锁
public ReentrantLock(boolean fair){
    sync = fair ? new FairSync() 
                : new NonfairSync();
}</code></pre>
<p>在<a href="https://zhoulei17.github.io/2019/05/09/java-concurreny-java-monitor/" target="_blank" rel="noopener">管程——并发编程的万能钥匙</a>中，介绍过入口等待队列，锁都对应着一个等待队列，如果线程没有获得锁，就会进入等待队列，当有线程释放锁的时候，就需要从等待队列中唤醒一个等待的线程。如果是公平锁，唤醒的策略是谁等待的时间长，就唤醒谁，很公平；如果是非公平锁，则不提供这个公平保证，有可能等待时间短的返回先被唤醒。</p>
<h1 id="用锁的最佳实践"><a href="#用锁的最佳实践" class="headerlink" title="用锁的最佳实践"></a>用锁的最佳实践</h1><p>锁用的不好就可能导致性能低下、性能差或者更危险会导致死锁。并发大师Doug Lea《Java并发编程：设计原则与模式》一书中，推荐三个用锁的最佳时间，他们分别是：</p>
<blockquote>
<ol>
<li>永远只在更新对象的成员变量时加锁</li>
<li>永远只在访问可变的成员变量时加锁</li>
<li>永远不再调用其他对象的方法时加锁</li>
</ol>
</blockquote>
<h1 id="在synchronized和ReentrantLock之间选择"><a href="#在synchronized和ReentrantLock之间选择" class="headerlink" title="在synchronized和ReentrantLock之间选择"></a>在synchronized和ReentrantLock之间选择</h1><p>关于使用：</p>
<ul>
<li><p>ReentrantLock</p>
<p>ReentrantLock在加锁和内存提供的语义与内置锁相同，此外还提供了锁等待、可中断的锁等待、公平锁，以及非块结构的加锁。</p>
<p>在安全性上，ReentrantLock有很大风险，如果忘记在finally块中调用unlock那就完蛋。</p>
</li>
<li><p>synchronized</p>
<p>与显式锁相比，内置锁仍然具有很大的优势。内置锁开发人员更为熟悉，并且简洁紧凑。</p>
</li>
</ul>
<p>关于性能：</p>
<p>在现有jdk 6之后的版本中对synchronized进行了优化，性能已经接近甚至超过了ReentrantLock。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>Java SDK并发包里的Lock接口里面的每个方法，你可以感受到，都是经过深思熟虑的。除了支持类似synchronized隐式加锁的lockI()之外，还支持超时、非阻塞、可中断的方式获取锁，这三种方式为我们编写更加安全、健壮的并发程序提供了很大的方便。</p>
<p>除了上面总结的三个最佳实践外，也可以参考诸如：减少锁的持有时间、减小锁的粒度等业界广为人知的规则，其实本质上都是相同的，不过是在该加锁的地方加锁而已。</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
        <tag>互斥</tag>
        <tag>lock</tag>
      </tags>
  </entry>
  <entry>
    <title>【线程协作篇】四、CountDownLatch和CyclicBarrier：如何让多线程步调一致</title>
    <url>/2019/07/15/2019-7-15-java-concurrency-communication-CountDownLatch-CyclicBarrier/</url>
    <content><![CDATA[<h1 id="CountDownLatch（闭锁实现）及用法"><a href="#CountDownLatch（闭锁实现）及用法" class="headerlink" title="CountDownLatch（闭锁实现）及用法"></a>CountDownLatch（闭锁实现）及用法</h1><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><p>这是java.util.concurrent引入的另一个并发工具。</p>
<p>前面讲了Semaphore主要用来控制多个线程对临界区的并发访问(许可)，与Semaphore不同，CountLatchDown主要用来同步一个或多个任务的，它可以强制当前线程等待由其他线程执行的任务完成后才继续执行。作用就相当于一扇门：在闭锁到达结束状态之前，这扇门是一直关闭的，并且没有任何线程通过，当到达结束状态后，将不会再改变状态，因此这扇门将永远保持打开状态。类似于Thread.join功能。<strong>闭锁可以用来确保某些活动直到其他活动都执行完后才继续执行的场景，</strong></p>
<h2 id="使用简介"><a href="#使用简介" class="headerlink" title="使用简介"></a>使用简介</h2><ul>
<li>用法过程：</li>
</ul>
<ol>
<li>CountDownLatch<strong>初始化设置初始计数值</strong>。</li>
<li>任何对象<strong>调用CountDownLatch的await()方法阻塞，直至计数值等于0</strong></li>
<li>其他任务在结束其工作时，<strong>在该CountDownLatch上执行countDown()方法减少计数值</strong>。</li>
</ol>
<ul>
<li><p>典型用法：</p>
<p>CountDownLatch的典型用法是将一个程序分成n个互相独立的可解决任务，并创建值为0的CountDownLatch。当每个任务完成时，都会在锁存储器上调用countDown()。等待问题被解决的任务在这个锁寄存器上调用await()，将它们自己拦住，直至锁寄存器计数结束。示例如下：</p>
</li>
</ul>
<h2 id="典型用法示例"><a href="#典型用法示例" class="headerlink" title="典型用法示例"></a>典型用法示例</h2><pre><code class="java">
public class CountDownLatchDemo {
    static final int SIZE = 100;
    public static void main(String[] args) {
        ExecutorService exec = Executors.newCachedThreadPool();
        CountDownLatch latch = new CountDownLatch(SIZE);
        for (int i = 0 ; i &lt; 10 ; i++) {
            exec.execute(new WaitingTask(latch));
        }
        for (int i = 0 ; i &lt; SIZE ;i++) {
            exec.execute(new TaskPortion(latch));
        }
        System.out.println(&quot;Launched all tasks&quot;);
        exec.shutdown();
    }
}

class TaskPortion implements Runnable {
    private static int counter = 0;
    private final int id = counter++;
    private static Random rand = new Random(47);
    private final CountDownLatch latch;

    public TaskPortion(CountDownLatch latch) {
        this.latch = latch;
    }
    verride
    public void run() {
        try {
            doWork();
        } catch (InterruptedException e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
        } finally {
            latch.countDown();
        }
    }

    public void doWork() throws InterruptedException {
        TimeUnit.MILLISECONDS.sleep(rand.nextInt(2000));
        System.out.println(this + &quot;completed&quot;);
    }

    public String toString() {
        return String.format(&quot;%1$-3d&quot;,id);
    }
}


class WaitingTask implements Runnable {
    private static int counter = 0;
    private final int id = counter++;
    private final CountDownLatch latch;

    public WaitingTask(CountDownLatch latch) {
        this.latch = latch;
    }

    verride
    public void run() {

        try {
            System.out.println(&quot;Waiting Task now &quot; + this);

            latch.await();
        } catch (InterruptedException e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
        }
        System.out.println(&quot;Latch barrier passed for &quot; + this);
    }

    public String toString() {
        return String.format(&quot;WaitingTask %1$-3d&quot;,id);
    }
}</code></pre>
<p><code>TaskPortion</code>与    <code>WaitingTask</code>共同持有同一个CountDownLatch对象，进行协作。</p>
<p>CountDownLatch初始化100，也就说只有当countDown执行100次即任务TaskPortion执行100次，计数器从100减到0时，那么被CountDownLatch await阻塞的另外10个WaintTask才会继续执行。</p>
<p>构造出一种一个主线程等待分解任务线程完成以后才继续执行的场景。</p>
<h1 id="CyclicBarrier-栅栏"><a href="#CyclicBarrier-栅栏" class="headerlink" title="CyclicBarrier(栅栏)"></a>CyclicBarrier(栅栏)</h1><h2 id="使用场景-1"><a href="#使用场景-1" class="headerlink" title="使用场景"></a>使用场景</h2><p>希望创建一组任务，他们并行地执行工作，然后再进行下一个步骤之前等待，直至所有任务都完成(也有些像join)。它是使得所有的并行任务都将在栅栏处列队等待，因此可以一致地向前移动。<br>CyclicBarrier可以使一定数量的参与方反复地在栅栏位置汇集，它在迭代算法中非常有用：这种算法通常将一个问题拆分成一系列相互独立的子问题。</p>
<h2 id="与CountDownLatch区别"><a href="#与CountDownLatch区别" class="headerlink" title="与CountDownLatch区别"></a>与CountDownLatch区别</h2><p>也就是说，闭锁是一次性对象，一旦进入终止状态就不能被重置了，栅栏类似于闭锁，它能阻塞一组线程直到某个事件发生。<strong>栅栏与闭锁的关键区别在于</strong>：所有线程必须同时到达栅栏位置，才能继续执行。闭锁用于等待事件，而栅栏用于等待其他线程。栅栏主要用于实现一些协议，比如说，几个家庭决定在某个地方集合：”所有人在6:00麦当劳碰头，到了以后要等其他人，之后再讨论下一步要做的事情”。</p>
<p>总结<strong>CyclicBarrier与CountDownLatch的主要区别是</strong>:</p>
<ol>
<li>CountDownLatch对象的计数器置为0以后，下次所有线程过来就会全部通过，计数器不会重置。而CyclicBarrier的计数器置为0之后，等待在栅栏处的线程统一调用，之后计数器会重新置为初始值。</li>
<li>CyclicBarrier在计数器置为0之后，支持回调函数调用。</li>
</ol>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p><strong>当线程到达栅栏位置时将调用await方法，这个方法将阻塞直到所有线程到达该栅栏位置。如果所有线程都到达栅栏位置，那么栅栏被打开，此时所有线程都被释放，而栅栏将被重置以便下次使用。</strong>如果对await的调用超时，或者await阻塞的线程被中断，那么栅栏就认为是打破了，所有阻塞的await调用都讲终止并抛出BrokenBarrierException。</p>
<pre><code class="java">public class CellularAutomata {

    private final Board mainBoard;
    private final CyclicBarrier barrier;
    private final Worker[] workers;

    public CellularAutomata(Board board) {
        this.mainBoard = board;
        int count = Runtime.getRuntime().availableProcessors();
        //1. 初始化CyclicBarrier栅栏
        this.barrier = new CyclicBarrier(count,new Runnable() {

            verride
            public void run() {
                //4. 所有线程（count）都到达栅栏，注册的回调函数被调用，提交count个线程处理结果
                mainBoard.commitNewValues();
            }
        });
        //2. 初始化，count个子任务线程分解任务处理
        this.workers = new Worker[count];
        for(int i = 0 ; i &lt; count ; i++) {
            workers[i] = new Worker(mainBoard.getSubBoard(count,i));
        }
    }

    private class Worker implements Runnable {
        private final Board board;

        public Worker(Board board) {
            this.board = board;
        }
        verride
        public void run() {
            while(board.hasConverged()) {
                for(int x = 0 ; x &lt; board.getMaxX(); x++) {
                    for(int y = 0 ; y &lt; board.getMaxY();y++) {
                        board.setNewValue(x,y,computeValue(x,y));
                    }
                }
                try {
                    //3.子任务处理后，当前线程到达栅栏await阻塞等待
                    barrier.await();
                } catch (InterruptedException e) {
                    return;
                } catch (BrokenBarrierException e) {
                    return;
                }
            }
        }
        private int computeValue(int x, int y) {
            // Compute the new value that goes in (x,y)
            return 0;
        }
    }

    interface Board {
        int getMaxX();
        int getMaxY();
        int getValue(int x, int y);
        int setNewValue(int x, int y, int value);
        void commitNewValues();
        boolean hasConverged();
        void waitForConvergence();
        Board getSubBoard(int numPartitions, int index);
    }
}</code></pre>
<ol>
<li><p>初始化CyclicBarrier栅栏，<strong>栅栏初始化计数count</strong>，并<strong>注册回调函数</strong>。</p>
<pre><code class="java">        this.barrier = new CyclicBarrier(count,new Runnable() {

            verride
            public void run() {
                //4. 所有线程（count）都到达栅栏，注册的回调函数被调用，提交count个线程处理结果
                mainBoard.commitNewValues();
            }
        });</code></pre>
</li>
</ol>
<ol start="2">
<li><p>初始化各个处理线程</p>
<pre><code class="java">        //2. 初始化，count个子任务线程分解任务处理
        this.workers = new Worker[count];
        for(int i = 0 ; i &lt; count ; i++) {
            workers[i] = new Worker(mainBoard.getSubBoard(count,i));
        }</code></pre>
</li>
<li><p>各个处理线程分别处理分解的任务，<strong>处理完毕调用CyclicBarrier的await()方法</strong>，挂起线程。</p>
</li>
<li><p>所有count个线程处理完毕即所有线程已到达栅栏，<strong>调用栅栏初始化注册的回调函数</strong>，进一步处理结果。栅栏的初始化计数恢复为count。<strong>下一次主线程调用该CyclicBarrier对象计数仍然为count，不用重复初始化对象复用</strong>。</p>
</li>
</ol>
<h1 id="其他使用示例"><a href="#其他使用示例" class="headerlink" title="其他使用示例"></a>其他使用示例</h1><p>参考王宝令老师的[并发编程实战的CountDownLatch和CyclicBarrier：如何让多线程步调一致][<a href="https://time.geekbang.org/column/article/89461]" target="_blank" rel="noopener">https://time.geekbang.org/column/article/89461]</a></p>
<p>里面从一个实际的订单对账的例子，讲解了用join、CountdDowanLatch、CyclicBarrier一步步优化的过程。</p>
<h1 id="Exchanger-数据交换栅栏"><a href="#Exchanger-数据交换栅栏" class="headerlink" title="Exchanger(数据交换栅栏)"></a>Exchanger(数据交换栅栏)</h1><p>Exchanger，是一种两房(Two-Party)栅栏，各方在栅栏位置上交互数据。当两方执行不对称的操作时，Exchanger会非常有用，例如当一个线程向缓冲区写入数据，而另一个线程从缓冲区读取数据。这些线程可以使用Exchanger来汇合，并将满的缓冲区与空的缓冲区交换。当两个线程通过Exchanger交换对象时，这种交换就能把这两个对象安全地发布给对象。</p>
<p>一种典型场景是：使用Exchanger来实现生产者消费者任务，ExchangerProducer和ExchangerConsumer使用一个List<T>作为交换的对象，它们都包含一个用于这个List的Exchanger。当调用<strong>Exchanger.exchange()</strong>方法时，它将阻塞直至对方任务调用它自己的**exchange()方法，那时这两个exchange()方法将全部完成，而List则被互换。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><strong>CountDownLatch</strong>和<strong>CyclicBarrier</strong>是Java并发包提供的两个非常易用的线程同步工具类，这两个工具类用法的区别：</p>
<ul>
<li><p><strong>CountDownLatch主要用来解决一个线程等待多个线程的场景</strong>，可以类比旅游团长要等待所有游客到齐才能去下一个景点。</p>
</li>
<li><p>而<strong>CyclicBarrier是一组线程之间互相等待</strong>，更像是几个驴友之间一直不离不弃。</p>
</li>
</ul>
<ul>
<li><p><strong>CountDownLatch的计数器是不能循环利用的</strong>，也就是说一旦计数器减到0，再有线程调用await()该线程会直接通过。</p>
</li>
<li><p>但<strong>CyclicBarrier的计算器是可以循环利用，而且具备自动重置的功能</strong>，一旦计数器减到0会自动重置到设置的初始值。</p>
</li>
<li><p>除此之外，<strong>CyclicBarrier还可以设置回调函数</strong>。</p>
</li>
</ul>
<p>关于使用<a href="https://time.geekbang.org/column/article/89461" target="_blank" rel="noopener">CountDownLatch和CyclicBarrier解决多线程协同的好例子</a>可以参考阅读，写的非常好！</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
        <tag>线程协作</tag>
        <tag>信号量</tag>
      </tags>
  </entry>
  <entry>
    <title>【线程协作篇】三、信号量Semaphore-控制临界区资源的多线程访问</title>
    <url>/2019/07/06/2019-7-06-java-concurrency-communication-semphore/</url>
    <content><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Semaphore，又称为信号量，类似于现实生活中的信号灯，车辆能不能通行要看绿灯。同样，在编程世界里，线程能否运行，也要看信号量是不是允许。<strong>不同于concurrent.Lock或者内建的sychronized锁同一时刻最多只有一个线程访问临界区，Semaphore允许n个线程同时访问临界区。</strong></p>
<p>信号量由迪杰斯特拉于1965年提出，之后的15年，信号量一直都是并发编程领域的总结者，知道1980年管程被提出来，才有了第二选择。目前几乎所有的并发编程语言都支持信号量机制。</p>
<p>并发编程<a href="[https://zhoulei17.github.io/2019/05/09/java-concurreny-system-courrenency/#%E4%BF%A1%E5%8F%B7%E9%87%8F%E4%B8%8Epv%E6%93%8D%E4%BD%9C](https://zhoulei17.github.io/2019/05/09/java-concurreny-system-courrenency/#信号量与pv操作)">操作系统层面讲过信号量</a>,下面就简单介绍下信号量模型，以此说明信号量实现的原理。</p>
<h1 id="信号量模型"><a href="#信号量模型" class="headerlink" title="信号量模型"></a>信号量模型</h1><p>信号量模型很简单，可以概括为：<strong>一个计数器，一个等待队列，三个方法</strong>。在信号量模型里，计数器和等待队列是对外透明的，所以只能通过三个方法：init()、down()、up()来说明。用图来表示:</p>
<p><img data-src="/img/in-post/image-20190709235323544.png" alt=""></p>
<p>在三个方法详细的语义如下：</p>
<ul>
<li>init()：设置计算器的初始值，即资源的初始数量。</li>
<li>down()：等同于P、V信号量的P操作，申请资源的操作，计算器减1；如果此时计算器的值小于0，则当前线程被阻塞，否则当前线程可以继续执行。</li>
<li>up()：等同于P、V信号量的V操作，释放资源，计算器加1；如果此时计数器的值小于或者等于0，则唤醒等待队列中的一个线程，并将其从等待队列中移除。</li>
</ul>
<p>这里init()、down()、up()三个方法都是原子性的，并且原子性是由信号量模型的实现方保证的。在Java中，信号量由<code>java.util.cocurrent.Semaphore</code>实现，Semaphore类能保证这三个方法都是原子操作(具体原子操作如何保证，以及这三个方法的实现原理待后续源码解析)。大致的代码模型如下：</p>
<pre><code class="java">class Semaphore{
  // 计数器
  int count;
  // 等待队列
  Queue queue;
  // 初始化操作
  Semaphore(int c){
    this.count=c;
  }
  // 
  void down(){
    this.count--;
    if(this.count&lt;0){
      // 将当前线程插入等待队列
      // 阻塞当前线程
    }
  }
  void up(){
    this.count++;
    if(this.count&lt;=0) {
      // 移除等待队列中的某个线程 T
      // 唤醒线程 T
    }
  }
}
</code></pre>
<p>down()、up()等同信号量中的P、V操作申请与释放资源，在Java Semaphore中等价于acquire()和release()方法。</p>
<h1 id="如何使用信号量"><a href="#如何使用信号量" class="headerlink" title="如何使用信号量"></a>如何使用信号量</h1><h2 id="简单示例"><a href="#简单示例" class="headerlink" title="简单示例"></a>简单示例</h2><p>信号量等同于过红绿灯，绿灯给行人发放通行许可。只不过互斥场景运行一名行人通过(进入临界区)，而信号量允许多名行人通过进入临界区。下面以count+=1累加操作说明，只允许一个线程执行，也就是说要保证互斥。那这种情况信号量是如何控制的？</p>
<pre><code class="java">static int count;
// 初始化信号量
static final Semaphore s 
    = new Semaphore(1);
// 用信号量保证互斥    
static void addOne() {
  s.acquire();
  try {
    count+=1;
  } finally {
    s.release();
  }
}
</code></pre>
<p>分析下，信号量是如何保证互斥的。假设两个线程T1、T2同时访问addOne()方法。</p>
<p>当它们同时调用acquire()的时候，由于acquire是一个原子操作，所以只能由一个线程(假设是T1)把信号量减为0，另外一个线程(T2)则将计数器减为-1。</p>
<p>对于线程T1，信号量里面的计数器的值是0，大于等于0，所以线程T1会继续执行；</p>
<p>对于线程T2，信号量里面的计数器的值是-1，小于0，按照信号量模型里对down()操作的描述，线程T2将被阻塞。</p>
<p>所以此时只有线程T1会进入临界区执行count+=1；</p>
<p>当线程T1执行release操作，也就是up()操作的时候，信号量里的计数器的值是-1，加上1之后的值是0，大于等于0，按照信号量模型up()操作的描述，此时等待队列T2将被唤醒。于是T2在T1执行完临界区代码之后获得进入临界区的执行的许可，<strong>从而保证了互斥性。</strong></p>
<h1 id="使用信号量实现限流器"><a href="#使用信号量实现限流器" class="headerlink" title="使用信号量实现限流器"></a>使用信号量实现限流器</h1><p>上面的例子，我们用信号量实现了一个最简单的互斥锁功能。实际上信号量不同于Lock的功能，不单单只有一个互斥功能，还有一个功能是Lock不容易实现的，那就是：<strong>Semaphore可以允许多个线程同时访问临界区</strong>。</p>
<p>下面通过一个例子演示，如何控制不多于N个线程同时进入临界区的场景。比如实现一个对象池的功能，一次性创建出N个对象，之后所有线程重复利用这N个对象，当然在对象释放前，也是不允许其他线程使用的(如果对象本身需要保证线程安全)。这里面对对象的访问需要进行限流，就是不允许多于N个线程同时进入临界区。</p>
<pre><code class="java">package thread.communication.semaphore;

import java.util.List;
import java.util.Vector;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Semaphore;
import java.util.function.Function;

public class ObjectPool_Semaphore&lt;T,R&gt; {
    List&lt;T&gt; pool;
    //用信号量实现限流器
    final Semaphore sem;

    ObjectPool_Semaphore(int size,T t) {
        pool =  new Vector&lt;T&gt;();
        for (int i = 0 ; i &lt; size ; i ++) {
            Object obj = (Long)t + i;
            pool.add((T)obj);
        }
        sem = new Semaphore(size);
    }
    //利用对象池的对象，调用 func
    R exec(Function&lt;T,R&gt; func) throws InterruptedException {
        T t = null;
        sem.acquire();
        try {
            t = pool.remove(0);
            return func.apply(t);
        }finally {
            pool.add(t);
            sem.release();
        }
    }
    public static void main(String[] args) throws InterruptedException {
        //创建对象池
        final ObjectPool_Semaphore&lt;Long, String&gt; pool = new ObjectPool_Semaphore&lt;Long, String&gt;(15, 0L);
        Thread thread = new Thread(() -&gt;{
            try {
                for (int i = 0  ; i &lt; 10 ; i++) {
//                    Thread.sleep((long) (50*Math.random()));
                    pool.exec(t -&gt;  {
                        System.out.println(&quot;Thread ---&quot;+t);
                        return t.toString();
                    });
                }
            } catch (InterruptedException e) {
                // TODO Auto-generated catch block
                e.printStackTrace();
            }

        });
        ExecutorService exec = Executors.newCachedThreadPool();
        //通过4个线程，每个线程10次循环访问对象池 4*10次，也就是需要控制最多15个线程的进入临界区，对象池内有15个共享对象。
        exec.submit(thread);
        exec.submit(thread);
        exec.submit(thread);
        exec.submit(thread);
        exec.shutdown();
    }
}
</code></pre>
<p>注意这里面对象池的容器是用的Vector，因为在临界区内存在最多15个线程的并发，必须要对象容器是线程安全的容器才能保证安全不出错。</p>
<p>输出：</p>
<pre><code class="java">Launched all tasks
Waiting Task now WaitingTask 1  
Waiting Task now WaitingTask 7  
Waiting Task now WaitingTask 0  
Waiting Task now WaitingTask 4  
Waiting Task now WaitingTask 2  
Waiting Task now WaitingTask 5  
Waiting Task now WaitingTask 8  
Waiting Task now WaitingTask 6  
Waiting Task now WaitingTask 3  
43 completed
Waiting Task now WaitingTask 9  
99 completed
36 completed
95 completed
94 completed
11 completed
21 completed
77 completed
7  completed
9  completed
75 completed
79 completed
10 completed
40 completed
96 completed
63 completed
23 completed
34 completed
29 completed
38 completed
55 completed
90 completed
88 completed
28 completed
5  completed
50 completed
8  completed
1  completed
12 completed
27 completed
98 completed
13 completed
72 completed
71 completed
2  completed
45 completed
91 completed
14 completed
31 completed
17 completed
6  completed
97 completed
35 completed
69 completed
20 completed
32 completed
4  completed
68 completed
37 completed
47 completed
87 completed
70 completed
84 completed
86 completed
66 completed
54 completed
42 completed
41 completed
46 completed
74 completed
57 completed
65 completed
0  completed
80 completed
19 completed
60 completed
15 completed
89 completed
51 completed
25 completed
53 completed
62 completed
58 completed
92 completed
76 completed
22 completed
56 completed
18 completed
85 completed
61 completed
30 completed
59 completed
67 completed
26 completed
24 completed
48 completed
39 completed
33 completed
3  completed
52 completed
93 completed
81 completed
78 completed
73 completed
44 completed
82 completed
49 completed
64 completed
83 completed
16 completed
Latch barrier passed for WaitingTask 1  
Latch barrier passed for WaitingTask 7  
Latch barrier passed for WaitingTask 4  
Latch barrier passed for WaitingTask 2  
Latch barrier passed for WaitingTask 0  
Latch barrier passed for WaitingTask 5  
Latch barrier passed for WaitingTask 8  
Latch barrier passed for WaitingTask 6  
Latch barrier passed for WaitingTask 3  
Latch barrier passed for WaitingTask 9  </code></pre>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>在Java并发领域中，重点支持的还是管程模型：</p>
<p>引用网友不错的理解，来帮助理解信号量与管程的区别：</p>
<blockquote>
<p><img data-src="/img/in-post/image-20190710003048917.png" alt=""></p>
</blockquote>
<p>后续，还有Semaphore是如何实现acquire与release的，内部阻塞队列是如何做的？都使用了那些技巧？单独实现互斥与Lock的不同于优劣？敬请期待后面的详细的源码分析。</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
        <tag>线程协作</tag>
        <tag>信号量</tag>
      </tags>
  </entry>
  <entry>
    <title>【线程协作篇】二、生产者与消费者与阻塞队列</title>
    <url>/2019/07/04/2019-7-04-java-concurrency-communication-queue/</url>
    <content><![CDATA[<h1 id="生产者—消费者与队列"><a href="#生产者—消费者与队列" class="headerlink" title="生产者—消费者与队列"></a>生产者—消费者与队列</h1><p>wait和notifyAll方法是一种非常低级的方式解决任务互操作问题，即每次交互都握手。在很多情况下，可以使用更高的抽象级别。使用<strong>同步队列</strong>来解决任务协作问题。同步队列在任何时刻都允许一个任务拆入或移除元素。在<code>java.util.concurrent.BlockingQueue</code>接口中提供了这个队列，这个接口有大量的标准实现。通常可以使用LinkedBlockingQueue，它是一个无界队列，还可以使用ArrayBlockingQueue,它具有固定尺寸。</p>
<p>如果消费者任务试图从队列中获取元素，而此时队列为空，那么这些队列还可以挂起消费者线程，并且当有元素可用时恢复消费者任务。</p>
<h1 id="阻塞队列使用"><a href="#阻塞队列使用" class="headerlink" title="阻塞队列使用"></a>阻塞队列使用</h1><pre><code class="java">public class TestBlockingQueues {

    static void getKey() {
        try {
            new BufferedReader(new InputStreamReader(System.in)).readLine();
        } catch (IOException e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
        }
    }

    static void getKey(String message) {
        System.out.println(message);
        getKey();
    }

    static void test(String msg,BlockingQueue&lt;LiftOff&gt; queue) {
        System.out.println(msg);
        LiftOffRunner runner = new LiftOffRunner(queue);
        Thread t = new Thread(runner);
        t.start();
        for(int i = 0 ; i &lt; 5 ; i++) {
            runner.add(new LiftOff(5));
        }
        getKey(&quot;Press &#39;Enter&#39; (&quot; + msg+ &quot;)&quot;);
        t.interrupt();
        System.out.println(&quot;Finished &quot; + msg + &quot; test&quot;);
    }

    public static void main(String[] args) {
        test(&quot;LinkedBlockingQueue&quot;,new LinkedBlockingQueue&lt;LiftOff&gt;());
        test(&quot;ArrayBlockingQueue&quot;,new ArrayBlockingQueue&lt;LiftOff&gt;(3));
        test(&quot;SynchronousQueue&quot;,new SynchronousQueue&lt;LiftOff&gt;());
    }
}

class LiftOffRunner implements Runnable {
    private BlockingQueue&lt;LiftOff&gt; rockets;

    public LiftOffRunner(BlockingQueue&lt;LiftOff&gt; rockets) {
        this.rockets = rockets;
    }

    public void add(LiftOff lo) {
        try {
            rockets.put(lo);
        } catch (InterruptedException e) {
            // TODO Auto-generated catch block
            System.out.println(&quot;Interrupted during put()&quot;);
        }
    }
    verride
    public void run() {
        // TODO Auto-generated method stub
        try {
            while(!Thread.interrupted()) {
                LiftOff rocket = rockets.take();
                rocket.run();
            }
        } catch (InterruptedException e) {
            // TODO Auto-generated catch block
            System.out.println(&quot;Waking from take()&quot;);
        }

        System.out.println(&quot;Exiting LiftRunner&quot;);
    }
}</code></pre>
<h1 id="阻塞队列总结"><a href="#阻塞队列总结" class="headerlink" title="阻塞队列总结"></a>阻塞队列总结</h1><h2 id="类关系"><a href="#类关系" class="headerlink" title="类关系"></a>类关系</h2><p>阻塞队列都实现了BlockingQueue接口：</p>
<p><img data-src="/img/in-post/1562296938198.png" alt=""></p>
<p>另外阻塞队列都继承了AbstractQueue</p>
<p><img data-src="/img/in-post/1562296518137.png" alt=""></p>
<p>另外还有双端阻塞队列。</p>
<h2 id="队列接口和抽象类"><a href="#队列接口和抽象类" class="headerlink" title="队列接口和抽象类"></a>队列接口和抽象类</h2><ul>
<li>BlockingQueue<E>接口</li>
</ul>
<pre><code class="java">public interface BlockingQueue&lt;E&gt; extends Queue&lt;E&gt; {
    boolean add(E e);

    boolean offer(E e);

    void put(E e) throws InterruptedException;

    boolean offer(E e, long timeout, TimeUnit unit)
        throws InterruptedException;

    E take() throws InterruptedException;

    E poll(long timeout, TimeUnit unit)
        throws InterruptedException;

    int remainingCapacity();

    boolean remove(Object o);

    public boolean contains(Object o);

    int drainTo(Collection&lt;? super E&gt; c);

    int drainTo(Collection&lt;? super E&gt; c, int maxElements);
}</code></pre>
<ul>
<li>AbstractQueue<E></li>
</ul>
<pre><code class="java">public abstract class AbstractQueue&lt;E&gt;
    extends AbstractCollection&lt;E&gt;
    implements Queue&lt;E&gt; {

    protected AbstractQueue() {
    }

    public boolean add(E e) {
        if (offer(e))
            return true;
        else
            throw new IllegalStateException(&quot;Queue full&quot;);
    }

    public E remove() {
        E x = poll();
        if (x != null)
            return x;
        else
            throw new NoSuchElementException();
    }

    public E element() {
        E x = peek();
        if (x != null)
            return x;
        else
            throw new NoSuchElementException();
    }

    public void clear() {
        while (poll() != null)
            ;
    }

    public boolean addAll(Collection&lt;? extends E&gt; c) {
        if (c == null)
            throw new NullPointerException();
        if (c == this)
            throw new IllegalArgumentException();
        boolean modified = false;
        for (E e : c)
            if (add(e))
                modified = true;
        return modified;
    }

}</code></pre>
<h2 id="都有哪些阻塞队列"><a href="#都有哪些阻塞队列" class="headerlink" title="都有哪些阻塞队列"></a>都有哪些阻塞队列</h2><p><img data-src="/img/in-post/clipboard-1562305414748.png" alt=""></p>
<p>可以从上面看到主要有6个<strong>单端阻塞队列</strong>：</p>
<ul>
<li>ArrayBlockingQueue</li>
<li>DelayQeueue</li>
<li>LinkedBlockingQueue</li>
<li>PriorityBlockingQueue</li>
<li>SynchronousQueue</li>
<li>LkinedTransferQueue</li>
</ul>
<h3 id="LinkedBlockingQueue实际是有界阻塞队列"><a href="#LinkedBlockingQueue实际是有界阻塞队列" class="headerlink" title="LinkedBlockingQueue实际是有界阻塞队列"></a>LinkedBlockingQueue实际是有界阻塞队列</h3><ul>
<li><p>基于<strong>链表</strong>实现的BlockingQueue队列</p>
</li>
<li><p>LinkedBlockingQueue，<strong>容易被误解为无边界，但其实其行为和内部代码都是基于有界的逻辑实现的</strong>。</p>
</li>
</ul>
<p>只不过如果我们没有在创建队列时就指定容量，那么其容量限制就自动被设置为 Integer.MAX_VALUE，成为了无界队列。</p>
<h3 id="ArrayBlockingQueue有界阻塞队列"><a href="#ArrayBlockingQueue有界阻塞队列" class="headerlink" title="ArrayBlockingQueue有界阻塞队列"></a>ArrayBlockingQueue有界阻塞队列</h3><ul>
<li><p>基于<strong>数组</strong>实现的BlockingQueue有界阻塞队列。此对联按照FIFO的原则对元素进行排序。</p>
</li>
<li><p>典型的有界队列，其内部以final的数组保存数据，数组的大小决定了队列的边界，所以我们在创建ArrayBlockingQueue时，都要制定容量，如</p>
</li>
</ul>
<p><code>public ArrayBlockingQueue(int capacity,boolean fair)</code></p>
<h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><p>默认情况下不保证线程公平的访问队列，内部使用<code>lock = new ReentrantLock(fair);</code>可重入锁来实现且fair等于false。也可以支持设置fair=true，即lock为公平锁，从而支持公平阻塞队列，即先阻塞的队列先获得锁执行。为了保证公平性通常会降低吞吐量。</p>
<h4 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h4><p>初始化：</p>
<pre><code class="java">    public ArrayBlockingQueue(int capacity, boolean fair) {
        if (capacity &lt;= 0)
            throw new IllegalArgumentException();
        this.items = new Object[capacity];
        lock = new ReentrantLock(fair);
        notEmpty = lock.newCondition();
        notFull =  lock.newCondition();
    }</code></pre>
<p>分别为非阻塞与阻塞的插入off与put：</p>
<pre><code class="java">    public boolean offer(E e) {
        checkNotNull(e);
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            if (count == items.length)
                return false;
            else {
                enqueue(e);
                return true;
            }
        } finally {
            lock.unlock();
        }
    }

    /**
     * Inserts the specified element at the tail of this queue, waiting
     * for space to become available if the queue is full.
     *
     * hrows InterruptedException {@inheritDoc}
     * hrows NullPointerException {@inheritDoc}
     */
    public void put(E e) throws InterruptedException {
        checkNotNull(e);
        final ReentrantLock lock = this.lock;
        lock.lockInterruptibly();
        try {
            while (count == items.length)
                notFull.await();
            enqueue(e);
        } finally {
            lock.unlock();
        }
    }</code></pre>
<h3 id="SynchronousQueue-大小为1-一个不存储元素的阻塞队列"><a href="#SynchronousQueue-大小为1-一个不存储元素的阻塞队列" class="headerlink" title="SynchronousQueue 大小为1?一个不存储元素的阻塞队列"></a>SynchronousQueue 大小为1?一个不存储元素的阻塞队列</h3><ul>
<li>同步队列。对该队列的存、取操作必须交替进行。</li>
<li>这是一个非常奇葩的队列实现，每个删除操作都要等待插入操作，反之每个插入操作也都要等待其删除动作。那么这个队列的容量是多少呢？其实不是的，其内部容量是0。</li>
<li>默认情况，不保证线程公平的访问队列。可以创建一个公平阻塞队列。</li>
</ul>
<h3 id="PriorityBlockingQueue一个支持优先级排序的无界阻塞队列"><a href="#PriorityBlockingQueue一个支持优先级排序的无界阻塞队列" class="headerlink" title="PriorityBlockingQueue一个支持优先级排序的无界阻塞队列"></a>PriorityBlockingQueue一个支持优先级排序的无界阻塞队列</h3><ul>
<li><p>并不是标准的阻塞队列。与PriorityQueue类似，该队列调用remove、poll、take等方法去除元素时，并不是取出队列中存在时间最长的元素，而是队列中最小的元素。PriorityBlockingQueue判断元素的大小（Comparable）即可根据元素的大小来自然排序，也可以使用Comparator进行定制排序。</p>
</li>
<li><p>是无边界的优先队列，虽然严格意义上来讲，其大小总归是要受系统资源影响。</p>
</li>
</ul>
<h3 id="DelayQueue一个使用优先级队列的无界阻塞队列"><a href="#DelayQueue一个使用优先级队列的无界阻塞队列" class="headerlink" title="DelayQueue一个使用优先级队列的无界阻塞队列"></a>DelayQueue一个使用优先级队列的无界阻塞队列</h3><ul>
<li>是一种特殊的BlockingQueue，底层基于PriorityBlockingQueue实现。不过DelayQueue要求集合元素都实现Delay接口（该接口里只有一个long getDelay()方法），DelayQueue根据集合元素的getDelay()方法的返回值排序。</li>
<li>无边界队列</li>
</ul>
<h4 id="应用场景-1"><a href="#应用场景-1" class="headerlink" title="应用场景"></a>应用场景</h4><p>DelayQueue非常有用，可以用于以下场景：</p>
<ul>
<li><p>缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。</p>
</li>
<li><p>定时任务调度：使用DelayQueue保存当天将会执行的任务和执行时间，一旦从DelayQueue中获取到任务就开始执行，比如TimerQueue就使用DelayQueue实现的。</p>
</li>
</ul>
<p>  可以自己写一个DelayQueue的实现试试看。</p>
<h3 id="LinkedTransferQueue一个由链表结构组成的无界阻塞队列"><a href="#LinkedTransferQueue一个由链表结构组成的无界阻塞队列" class="headerlink" title="LinkedTransferQueue一个由链表结构组成的无界阻塞队列"></a>LinkedTransferQueue一个由链表结构组成的无界阻塞队列</h3><ul>
<li>无边界队列</li>
</ul>
<p>LinkedTransferQueue是一个由链表结构组成的无界阻塞TransferQueue队列。相对于其他阻塞队列，LinkedTransferQueue多了transfer和transfer方法。</p>
<h1 id="阻塞队列的方法之间的关系"><a href="#阻塞队列的方法之间的关系" class="headerlink" title="阻塞队列的方法之间的关系"></a>阻塞队列的方法之间的关系</h1><p>BlockingQueue包含的方法之间的对应关系</p>
<table>
<thead>
<tr>
<th></th>
<th>抛出异常</th>
<th>不同返回值</th>
<th>阻塞线程</th>
<th>指定超时时长</th>
</tr>
</thead>
<tbody><tr>
<td>队尾插入元素</td>
<td>add(e)</td>
<td>offer(e)</td>
<td>put(e)</td>
<td>offer(e,time,unit)</td>
</tr>
<tr>
<td>对头删除元素</td>
<td>remove()</td>
<td>poll()</td>
<td>take()</td>
<td>poll(time,unit)</td>
</tr>
<tr>
<td>获取、不删除元素</td>
<td>element()</td>
<td>peek()</td>
<td>无</td>
<td>无</td>
</tr>
</tbody></table>
<ul>
<li><p>BlockingQueue提供如下<strong>两个支持阻塞</strong>的方法。</p>
<ul>
<li>put(E e)：尝试把E元素放入BlockingQueue中，如果该队列的元素已满，则阻塞线程。</li>
<li>take()：尝试从BlockingQueue的头部取出元素，如果该队列的元素已空，则阻塞线程。</li>
</ul>
</li>
<li><p>BlockingQueue继承了Queue接口，当然也可以使用Queue接口的方法。这些方法可以归纳为<strong>三组</strong>。</p>
<ul>
<li>add(E)、offer(E e)和put(E e)：在队列尾部插入元素，当队列满时，这三个方法分别<strong>抛出异常、返回false、阻塞队列</strong>。</li>
</ul>
</li>
<li><p>remove()、poll()、take()：在对头部删除并返回删除的元素(remove返回boolean)。当队列已空时，这三个方法分别会<strong>抛出异常、返回false、阻塞队列</strong>。</p>
<ul>
<li>element()和peek()方法：在队列头取出但不删除元素，当队列为已空时，这两个方法分别<strong>抛出异常、返回false</strong>。</li>
</ul>
</li>
</ul>
<h1 id="阻塞队列的实现原理"><a href="#阻塞队列的实现原理" class="headerlink" title="阻塞队列的实现原理"></a>阻塞队列的实现原理</h1><p>如果队列是空，消费者会一直等待，当生产者添加元素时，消费者是被通知到当前队列已经有元素的呢？想想如果是你设计，如何让消费者和生产者进行高效通信的呢？下面来看JDK是怎么实现阻塞队列的。</p>
<p><strong>使用通知模式实现</strong>。所谓通知模式呢就是：当生产者往满的队列里面添加元素时会阻塞住生产者，当消费者消费了一个队列后，会通知生产者当前队列不可用。通过查看ArraryBlocking源码发现使用了Condition来实现通知模式。阻塞队列的阻塞方法put和take的代码如下：</p>
<pre><code class="java">    public void put(E e) throws InterruptedException {
        checkNotNull(e);
        final ReentrantLock lock = this.lock;
        lock.lockInterruptibly();
        try {
            while (count == items.length)
                notFull.await(); (1)
            enqueue(e); (2)
        } finally {
            lock.unlock();
        }
    }

    public E take() throws InterruptedException {
        final ReentrantLock lock = this.lock;
        lock.lockInterruptibly();
        try {
            while (count == 0)
                notEmpty.await();
            return dequeue();
        } finally {
            lock.unlock();
        }
    }
</code></pre>
<ul>
<li>调用put方法插入元素，如果队列满调用则在<code>notFull.await();</code>挂起线程并且等待对条件变量notFull的通知。</li>
<li>调动take取出并删除元素，如果队列已经为空则<code>notEmpty.await();</code>挂起线程并等待notEmpty的通知。</li>
</ul>
<p>正是通过条件变量的notEmpty和notFull的await达到阻塞的目的。</p>
<p>而何时通知这两个条件变量：</p>
<pre><code class="java">    private void enqueue(E x) {
        // assert lock.getHoldCount() == 1;
        // assert items[putIndex] == null;
        final Object[] items = this.items;
        items[putIndex] = x;
        if (++putIndex == items.length)
            putIndex = 0;
        count++;
        notEmpty.signal();
    }

    private E dequeue() {
        // assert lock.getHoldCount() == 1;
        // assert items[takeIndex] != null;
        final Object[] items = this.items;
        @SuppressWarnings(&quot;unchecked&quot;)
        E x = (E) items[takeIndex];
        items[takeIndex] = null;
        if (++takeIndex == items.length)
            takeIndex = 0;
        count--;
        if (itrs != null)
            itrs.elementDequeued();
        notFull.signal();
        return x;
    }</code></pre>
<ul>
<li>在生成调用enqueue后队列中存在元素了，就唤醒取元素的take线程在notEmpty状态上的阻塞，继续获取元素即dequeue。</li>
<li>在取出dequeue元素时，就唤醒put线程在notFull状态上的阻塞，</li>
</ul>
<p>在通过notEmpty和notFull这两个状态变量的控制来做到两个线程存取的满与空的相互协作通信。</p>
<p>而await的实现单独在AQS总结上解释。以下是await基于AQS上的实现。</p>
<pre><code class="java">        public final void await() throws InterruptedException {
            if (Thread.interrupted())
                throw new InterruptedException();
            Node node = addConditionWaiter();
            int savedState = fullyRelease(node);
            int interruptMode = 0;
            while (!isOnSyncQueue(node)) {
                LockSupport.park(this);
                if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
                    break;
            }
            if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)
                interruptMode = REINTERRUPT;
            if (node.nextWaiter != null) // clean up if cancelled
                unlinkCancelledWaiters();
            if (interruptMode != 0)
                reportInterruptAfterWait(interruptMode);
        }</code></pre>
<p><img data-src="/img/in-post/image-20191108005926618.png" alt=""></p>
<p>当往队列里插入一个元素时，如果队列不可用，那么阻塞生产者主要通过<code>LockSupport.park(this)</code>来实现。</p>
<pre><code class="java">    public static void park(Object blocker) {
        Thread t = Thread.currentThread();
        setBlocker(t, blocker);
        UNSAFE.park(false, 0L);
        setBlocker(t, null);
    }</code></pre>
<p><img data-src="/img/in-post/image-20191108010009201.png" alt=""></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://time.geekbang.org/column/article/90201" target="_blank" rel="noopener">并发容器：都有哪些“坑”需要我们填？</a></p>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
        <tag>线程协作</tag>
        <tag>阻塞队列</tag>
      </tags>
  </entry>
  <entry>
    <title>【线程协作篇】一、wait、notify、notifyAll&amp;Lock、Condition</title>
    <url>/2019/06/19/2019-6-19-java-concurrency-communication-wait-notify/</url>
    <content><![CDATA[<p>当使用线程运行多个任务时，可以通过锁（互斥）来同步两个任务的行为，从而使得一个任务不会干涉另一个任务的资源。两个任务在交替着访问某项共享资源(通常是内存)，可以使用互斥来使得任何时刻只有一个线程访问这项资源。</p>
<p>那么如何使任何彼此之间可以协作，以使得多个任务一起工作解决特定的问题，即解决的问题不是彼此之间的干涉，而是彼此之间的协作，因为在这类问题中，有一部任务必须在其他部分被解决之前解决。比如工程规划问题：必须先挖房子的地基，但是接下来可以并行地铺设钢结构和构建水泥部件，而这两项任务必须在混凝土浇筑之前完成。</p>
<p>任务协作，关键问题是任务之间的握手。为了实现握手，我们使用了<strong>相同的基础特征</strong>：互斥。在这种情况下，互斥能够确保只有一个任务可以响应某个信号，这样就可以根除任何可能的竞争条件。<strong>在互斥之上</strong>，我们为任何添加了一种途径，可以将其挂起，直到某些外部条件发生变化(例如，管道现在已经到位)，表示是时候让这个任务开动了。</p>
<p>这种握手，可以通过<strong>Object的方法wait和notify来安全地实现。JAVA SE5的并发类库还提供了具有await()和signal()方法的Condition对象</strong>。</p>
<h1 id="wait-与notifyAll-介绍"><a href="#wait-与notifyAll-介绍" class="headerlink" title="wait()与notifyAll()介绍"></a>wait()与notifyAll()介绍</h1><p>wait()会在等待外部条件发生变化的时候将任务挂起，并且只有在notify()和notifyAll()发生时，即表示发生了某些感兴趣的事物，这个任务才会被唤醒并去检查所发生的变化。因此，wait()提供了一种在任务之间对活动同步的方式。</p>
<p><strong>调用sleep()的时候锁并不会被释放，yield()也是如此；</strong></p>
<p>另外，当一个任务在方法中遇到wait()的调用的时候，线程的执行被挂起，对象上的锁被释放。正是因为wait()会释放锁，另外一个任务可以获得这个锁，因此在该对象中的其他sychronized方法可以在wait期间被调用。这一点至关重要，因为正是由于其他线程进入其他方法触发出使被挂起任务重新唤醒的状态变化。</p>
<h2 id="wait-与sleep-的不同点"><a href="#wait-与sleep-的不同点" class="headerlink" title="wait()与sleep()的不同点"></a>wait()与sleep()的不同点</h2><p>有两种形式的wait: </p>
<ul>
<li>第一种是带超时参数（毫秒）：</li>
</ul>
<ol>
<li>在wait期间对象锁是释放的。</li>
<li>可以通过notify、notifyAll或者另时间到期，从wait()中恢复。</li>
</ol>
<ul>
<li>第二种是不带参数的wait()。：</li>
</ul>
<p>这种wait()将无线等待下去，直到线程接收到notify()或者notifyAll的消息。</p>
<h2 id="注意是Object的wait、notify与notifAll"><a href="#注意是Object的wait、notify与notifAll" class="headerlink" title="注意是Object的wait、notify与notifAll"></a>注意是Object的wait、notify与notifAll</h2><p>wait()、notify以及notifyAll有一个比较特殊的方面，那就是这些方法是基于Object的一部分，而不是属于Thread的一部分。尽管开始看起来有点奇怪——仅仅针对线程的功能却作为通用基类的一部分而实现，不过这是有道理的，因为这些方法操作的锁也是所有对象的一部分。所以把wait放进任何同步控制方法中，而不用考虑这个类是继承自Thread还是实现了Runnable接口。<strong>实际上，只能在同步控制方法或同步块里调用wait、notify和notifyAll。</strong>(因为不用操作锁，所以sleep可以在非同步控制方法里调用)。</p>
<p>如果在非同步控制方法里调用这些方法，程序可以编译，但运行会报IllegalMonitorStateException异常，并伴随着一些含糊的消息，比如”当前线程不是所有者”，意思是，调用wait、notify和notifyAll的任务在调用这些方法时必须<strong>“拥有”</strong>对象的锁。</p>
<ul>
<li>对于使用sychronized修饰的同步方法，该类默认this就是同步监视器对象，因此可以在方法内直接调用者三个方法。</li>
<li>对于sychronized同步代码块，同步监视器是sychronzied括号内指定的对象，因此需要在指定的这个对象上调用这三个方法。</li>
</ul>
<h1 id="wait、notify、notifyAll的使用示例"><a href="#wait、notify、notifyAll的使用示例" class="headerlink" title="wait、notify、notifyAll的使用示例"></a>wait、notify、notifyAll的使用示例</h1><p>下面以Java编程思想中的 汽车打蜡示例来说明wait notify notifyAll的使用：</p>
<p>示例说明：两项任务，抛光和打蜡；</p>
<p>抛光任务在涂腊之前完成不能工作，而涂腊任务在涂另一层醋之前，必须等待抛光任务完成。</p>
<ul>
<li>共享对象为Car，打蜡抛光任务共同作用于Car：</li>
</ul>
<pre><code class="java">public class Car {

    private boolean waxOn = false;

    public synchronized void waxed() {
        waxOn = true;
        notifyAll();
    }

    public synchronized void buffed() {
        waxOn = false;
        notifyAll();
    }

    public synchronized void waitingForWaxing() throws InterruptedException {
        while(waxOn == false) {
            wait();
        }
    }

    public synchronized void waitingForBuffing() throws InterruptedException {
        while(waxOn == true) {
            wait();
        }
    }
}</code></pre>
<ul>
<li><p>抛光任务：</p>
<pre><code class="java">public class WaxOff implements Runnable {
    private Car car;
    public WaxOff(Car car) {
        this.car = car;
    }

    verride
    public void run() {
        // TODO Auto-generated method stub
        while(!Thread.interrupted()) {
            try {
                car.waitingForWaxing();
                System.out.println(&quot;Wax off!&quot;);
                TimeUnit.MILLISECONDS.sleep(200);
                car.buffed();
            } catch (InterruptedException e) {
                // TODO Auto-generated catch block
                System.out.println(&quot;Exiting via interrupt&quot;);
                Thread.currentThread().interrupt();//JVM异常处理会清除标志位，因此加入sleep被中断就会进入异常分支，就需要再次中断。
            }
        }
        System.out.println(&quot;Ending wax off txask&quot;);
    }

}</code></pre>
</li>
</ul>
<ul>
<li><p>打蜡任务：</p>
<pre><code class="java">public class WaxOn implements Runnable {
    private Car car;

    public WaxOn(Car car) {
        this.car = car;
    }
    verride
    public void run() {
        while(!Thread.interrupted()) {
            try {
                System.out.println(&quot;Wax on!&quot;);
                TimeUnit.MILLISECONDS.sleep(200);
                car.waxed();
                car.waitingForBuffing();
            } catch (InterruptedException e) {
                System.out.println(&quot;Exiting via interrupt&quot;);
                Thread.currentThread().interrupt();
            }
        }
        System.out.println(&quot;Ending wax on task&quot;);
    }
}</code></pre>
</li>
</ul>
<ul>
<li><p>main函数：</p>
<pre><code class="java">public class WaxOMatic {

    public static void main(String[] args) throws InterruptedException {
        Car car = new Car();
        ExecutorService exec = Executors.newCachedThreadPool();
        exec.execute(new WaxOff(car));
        exec.execute(new WaxOn(car));
        TimeUnit.SECONDS.sleep(5);
        exec.shutdownNow();
    }    
}</code></pre>
</li>
</ul>
<p>输出：</p>
<pre><code class="java">Wax on!
Wax off!
Wax on!
Wax off!
Wax on!
Wax off!
Wax on!
Wax off!
Wax on!
Wax off!
Wax on!
Wax off!
Wax on!
Wax off!
Wax on!
Wax off!
Wax on!
Wax off!
Wax on!
Wax off!
Wax on!
Wax off!
Wax on!
Wax off!
Wax on!
Exiting via interrupt
Ending wax off txask
Exiting via interrupt
Ending wax on task</code></pre>
<h1 id="notify-与notifyAll的区别"><a href="#notify-与notifyAll的区别" class="headerlink" title="notify()与notifyAll的区别"></a>notify()与notifyAll的区别</h1><p>在开发过程中，可能会有多个任务在单个Car对象上处于wait状态，因此调用notifiYAll()比只调用notify要更安全。但是如果只有两个任务的协作，即只有一个任务会处于wait状态，选择notifyAll和notifyAll就无所谓了。</p>
<p>使用notifyAll而不是notify算是一种优化。</p>
<ul>
<li>使用notify时，在众多等待同一个锁的任务中只会有一个被唤醒。因此<ul>
<li>如果使用notify，就必须确保被唤醒的是恰当的任务。</li>
<li>另外，为了使用notify，所有任务必须等待相同的条件，因为如果你有多个任务在等待不同的条件，那么你就没办法确定唤醒的是不是恰当的任务。</li>
</ul>
</li>
<li>使用notifyAll，那么所有在这个同步监视器（锁）上等待的任务都会被唤醒。</li>
</ul>
<h1 id="错失的信号"><a href="#错失的信号" class="headerlink" title="错失的信号"></a>错失的信号</h1><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>当两个线程使用notify/wait或notifyAll/wait进行协作时，有可能由于错误的加锁位置而错过信号。假设线程T1通知T2，下面的实现方式就是有这个问题的：</p>
<pre><code class="java">T1:
sychronized(sharedMonitor) {
  &lt;设置T2的条件&gt;
  sharedMonitor.notify();
}

T2:
while(someCondition) {
  //ponit 1
  sychronized(sharedMonitor) {
    sharedMoniotr.wait();
  }
}</code></pre>
<p>&lt;设置T2的条件&gt;设置someCondition=fale，告诉T2不用调用wait。</p>
<p>假设T2执行判断发现someConidition==true。在Point1处，线程调度器可能已经切换到T1（即还没来得及wait）。而T1又改变someCondition=false，然后就调用notify。</p>
<p>当线程又重新切换至T2时，此时T2从Ponit1继续执行，盲目了执行wait挂起T2线程（而实际上状态条件已经被T1改变了，即somecondition=false，即T2不应该调用wait），<strong>那么此时T1刚刚发出的notify()就错失掉了</strong>。而T2也将无限地等待这个已经发送过的信号（即发生了notify,wait控制的错乱），此时产生了<strong>死锁</strong>。</p>
<p>说明T2的wait操作依赖T1和T2共享的someCondition，是一个竞态条件，</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a><strong>解决方案</strong></h2><p>该问题的解放方案就是防止在someCondition变量上产生竞态条件。下面是T2正确的执行方式：</p>
<pre><code class="java">sychronized(sharedMonitor) {
  while(someConidition) {
    sharedMonitor.wait();
  }
}</code></pre>
<p>现在，如果T1首先执行，当控制返回T2时，T2将发现条件发生了变化，从而不会进入wait()。</p>
<p>反过来，如果T2首先执行，那它将进入wait()，并且稍后会由T1唤醒。因此，信号不会丢失了。</p>
<h1 id="使用wait、notify实现生产者与消费者"><a href="#使用wait、notify实现生产者与消费者" class="headerlink" title="使用wait、notify实现生产者与消费者"></a>使用wait、notify实现生产者与消费者</h1><p>wait、notify还经常用于实现生产者和消费者类应用场景。</p>
<ul>
<li>类：一个饭店(Restaurant)，它有一个厨师(Chef)和一个服务员(WaitPerson)。</li>
<li>逻辑：服务员必须等待厨师准备好膳食，当厨师准备好膳食通知服务员，之后服务员上菜，然后继续等待。厨师代表生产者，服务员代表消费者。两个任务必须在膳食被生产和消费时进行握手，而系统必须以有序的方式关闭。</li>
</ul>
<ul>
<li>饭店：<pre><code class="java">package thread.communication.producerconsumer;
</code></pre>
</li>
</ul>
<p>import java.util.concurrent.ExecutorService;<br>import java.util.concurrent.Executors;<br>import java.util.concurrent.TimeUnit;</p>
<p>public class Restaurant {<br>    Meal meal;<br>    ExecutorService exec = Executors.newCachedThreadPool();<br>    WaitPerson waitPerson = new WaitPerson(this);<br>    Chef chef = new Chef(this);</p>
<pre><code>public Restaurant() {
    exec.execute(chef);
    exec.execute(waitPerson);
}

public static void main(String[] args) {
    new Restaurant();
}</code></pre><p>}<br>class Meal {<br>    private final int orderNum;</p>
<pre><code>public Meal(int orderNum) {
    this.orderNum = orderNum;
}

verride
public String toString() {
    return &quot;Meal [orderNum=&quot; + orderNum + &quot;]&quot;;
}</code></pre><p>}</p>
<pre><code>* 服务员：
```java
class WaitPerson implements Runnable {

    private Restaurant restaurant;

    public WaitPerson(Restaurant restaurant) {
        this.restaurant = restaurant;
    }

    verride
    public void run() {
        try {
            while (!Thread.interrupted()) {
                synchronized (this) {
                    while (restaurant.meal == null) {
                        wait();
                    }
                }
                System.out.println(&quot;Waitperson got &quot; + restaurant.meal);
                synchronized (restaurant.chef) {
                    restaurant.meal = null;
                    restaurant.chef.notifyAll();
                }
            }
        } catch (InterruptedException e) {
            System.out.println(&quot;WaitPerson interrupted&quot;);
        }
    }
}</code></pre><ul>
<li>厨师：</li>
</ul>
<pre><code class="java">class Chef implements Runnable {
    private Restaurant restaurant;
    private int count = 0;

    public Chef(Restaurant r) {
        restaurant = r;
    }

    public void run() {
        try {
            while (!Thread.interrupted()) {
                synchronized (this) {
                    while (restaurant.meal != null) {
                        wait();
                    }
                }
                if (++count == 10) {
                    System.out.println(&quot;Out of food,closing&quot;);
                    restaurant.exec.shutdownNow();
                }
                System.out.print(&quot;Order up! &quot;);
                synchronized (restaurant.waitPerson) {
                    restaurant.meal = new Meal(count);
                    restaurant.waitPerson.notifyAll();
                }
                TimeUnit.MILLISECONDS.sleep(100);
            }
        } catch (InterruptedException e) {

            System.out.println(&quot;Chef interrupted&quot;);
        }

    }
}
</code></pre>
<p>输出：</p>
<p><img data-src="/img/in-post/image-20190703232317885.png" alt=""></p>
<p>后续篇，在总结队列时，还会介绍再用队列来实现生产者消费者场景的应用。</p>
<h1 id="使用显式的Lock和Condition对象"><a href="#使用显式的Lock和Condition对象" class="headerlink" title="使用显式的Lock和Condition对象"></a>使用显式的Lock和Condition对象</h1><p>使用互斥并允许挂起的基本类是<strong><code>Condition</code></strong>，可以通过在<code>Conditio</code>上调用<strong><code>await()</code></strong>来挂起一个任务。当外部条件发生变化时，以为着某个任务应该继续执行，可以通过调用<strong><code>signal()</code></strong>来通知这个任务，从而唤醒一个任务，或者调用singalAll来唤醒所有这个Condition上被其他自身挂起的任务(与使用notifyAll相比，signalAll是更安全的方式)。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol>
<li>Wait、notify、notifyAll是Object的方法，且wait调用只阻塞和唤醒线程，阻塞时不持有锁。</li>
<li>Wait、notify、notifyAll要在锁内（互斥）调用，且锁的监视器对象为当前wait、notifyAll阻塞唤醒的对象。如上面的厨师和服务员的例子可以看到加锁的监视器对象可以看出。</li>
<li>注意notify和notifAll的区别。</li>
<li>注意加锁的范围，防止错失信号的发生。</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
        <tag>线程协作</tag>
        <tag>wait</tag>
      </tags>
  </entry>
  <entry>
    <title>【基本概念篇】十一、Java线程的状态和生命周期</title>
    <url>/2019/05/15/2019-5-15-java-concurreny-java-thread-status/</url>
    <content><![CDATA[<p>Java线程本质上就是操作系统的线程，它们是一一对应的。</p>
<p>在操作系统层面，线程也有“生老病死”，专业的说法叫生命周期。对于有生命周期的事物，要学好它，思路非常简单，只要能搞懂<strong>生命周期中各个节点的状态转换机制</strong>就可以了。</p>
<p>虽然不同的开发语言对于操作系统线程进行了不同的封装，但是对于线程的生命周期这部分，基本上是雷同的。所以，我们先来了解一下通用的线程生命周期模型，这部分内容也适用于很多其他编程语言；然后再针对性地学习一下Java中线程的生命周期。</p>
<h1 id="通用的线程生命周期"><a href="#通用的线程生命周期" class="headerlink" title="通用的线程生命周期"></a>通用的线程生命周期</h1><p>通用的线程生命基本上可以用下图“五态模型”来描述。这五态分别是：<strong>初始状态、可运行状态、休眠状态和终止状态</strong>。</p>
<p><img data-src="/img/in-post/1558418791341.png" alt=""></p>
<ol>
<li><strong>初始状态</strong>：指线程已经被创建，但是还不允许分配CPU执行。此状态属于编程语言特有，仅仅是在编程语言层面被创建（如果是Java开发，可以认为是Java内部状态），在操作系统层面真正的线程还没有被创建。</li>
<li><strong>可运行状态</strong>：指的是线程可以分配CPU执行。在这种状态下，真正的操作系统线程已经被成功创建了，所以可以分配CPU执行。</li>
<li><strong>运行状态</strong>：当有空闲CPU时，操作系统会将其分配给一个处于可运行状态的线程，被分配到CPU的线程的状态就转换成了运行状态。</li>
<li><strong>休眠状态</strong>：运行状态的线程如果调用一个阻塞的API(例如已阻塞方式读文件)或者等待某个事件（例如条件变量），那么线程的状态就会转换到休眠状态，同时释放CPU使用权，休眠状态的线程永远没有机会获得CPU的使用权。当等待的时间出现了，线程就会从休眠状态转换为可运行状态。</li>
<li><strong>终止状态</strong>：线程执行完或者出现异常就会进入终止状态，终止状态的线程不会切换到其他任何状态，进入终止状态也就意味着线程的生命周期结束了。</li>
</ol>
<p>这五种状态在不同的变成语言里面会有简化合并。例如，C语言的POSIX Thread规范，就把初始状态和可运行状态合并了；Java语言里则把可运行状态和运行状态合并了，这两个状态在操作系统调用层面有用，而JVM不关心这两个状态，因为JVM把线程调度交给操作系统处理了。</p>
<p>除了简化合并，这五种状态也有可能被简化，比如，Java里就喜欢了休眠状态，下面来详细说。</p>
<h1 id="Java中的线程生命周期"><a href="#Java中的线程生命周期" class="headerlink" title="Java中的线程生命周期"></a>Java中的线程生命周期</h1><p>在<code>java.lang.Thread</code>包的<code>Thread</code>里有个内部枚举类<code>State</code>定义了Thread的状态：</p>
<pre><code class="java">public enum State {
        /**
         * Thread state for a thread which has not yet started.
         */
        NEW,

        /**
         * Thread state for a runnable thread.  A thread in the runnable
         * state is executing in the Java virtual machine but it may
         * be waiting for other resources from the operating system
         * such as processor.
         */
        RUNNABLE,

        /**
         * Thread state for a thread blocked waiting for a monitor lock.
         * A thread in the blocked state is waiting for a monitor lock
         * to enter a synchronized block/method or
         * reenter a synchronized block/method after calling
         * {@link Object#wait() Object.wait}.
         */
        BLOCKED,

        /**
         * Thread state for a waiting thread.
         * A thread is in the waiting state due to calling one of the
         * following methods:
         * &lt;ul&gt;
         *   &lt;li&gt;{@link Object#wait() Object.wait} with no timeout&lt;/li&gt;
         *   &lt;li&gt;{@link #join() Thread.join} with no timeout&lt;/li&gt;
         *   &lt;li&gt;{@link LockSupport#park() LockSupport.park}&lt;/li&gt;
         * &lt;/ul&gt;
         *
         * &lt;p&gt;A thread in the waiting state is waiting for another thread to
         * perform a particular action.
         *
         * For example, a thread that has called &lt;tt&gt;Object.wait()&lt;/tt&gt;
         * on an object is waiting for another thread to call
         * &lt;tt&gt;Object.notify()&lt;/tt&gt; or &lt;tt&gt;Object.notifyAll()&lt;/tt&gt; on
         * that object. A thread that has called &lt;tt&gt;Thread.join()&lt;/tt&gt;
         * is waiting for a specified thread to terminate.
         */
        WAITING,

        /**
         * Thread state for a waiting thread with a specified waiting time.
         * A thread is in the timed waiting state due to calling one of
         * the following methods with a specified positive waiting time:
         * &lt;ul&gt;
         *   &lt;li&gt;{@link #sleep Thread.sleep}&lt;/li&gt;
         *   &lt;li&gt;{@link Object#wait(long) Object.wait} with timeout&lt;/li&gt;
         *   &lt;li&gt;{@link #join(long) Thread.join} with timeout&lt;/li&gt;
         *   &lt;li&gt;{@link LockSupport#parkNanos LockSupport.parkNanos}&lt;/li&gt;
         *   &lt;li&gt;{@link LockSupport#parkUntil LockSupport.parkUntil}&lt;/li&gt;
         * &lt;/ul&gt;
         */
        TIMED_WAITING,

        /**
         * Thread state for a terminated thread.
         * The thread has completed execution.
         */
        TERMINATED;
    }
</code></pre>
<p>Java中线程的六种状态，分别是：</p>
<ol>
<li>NEW（初始化状态）</li>
<li>RUNNABLE（可运行/运行状态）</li>
<li>BLOCKED（阻塞状态）</li>
<li>WAITING（无时限等待）</li>
<li>TIMED_WAITING（有时限等待）</li>
<li>TERMINATED（终止状态）</li>
</ol>
<p>相比操作系统的五种状态比较多，实际在操作层面，Java线程中的BLOCKED、WAITING、TIME_WAITING是一种状态，即前面提到的<strong>休眠状态</strong>。也就说<strong>只要Java线程处于这三种状态之一，那么这个线程就永远没有CPU使用权</strong>。</p>
<p>所以Java线程的生命周期可以简化转化为：</p>
<p><img data-src="/img/in-post/1558418772484.png" alt=""></p>
<p>其中，BLOCKED、WAITING、TIMED_WAITING可以理解为导致线程休眠的三种原因。</p>
<p>那么那些情形会导致线程从RUNNABLE状态转换到这三种状态？</p>
<p>这三种状态又是何时转换回RUNNABLE的呢？</p>
<p>NEW、TERMINATED和RUNNABLE状态是如何转换的？</p>
<h1 id="Java生命周期状态转换"><a href="#Java生命周期状态转换" class="headerlink" title="Java生命周期状态转换"></a>Java生命周期状态转换</h1><p>一个典型的状态转换图如下：</p>
<p><img data-src="/img/in-post/clipboard.png" alt=""></p>
<p>当然不止图中的条件触发状态转换，如下：</p>
<h2 id="1-RUNNABLE-lt-——-gt-BLOCKED-的状态转换"><a href="#1-RUNNABLE-lt-——-gt-BLOCKED-的状态转换" class="headerlink" title="1. RUNNABLE &lt;——&gt; BLOCKED 的状态转换"></a>1. RUNNABLE &lt;——&gt; BLOCKED 的状态转换</h2><ol>
<li><strong>等待synchronized的隐式锁</strong>或者LOCK显式锁。synchronized修饰的方法、代码同一时刻只允许一个线程执行，其他线程只能等待，这种情况下等待的线程就会从RUNNABLE转换到BLOCKED状态。而当等待的线程获得synchronized隐式锁时，就又会从BLOCKED转换到RUNNABLE状态。</li>
<li><strong>IO阻塞</strong>。例如执行InputStream的read()方法，该方法一直阻塞到从流中读取一个字节为止，它可以无限阻塞不能指定超时时间。</li>
</ol>
<h2 id="2-RUNNABLE-lt-——-gt-WAITING的状态转换"><a href="#2-RUNNABLE-lt-——-gt-WAITING的状态转换" class="headerlink" title="2. RUNNABLE&lt;——&gt;WAITING的状态转换"></a>2. RUNNABLE&lt;——&gt;WAITING的状态转换</h2><p>总体来说，有四种场景会触发这种转换：</p>
<ol>
<li>第一种场景，获得synchronized隐式锁的线程，<strong>调用无参数的Object.wait()方法</strong>。类似生产消费者模式，发现任务条件尚未满足，就让消费线程wait()，另外的生产者线程去准备条件，满足notify消费线程。（还有concurrent包中的singal和signalAll()）</li>
<li>第二种场景，<strong>调用无参数的Thread.join()方法</strong>。其中join()是一种线程同步方法，例如有一个线程对象thread A，当调用A.join()的时候，执行这条语句的线程就会等待thread A执行完，而等待中的这个线程，其状态就会从RUNNABLE转换到WAITING。当线程thread A执行完，原来等待它的线程又会从WAITING转换到RUNNABLE。</li>
<li>第三种场景，<strong>调用LockSupport.park()方法</strong>。其中的LockSupport对象，其实Java并发包中的锁都是基于它实现的。调用LockSupport.park()方法，当先线程会阻塞，线程状态从RUNNABLE转换到WAITING。调用LockSupport.unpark(Thread thread)可以唤醒目标线程，目标线程状态又会从WAITING状态转换到RUNNABLE。</li>
</ol>
<h2 id="3-RUNNABLE-lt-——-gt-TIMED-WAITING-的状态转换"><a href="#3-RUNNABLE-lt-——-gt-TIMED-WAITING-的状态转换" class="headerlink" title="3. RUNNABLE&lt;——&gt; TIMED_WAITING 的状态转换"></a>3. RUNNABLE&lt;——&gt; TIMED_WAITING 的状态转换</h2><p>有五种场景会触发这种转换：</p>
<ol>
<li>调用<strong>带超时参数的</strong>Thread.sleep(long millis)方法；</li>
<li>获得synchronized隐式锁的线程，调用<strong>带超时参数</strong>的Object.wait(long timeout)方法；</li>
<li>调用<strong>带超时参数</strong>的Thread.join(long millis)方法；</li>
<li>调用<strong>带超时参数</strong>的LockSupport.parkNanos(Object blocker,long deadline)方法；</li>
<li>调用<strong>带有超时参数</strong>的LockSupport.parkUntil(long deadline)方法。</li>
</ol>
<h2 id="4-NEW-——-gt-RUNNABLE状态"><a href="#4-NEW-——-gt-RUNNABLE状态" class="headerlink" title="4. NEW ——&gt;RUNNABLE状态"></a>4. NEW ——&gt;RUNNABLE状态</h2><p>NEW状态的线程不会被操作系统调度，因此不会执行。Java线程要执行，就必须转换到RUNNABLE状态。从NEW状态转换到RUNNABLE状态很简单，只要调用线程对象的start()方法就可以了。</p>
<h2 id="5-RUNNABLE——-gt-TERMINATED的状态"><a href="#5-RUNNABLE——-gt-TERMINATED的状态" class="headerlink" title="5. RUNNABLE——&gt;TERMINATED的状态"></a>5. RUNNABLE——&gt;TERMINATED的状态</h2><p>线程执行完run方法后，会自动转换到TERMINATED状态，当然如果执行run()方法的时候异常抛出，也会导致线程终止。有时候我们需要强制中断run()方法的执行，例如run()方法访问了一个很慢的网络，我们等不下去了，想终止怎么办呢？Java的Thread类里面倒是有个stop()方法，不过已经标记为@Deprecated，不建议使用了。合适的方式是调用interrupt()方法。</p>
<h1 id="stop-与interrupt"><a href="#stop-与interrupt" class="headerlink" title="stop()与interrupt()"></a>stop()与interrupt()</h1><p>那stop和interrupt方法的主要区别是什么？</p>
<ul>
<li><p><strong>stop()</strong>：方法会真正杀死线程，不会给线程喘息的机会，如果线程持有ReentrantLock锁，被stop的线程并不会自动调用ReentrantLock锁的unlock方法释放锁，那其他线程就再也没机会获得ReentrantLock锁了，危险！所以该方法不建议使用了，类似的情况还有suspend和resume方法，这两个方法同样不建议使用。</p>
</li>
<li><p><strong>interrupt()</strong>：相对温柔很多，interrupt()方法仅仅是通知线程，线程有机会执行一些后续操作，同样也可以无视这个通知。被interrupt的线程，是怎么收到通知的？一种是异常，另一种是主动检测，关于interrupt的内容，在<a href="https://zhoulei17.github.io/2019/03/09/java-concurreny-control-thread/#%E7%BB%88%E7%BB%93%E4%BB%BB%E5%8A%A1" target="_blank" rel="noopener">控制线程</a>中详细介绍了，可以跳过去看。这里再提下：</p>
<ul>
<li><p>当线程A处于WAITING、TIMED_WAITING状态时，如果其他线程调用线程A的interrupt()，会使线程A返回到RUNNABLE状态，同时线程A的代码会触发InterruptedException异常。上面提到的WAITING、TIMED_WAITING状态的触发条件，都是调用了类似wait()、join()、sleep()这样的方法，这些方法仔细看会发现都是throws InterruptedException这个异常。这个异常的触发条件是：其他线程调用了该线程的interrupt()方法。</p>
</li>
<li><p>当线程A处于RUNNABLE状态时，并且阻塞在java.nio.channels.InterruptibleChannel上时，如果其他线程调用线程A的interrupt()方法，线程A会触发java.nio.channels.ClosedByInterruptException异常；而阻塞在java.nio.channels.Selector上时，如果其他线程调用线程A的interrupt()，线程A的java.nio.channels.Selector会立即返回。</p>
</li>
</ul>
</li>
</ul>
<pre><code>上面的这两种情况属于被中断的线程通过异常的方式获得通知。还有一种是主动监测，如果线程处于RUNNABLE状态，并且没有阻塞在某个I/O操作上，例如中间计算圆周率的线程A，这时就得依赖线程A主动监测中断状态了。如果其他线程调用线程A的interrupt()方法，那么线程A可以通过isInterrupted()方法，检测是不是自己被中断了。</code></pre><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="再总结导致线程阻塞的情况"><a href="#再总结导致线程阻塞的情况" class="headerlink" title="再总结导致线程阻塞的情况"></a>再总结导致线程阻塞的情况</h2><ol>
<li>（状态：TIMED_WAITING，可中断）线程执行Thread.sleep(time)，它一直阻塞或者阻塞到指定的毫秒时间之后，或者阻塞被另一个线程中断。</li>
<li>（状态：WAITING或者TIMED_WAITING，可中断）Object.wait()/Object.wait(time)，他会一直阻塞直到通知（notify/notifyAll）、被中断或者等待指定时间。</li>
<li>（状态：BLOCKED，不可中断）导致线程阻塞的不同I/O方式有很多。常见的一种方式是InputStream的read()方法，该方法一直阻塞到从流中读取一个字节的数据为止，它可以无限阻塞，不能指定超时时间。</li>
<li>（状态：BLOCKED，不可中断）线程也可以阻塞等待获取某个对象锁的排他性访问权限（即等待获得synchronized锁时阻塞）。</li>
</ol>
<table>
<thead>
<tr>
<th align="center">状态</th>
<th>触发</th>
<th>中断措施</th>
<th>恢复状态</th>
</tr>
</thead>
<tbody><tr>
<td align="center">BLOCKED</td>
<td>等待synchronized隐式锁</td>
<td>不可中断</td>
<td>获得锁</td>
</tr>
<tr>
<td align="center">BLOCKED</td>
<td>等待Lock显式锁</td>
<td>使用超时锁或者可中断锁</td>
<td>获得锁</td>
</tr>
<tr>
<td align="center">BLOCKED</td>
<td>IO阻塞如read()</td>
<td>不可中断</td>
<td>读到字节</td>
</tr>
<tr>
<td align="center">WAITING</td>
<td>thread A.join()</td>
<td>interrupt()</td>
<td>thread A执行结束</td>
</tr>
<tr>
<td align="center">WAITING</td>
<td>Object A.wait()</td>
<td>interrupt()</td>
<td>Object.notify/A.notifyAll</td>
</tr>
<tr>
<td align="center">WAITING</td>
<td>LockSupport.park()</td>
<td>不可中断</td>
<td>LockSupport.unPark()</td>
</tr>
<tr>
<td align="center">TIMED_WAITING</td>
<td>Thread.sleep(time)</td>
<td>interrupt()</td>
<td>当前线程sleep结束</td>
</tr>
<tr>
<td align="center">TIMED_WAITING</td>
<td>thread A.join(time)</td>
<td>interrupt()</td>
<td>thread A执行结束</td>
</tr>
<tr>
<td align="center">TIMED_WAITING</td>
<td>Object A.wait(time)</td>
<td>interrupt()</td>
<td>Object.notify/A.notifyAll</td>
</tr>
<tr>
<td align="center">TIMED_WAITING</td>
<td>LockSupport.parkNanos(Object blocker,long deadline)或LockSupport.parkUntil(long deadline)</td>
<td>不可中断</td>
<td>LockSupport.unPark()</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
        <tag>生命周期</tag>
      </tags>
  </entry>
  <entry>
    <title>【基本概念篇】十二、如何构建线程安全的对象——对象的共享</title>
    <url>/2019/05/15/2019-5-22-java-concurreny-how-to-dev-objshare/</url>
    <content><![CDATA[<p>当多个线程访问某个状态变量并且其中有一个线程是写操作时，必须采用同步机制来协同这些线程对变量的访问。</p>
<p>Java中的主要同步机制是关键字synchronized，提供独占的加锁方式，当然”同步”这个术语还包括volatile、显式锁以及原子变量。</p>
<p>可以总结，如果当多个线程访问同一个可变的状态变量时没有使用合适的同步，那么程序就会出错。有哪些方式可以修复的<strong>并发策略</strong>：</p>
<ul>
<li>不在线程之间共享该状态变量，也可以说<strong>无状态</strong>的对象的肯定是线程安全的</li>
<li>将状态变量修改为<strong>不可变的变量</strong></li>
<li>在访问状态变量时<strong>使用同步</strong></li>
</ul>
<p>之前总结了如何通过同步来避免多个线程同一时刻访问相同的数据。本篇文章主要讲：怎么共享和发布对象，从而使他们能够安全地被多个线程同时访问。即：</p>
<ol>
<li>一方面，我们不仅希望防止某个线程被正在使用对象状态而另一个线程同时修改状态。</li>
<li>另一方面，我们还希望当一个线程修改了对象状态后，其他线程能够看到发生状态的变化。如果没有同步，就无法实现。</li>
</ol>
<p>关键字synchronized不仅仅可以实现原子性或者确定”临界区”，同时也能够实现共享对象的<strong>内存可见性</strong>。</p>
<blockquote>
<p>加锁的含义不仅仅局限于互斥行为，还包括内存可见性。为了确保所有线程都能看到共享变量的最新值，所有执行读操作或者写操作的线程都必须在同一个锁上同步。</p>
</blockquote>
<p>除了synchronized实现的同步可见性方案，Java语言还提供一种稍弱的同步机制，即volatile变量，用来确保变量的更新操作通知到其他线程。</p>
<h1 id="1-可见性-volatile"><a href="#1-可见性-volatile" class="headerlink" title="1. 可见性(volatile)"></a>1. 可见性(volatile)</h1><p>由于重排序，程序的执行结果往往让人产生错觉。</p>
<h2 id="volatile变量"><a href="#volatile变量" class="headerlink" title="volatile变量"></a>volatile变量</h2><p>当把变量声明为volatile类型后，编译器与运行时都会注意到这个变量是共享的，因此不会将变量上的操作与其他内存操作一起重排序。volatile变量不会被缓存在寄存器或者本地内存中，因此在读取volatile类型的变量时总会返回最新写入的值。</p>
<p>在访问volatile变量时不会执行加锁操作，因此也就不会使线程阻塞，因此volatile变量是一种比sychronized关键字更轻量级的同步。不建议过度依赖volatile变量提供的可见性，如果在代码中依赖volatile变量来控制状态可见性，通常比使用锁的代码更脆弱，也更难以理解。</p>
<blockquote>
<p>仅当volatile变量能够简化代码的实现以及对同步策略的验证时，才应该使用它们。如果在验证正确性需要对可见性进行复杂判断，那么就不要使用volatile变量。volatile变量的正确使用方式包括：</p>
<ol>
<li>确保它们自身状态的可见性。</li>
<li>确保它们所引用对象的状态的</li>
<li>标识一些重要的程序生命周期事件的发生(例如，初始化或关闭)</li>
</ol>
</blockquote>
<p><strong>volatile的典型用法</strong>：检查某个状态标记以判断是否退出循环。</p>
<pre><code class="java">volatile boolean asleep;
...
  while(!asleep)
    countSomeSheep();</code></pre>
<p>虽然volatile变量很方便，但也存在一些局限性。volatile变量通常用作某个操作完成、发生中断或者状态的标志。例如上面的asleep标志。尽管volatile变量也可以用于表示其他的状态信息，但使用时要注意，比如volatile语义不能确保递增操作(count++)的原子性，除非确保只有一个线程对变量执行写操作。(原子变量提供了”读—改—写”的原子操作)，并且常常用做一种”更好的volatile变量”。</p>
<blockquote>
<p>加锁机制既可以确保可见性又可以确保原子性，而volatile变量只能确保可见性。</p>
</blockquote>
<h2 id="volatile使用场景"><a href="#volatile使用场景" class="headerlink" title="volatile使用场景"></a>volatile使用场景</h2><p><strong>当且仅当满足以下条件时，才应该使用volatile变量</strong>：</p>
<ul>
<li>对变量的写入操作不依赖变量的当前值，或者你能够确保当前只有单个线程更新变量的值。</li>
<li>该变量不会与其他状态一起纳入不变性条件中。</li>
<li>在访问变量时不需要加锁。</li>
</ul>
<h1 id="2-发布和逸出-封装"><a href="#2-发布和逸出-封装" class="headerlink" title="2. 发布和逸出(封装)"></a>2. 发布和逸出(封装)</h1><ul>
<li><p><strong>“发布”</strong>对象的意思指，使对象能够在当前作用域之外的代码中使用。</p>
<p>例如，将一个指向该对象的引用保存到其他代码可以访问的地方，</p>
<p>或者在某一个非私有的方法中返回该引用，或者将引用传递到其他类的方法中。</p>
<p><strong>我们要确保对象及其内部状态不被发布</strong></p>
</li>
<li><p><strong>“逸出”</strong>的意思指，当某个不应该发布的对象被发布时称为”逸出”。</p>
</li>
</ul>
<p>当发布的对象逸出以后，必须假设有某个类或线程可能会误用该对象。</p>
<p>因此应该尽量使用<strong>封装</strong>：封装能够使得对程序的正确性进行分析变可能，并使得无意中破坏设计约束条件变得更难。</p>
<p>另外一种发布对象或其内部状态机制就是发布一个<strong>内部类的实例</strong>。</p>
<p>另外一个要注意的地方：</p>
<blockquote>
<p>不要在构造过程中使this引用逸出</p>
</blockquote>
<h1 id="3-线程封闭-无状态、ThreadLocal"><a href="#3-线程封闭-无状态、ThreadLocal" class="headerlink" title="3. 线程封闭(无状态、ThreadLocal)"></a>3. 线程封闭(无状态、ThreadLocal)</h1><p>一种避免同步的方式就是不共享数据，不共享数据的无状态对象肯定是线程安全的。称为<strong>线程封闭</strong>。</p>
<p>常见的例子如：</p>
<ul>
<li><p>Swing通过将可视化组件和数据模型封装到Swing的事件分发线程中来实现线程安全。</p>
</li>
<li><p>还有如JDBC的Connection对象，线程从连接池中获得一个Connection对象，并且用该对象来处理请求，使用完后再讲对象返回给连接池。由于大多数(Servlet请求或EJB调用等)都是由单个线程采用同样的方式来处理，并且在Connection对象返回之前，连接池不会再将它分配给其他线程，因此这种连接管理模式在处理隐含地将Connection对象封闭在线程中。</p>
</li>
</ul>
<p>Java提供<strong>局部变量</strong>和<strong>ThreadLocal类</strong>来帮助维持线程封闭性。下面来讲下：</p>
<h2 id="Ad-hoc线程封闭"><a href="#Ad-hoc线程封闭" class="headerlink" title="Ad-hoc线程封闭"></a>Ad-hoc线程封闭</h2><p>Ad-hoc实际就是指，维护线程封闭性的职责完全交给程序来实现。Ad-hoc线程封闭是非常脆弱的，因为没有任何一种语言特性，例如可见修饰符或局部变量，能将对象封闭到目标线程上。事实上，对线程封闭对象的引用通常保存在公有变量上。</p>
<p>在volatile变量行上存在一种特殊的线程封闭。只要你能确保只有<strong>单个线程</strong>对共享的volatile变量执行写入操作，那么就可以安全地在这些共享的volatile变量上执行”读取-修改-写入”的操作。这种情况下，相当于将修改操作封闭在单个线程中以防止发生<strong>竞态条件</strong>，并且volatile变量的可见性还确保了其他线程能看到最新的值。</p>
<p>由于Ad-hoc线程封闭技术的脆弱性，因此在程序中尽量少用，在可能的情况下应该使用更强的线程封闭技术(例如下面要将讲的，栈封闭和ThreadLocal类)。</p>
<h2 id="栈封闭"><a href="#栈封闭" class="headerlink" title="栈封闭"></a>栈封闭</h2><p>栈封闭是线程封闭的一种特例，在栈封闭中，<strong>只能通过局部变量才能访问对象</strong>。栈封闭（也被称为线程内部使用或者线程局部使用，不要与核心类库中的ThreadLocal混淆）比Ad-hoc线程封闭更易于维护，也更加健壮。</p>
<h2 id="ThreadLocal类"><a href="#ThreadLocal类" class="headerlink" title="ThreadLocal类"></a>ThreadLocal类</h2><ul>
<li><p>线程封闭性的一种更规范方法是使用ThreadLocal，这个类能使线程中的某个值与保存值的对象关联起来。</p>
</li>
<li><p>ThreadLocal提供get与set等访问接口或方法，为每个使用该变量的线程都保存一份独立的副本，因此get总是返回当前执行线程在调用set时设置的最新值。</p>
</li>
<li><p>ThreadLocal对象通常用于防止对可变的单实例对象(Singleton)或全局变量进行共享。例如，通过将JDBC的连接保存到ThreadLocal对象中，每个线程就会拥有属于自己的连接。</p>
</li>
</ul>
<h1 id="4-不变性final"><a href="#4-不变性final" class="headerlink" title="4.不变性final"></a>4.不变性final</h1><p>上面讲了，解决同步问题的方法，主要有</p>
<ol>
<li>共享变量的volatile的声明，即禁用JVM对该变量的重排序立即对其他线程可见，</li>
<li>注意共享变量的发布、避免共享变量逸出。</li>
<li>通过线程封闭手段避免避免对象状态在多线程之间共享(通过局部变量的栈封闭、以及ThreadLocal的线程副本隔离)。</li>
</ol>
<p>下面来讲下，解决同步的另外一种手段，即 <strong>不变性</strong>。</p>
<p>满足同步需求的另一种方法是使用不可变对象。很多与原子性、可见性相关的问题，例如得到失效数据、丢失更新或者观察到某个对象处于不一致的状态等等，都与多线程试图同时访问同一个可变的状态相关。如果对象的状态不会改变，那么这些问题与复杂性也就自然消失了。</p>
<blockquote>
<p>不可变对象一定是线程安全的。</p>
</blockquote>
<p><strong>不可变性不等于将对象中所有的域都声明为final类型，即使对象中所有的域都是final类型的，这个对象也仍然是可变的，因为在final类型的域中可以保存对可变对象的引用。</strong></p>
<p>因此需要满足以下条件，对象才是不可变的：</p>
<blockquote>
<ul>
<li>对象创建以后其状态就不能修改。</li>
<li>对象的所有域都是final类型。</li>
<li>对象是正确创建的(在对象的创建期间，this引用没有逸出)。</li>
</ul>
</blockquote>
<h1 id="5-安全发布"><a href="#5-安全发布" class="headerlink" title="5.安全发布"></a>5.安全发布</h1><p>先看下面这个例子</p>
<pre><code class="java">public Holder holder;

public void initialize() {
        holder = new Holder(42);
}</code></pre>
<p>由于存在可见性问题，其他线程看到的Holder对象将处于不一致的状态，即便在该对象的构造函数中已经正确地构建了不变性条件。这种不正确的发布导致其他线程看到尚未创建完成的对象。这就是<strong>在没有足够同步的情况下发布对象</strong>，不要这样做。</p>
<h2 id="不可变对象与初始化安全性"><a href="#不可变对象与初始化安全性" class="headerlink" title="不可变对象与初始化安全性"></a>不可变对象与初始化安全性</h2><p>Java内存模型为不可变对象的共享提供了一种特殊的初始化安全性保证。</p>
<p>已经知道，即使某个对象的引用对于其他线程是可见的，也并不意味着对象状态对于使用该对象的线程来说一定是可见的。为了确保对象状态能呈现出一致的视图，就必须使用同步。</p>
<p>另一方面，即使在发布不可变对象的引用时没有使用同步，也仍然可以安全地访问该对象。为了维持这种初始化安全性保证，必须满足不可变性的所有需求：</p>
<p>状态不可修改，所有域都是final类型，以及正确的构造过程。</p>
<blockquote>
<p><strong>任何线程都可以在不需要额外同步的情况下安全地访问不可变对象，即使在发布这些对象时没有使用同步。</strong></p>
</blockquote>
<p>但是，如果final类型的域指向的是可变对象，那么在访问这些域所指向的对象的状态时仍然需要同步。</p>
<h2 id="安全发布的常用模式"><a href="#安全发布的常用模式" class="headerlink" title="安全发布的常用模式"></a>安全发布的常用模式</h2><p>如何确保使用对象的线程能够看到该对象处于已发布的状态。</p>
<blockquote>
<p>要安全地发布一个对象，对象的引用以及对象的状态必须同步对其他线程可见。一个正确构造的对象可以通过以下来安全地发布：</p>
<ul>
<li>在静态初始化函数中初始化一个对象引用。</li>
<li>将对象的引用保存到volatile类型的域或者AtomicReferance对象中。</li>
<li>将对象的引用保存到某个正确构造对象的final类型域中。</li>
<li>将对象的引用保存到一个由锁保护的域中。</li>
</ul>
</blockquote>
<ul>
<li><p>在线程安全容器内部的同步以为着，在将对象放到某个容器后，例如Vector或synchronizedList时，满足上面的”将对象的引用保存到一个由锁保护的域中”。即：</p>
<p>线程A将对象X放入一个线程安全的容器，随后线程B读取这个对象，那么可以确保B看到A设置的X状态，即便在这段读/写X的应用程序代码中没有包含显式的同步。线程安全类包括：</p>
<p>Hashtable、sychronizedMap或者ConcurrentHashMap</p>
<p>Vector、CopyOnWriteArrayList、CopyOnWriteArrySet、synchronizedList或synchronizedSet</p>
<p>BlockingQueue或ConcurrentLinkedQueue</p>
<p>还有其他数据传递机制Future和Exchanger同样能实现安全发布。</p>
</li>
<li><p>静态初始化器由JVM在类的初始化阶段执行。由于在JVM内部存在着同步机制，因此通过这种方式初始化任何对象都可以被安全地发布。</p>
</li>
</ul>
<h2 id="可变对象"><a href="#可变对象" class="headerlink" title="可变对象"></a>可变对象</h2><p>如果对象在构造后可以修改，那么安全发布只能确保”发布当时”状态的可见性。对于可变对象，不仅在发布对象时需要同步，而且在每次对象访问时同样需要同步来确保后续操作的可见性。要安全地共享可变对象，这些对象就必须被安全地发布，并且必须是线程安全的或者由某个锁保护起来。</p>
<blockquote>
<p>对象的发布需求取决于它的可变性：</p>
<ul>
<li>不可变对象可以通过任意机制来发布</li>
<li>事实不可变对象必须通过安全方式来发布</li>
<li>可变对象必须通过安全方式来发布，并且必须是线程安全的或者由某个锁保护起来</li>
</ul>
</blockquote>
<h2 id="安全地共享对象"><a href="#安全地共享对象" class="headerlink" title="安全地共享对象"></a>安全地共享对象</h2><p>当获得对象的一个引用时，你需要知道这个引用上可以执行哪些操作。在使用它之前是否需要获得一个锁？是否可以修改它的状态或者只能读取它？许多并发错误都是由于没有理解共享对象的这些”既定规则”而导致的。当发布一个对象时，必须明确地说明对象的访问方式。</p>
<blockquote>
<p>在并发程序中使用和共享对象，可以使用一些实用的策略，包括：</p>
<p><strong>线程封闭</strong>。线程封闭的对象只能由一个线程拥有，对象被封闭在该线程中，并且只能由这个线程修改。</p>
<p><strong>只读共享</strong>。在没有额外同步的情况下，共享的只读对象可以由多个线程并发访问，但任何线程都不能修改它。共享的只读对象包括不可变对象和事实不可变对象。</p>
<p><strong>线程安全共享</strong>。线层安全的对象在其内部实现同步，因此多个线程可以通过对象的公有接口来进行访问而不需要进一步的同步。</p>
<p><strong>保护对象</strong>。被保护的对象只能通过持有特定的锁来访问。保护对象包括封装在其他线程安全对象中的对象，以及已发布的并且由某个特定锁保护的对象。</p>
</blockquote>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>【基本概念篇】十、管程——并发编程的万能钥匙</title>
    <url>/2019/05/10/2019-5-10-java-concurreny-java-monitor/</url>
    <content><![CDATA[<h1 id="什么是管程"><a href="#什么是管程" class="headerlink" title="什么是管程"></a>什么是管程</h1><p>在上一篇《从操作系统角度看并发》的最后 引入了管程，下面从Java角度看下管程。</p>
<p>在Java 1.5之前仅仅提供synchronized关键字及wait()、notify()、notifyAll()这三个方法。在刚接触Java的时候，可能会认为Java会提供信号量这种编程原语，因为操作系统原理课程告诉我们，用信号量可以解决所有并发问题，实际上不是的。Java采用的是管程技术，synchronized关键字及wait()、notify()、notifyAll()这三个方法都是管程的组成部分。</p>
<p>而<strong>管程和信号量是等价，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程</strong>。但管程更容易使用，所以Java选择了管程。</p>
<p>管程，对应的英文是Monitor，我们都喜欢将其翻译成”监视器”，这是直译。</p>
<p>操作系统领域一般都翻译成”管程”，这个意译。</p>
<p>所谓<strong>管程，指的是管理共享变量以及对共享变量的操作过程，让他们支持并发</strong>。翻译为Java领域的语言，就是管理类的成员变量和成员方法，让这个类是线程安全的。那管程是怎么管的呢？</p>
<h2 id="MESA模型"><a href="#MESA模型" class="headerlink" title="MESA模型"></a>MESA模型</h2><p>在管程发展史上，先后出现三种不同的管程模型：Hasen模型、Hoare模型和MESA模型。其中，现在广泛应用的是MESA模型，并且Java管程的实现参考也是MESA模型。所以，下面重点讲下MESA模型。</p>
<p>在并发编程领域，有两大核心问题：</p>
<p><strong>互斥</strong>，即同一时刻只允许一个线程访问共享资源；</p>
<p><strong>同步</strong>，即线程之间如何通信、协作。这两大问题，管程都能解决。</p>
<h2 id="管程如何解决互斥问题"><a href="#管程如何解决互斥问题" class="headerlink" title="管程如何解决互斥问题"></a>管程如何解决互斥问题</h2><p>解决互斥问题的思路很简单，就是将共享变量及其对共享变量的操作统一封装起来。在下图中，管程X将共享变量queue这个队列和先关操作入队enq()、出队dep()都封装起来了；</p>
<p>线程A和线程B如果想访问共享变量queue，只能通过调用管程提供的enq()、dep()方法来实现；enq()、de()保证互斥性，只允许一个线程进入管程。前面讲的互斥锁用法，其背后的模型就是它。</p>
<p><img data-src="/img/in-post/image-20190517010818816.png" alt=""></p>
<h1 id="管程如何解决同步问题"><a href="#管程如何解决同步问题" class="headerlink" title="管程如何解决同步问题"></a>管程如何解决同步问题</h1><p><img data-src="/img/in-post/image-20190517011130582.png" alt=""></p>
<p>如图，为MESA管程模型示意图。在管程模型里，共享变量和对共享变量的操作是被分装起来的，图中最外层的框就代表封装的意思。框的上面只有一个入口，并且在入口旁边还有一个入口等待队列。当多个线程同时试图进入管程内部时，只允许一个线程进入，其他选择则在入口等待队列中等待。这个过程类似医院就诊流程的分诊，只允许一个患者就诊，其他患者在门口等待。</p>
<p>管程中还引入了条件变量的概念，而且<strong>每个条件变量都对应有一个等待队列</strong>，如下图，条件变量A和条件变量B分别都有自己的等待队列。</p>
<p>条件变量和等待队列的作用是什么？实则就是解决线程同步问题的。也可以结合上面提到的入队出队加深理解：</p>
<ul>
<li><p>假设有个线程T1执行出队操作，不过需要注意的是执行出队操作，有个前提条件，就是队列不能是空的，而队列不空这个前提条件就是管程里的条件变量。如果线程T1进入管程恰好发现队列是空的，此时线程T1就去”队列不空”这个条件变量的等待队列中等待。</p>
</li>
<li><p>再假设之后另一个线程T2执行入队操作，入队操作执行成功之后，”队列不空”这个条件对于线程T1来说已经满足了，此时线程T2要通知T1，告诉它需要的条件已经满足。当线程他得到通知后，会从等待队列里面出来，但是出来之后不是马上执行，而是重新进入到入口等待队列里面。这个过程类似你验血完，回来找大夫，需要重新分诊。</p>
</li>
</ul>
<p>条件队列及其等待队列讲清楚了，下面再说说wait()、notify()、notifyAll()这三个操作。</p>
<h1 id="wait-、notify-、notifyAll-要等到直到队列不空，所以就用了notEmpty-await-；"><a href="#wait-、notify-、notifyAll-要等到直到队列不空，所以就用了notEmpty-await-；" class="headerlink" title="wait()、notify()、notifyAll()要等到直到队列不空，所以就用了notEmpty.await()；"></a>wait()、notify()、notifyAll()要等到直到队列不空，所以就用了notEmpty.await()；</h1><p>前面提到线程他发现”队列不空”这个条件不满足，需要进到对应的等待队列里等待。这个过程通过调用wait()来实现。如果我们用对象A代表”队列不空”这个条件，那么线程T1需要调用A.wait。</p>
<p>同理当”队列不空”这个条件满足时，线程T2需要调用A.notify来通知A等待队列中的一个线程，此时这个队列里面只有线程T1。至于notfiyAll()这个方法，它可以通知等待队列中的所有线程。</p>
<p>以代码来示例：</p>
<p>下面的代码实现一个阻塞队列，阻塞队列有两个操作分别是入队和出队，这两个方法都是先获取互斥锁，类比管程模型中的入口。</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
        <tag>管程</tag>
      </tags>
  </entry>
  <entry>
    <title>【基本概念篇】九、从操作系统角度看并发</title>
    <url>/2019/05/09/2019-5-09-java-concurreny-system-courrenency/</url>
    <content><![CDATA[<p>本文，先来看下操作系统级别的并发进程知识，以此引入下文中Java并发的管程以及信号量的知识。</p>
<p>在并发进程与并发线程一样如果不控制共享资源都会产生错误，这点暂不赘述。</p>
<p>先来看下进程之间的关系是怎么样的？</p>
<h1 id="进程间的关系"><a href="#进程间的关系" class="headerlink" title="进程间的关系"></a>进程间的关系</h1><ol>
<li><p>直接式与间接式制约</p>
<p>直接式制约：一程序段等待另一程序段的执行结果</p>
<p>间接式制约：并发程序段竞争同一资源</p>
</li>
<li><p>相交进程与无关进程：这个不用展开讲了，主要是逻辑上有无联系的区分。</p>
</li>
<li><p><strong>进程的同步与互斥：</strong></p>
<ul>
<li>进程同步（直接作用）：根据一定的时序关系合作完成一项任务<ul>
<li>并发进程因直接制约而互相等待，彼此相互发送消息进行合作，是的各进程按一定的速度执行</li>
<li>进程间的互相联系是有意识安排的，直接作用只发生相交进程间</li>
</ul>
</li>
</ul>
<p><img data-src="/img/in-post/1557480839440.png" alt=""></p>
<ul>
<li><p>进程互斥（间接作用）：各进程竞争使用临界资源</p>
<ul>
<li><p>临界资源：一次只允许一个进程使用的资源</p>
</li>
<li><p>进程互斥是进程同步的一种特殊情况</p>
</li>
<li><p>进程间要通过某种中介发生联系，是无意识安排的，可以发生在相交进程之间，也可发生在无关进程之间。</p>
<p><img data-src="/img/in-post/1557480647158.png" alt=""></p>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h1 id="临界区管理"><a href="#临界区管理" class="headerlink" title="临界区管理"></a>临界区管理</h1><p>进程间的互斥主要是对临界区的互斥访问，因此关于临界区如何管理是整个进程并发互斥的关键课题。</p>
<p>因此下面来简单了解下临界区的管理话题。</p>
<h2 id="临界区和其使用规则"><a href="#临界区和其使用规则" class="headerlink" title="临界区和其使用规则"></a>临界区和其使用规则</h2><ul>
<li>临界区：进程中涉及临近资源的程序段为临界区/互斥区，多个进程的临界区为相关临界区</li>
<li>临界区的使用原则：有空让进、无空等待、多中择一、有限等待、让权等待</li>
<li>解决进程互斥的两种做法：<ul>
<li>由竞争各方平等协商解决，包括硬件、软件两类方法。</li>
<li>引入进程管理者来协调竞争各方对互斥资源的使用。</li>
</ul>
</li>
</ul>
<h2 id="临界区管理的软件方法"><a href="#临界区管理的软件方法" class="headerlink" title="临界区管理的软件方法"></a>临界区管理的软件方法</h2><ol>
<li><p>两个失败的尝试（1）</p>
<p><img data-src="/img/in-post/1557481280511.png" alt=""></p>
</li>
<li><p>两个失败的尝试（2）</p>
<p><img data-src="/img/in-post/1557483560956.png" alt=""></p>
</li>
</ol>
<ol start="3">
<li><p>成功解决方法（Dekker算法）</p>
<p><img data-src="/img/in-post/1557483597707.png" alt=""></p>
</li>
</ol>
<p>实现临界区管理当然还有硬件方法比如测试并建立指令TS、交换指令SWAP、开关中断指令。</p>
<ul>
<li>软件解法的缺点主要在于：<ol>
<li>忙等待</li>
<li>实现过于复杂，需要高的变成技巧</li>
</ol>
</li>
<li>硬件方法解决临界区管理较为简单有效，其缺点主要在于：<ul>
<li>会导致“忙等待”</li>
<li>会导致“饥饿”</li>
<li>中断屏蔽方法代价较高，不适应多处理器</li>
</ul>
</li>
</ul>
<h1 id="信号量与P、V操作"><a href="#信号量与P、V操作" class="headerlink" title="信号量与P、V操作"></a>信号量与P、V操作</h1><h2 id="信号量定义（数据结构）"><a href="#信号量定义（数据结构）" class="headerlink" title="信号量定义（数据结构）"></a>信号量定义（数据结构）</h2><ul>
<li><p>信号量的提出</p>
<ul>
<li>上面介绍的临界区管理的方法存在问题，因为他们是平等进程间的一种协商机制，需要一个地位高于进程的管理者来解决公有资源的使用问题。</li>
<li>操作系统可从进程管理者的角度来处理互斥的问题，<strong>信号量</strong>就是操作系统提供的管理公有资源的有效手段。</li>
<li>1965年荷兰学者Dijkstra提出信号量(semaphore)与P、V操作机制，这一机制是系统用于管理公有资源的有效手段</li>
</ul>
</li>
<li><p>信号量是一个数据结构，负责协调各个进程，以保证他们能够正确、合理的使用公共资源。</p>
</li>
<li><p>信号量的定义：</p>
<pre><code class="c++">Struct semaphore 
  {   int value;            //信号量的值
      pointer_PCB queue;    //信号量队列指针
   } 
</code></pre>
<p>信号量说明：<strong>semaphore s</strong> </p>
</li>
</ul>
<p><img data-src="/img/in-post/1558404234145.png" alt=""></p>
<ul>
<li>信号量的特性<ul>
<li>信号量代表对某种公共资源的管理（如车开出停车场）时，此时若信号量队列有等待进程则释放一个（如让一辆车进入停车场）。</li>
<li>要使用资源的进程（如要进入停车场的车）需通过信号量，有资源时顺利通过（有车位时，看门人大开车栏）；若没有资源可用（如空车位为0），则所有进程都将进入对饮信号量的等待队列（如车子在看门人看守的车栏外排队等待）。</li>
<li>当一个进程归还资源（如车开出停车场）时，此时若信号量队列有等待进程释放一个（如让一辆车进入停车场）。</li>
</ul>
</li>
</ul>
<h2 id="P、V操作定义（操作）"><a href="#P、V操作定义（操作）" class="headerlink" title="P、V操作定义（操作）"></a>P、V操作定义（操作）</h2><ol>
<li><p>什么是P、V操？</p>
<p>P、V操作是能对<strong>信号量进行处理的唯一两个操作</strong>，是不可分割的一段程序，为<strong>原语操作</strong>（执行过程中不可以被中断），可以理解<strong>信号量</strong>是信号量机制提供的<strong>数据结构</strong>、而P、V操作是信号量机制提供的<strong>操作</strong>。</p>
</li>
<li><p><strong>P操作用于申请</strong>信号量管理的资源（如停车场一例中需要进入停车场使用车位的车应该执行P操作）。</p>
<p>P操作：</p>
<pre><code class="c++">P(s)
{
  s.value = s.value－－ ;        //s.value减1
  if (s.value &lt; 0)    
    //该进程被阻塞，进入相应队列，然后转进程调度 
   {
     该进程状态置为等待状态;
     将该进程的PCB插入相应的等待队列s.queue的末尾;
   }    
   //若s.value减1后仍大于或等于零，则进程继续执行         
} </code></pre>
<p><img data-src="/img/in-post/1558405062067.png" alt=""></p>
</li>
</ol>
<ol start="3">
<li><p><strong>V操作用于释放</strong>用于释放资源（如停车场一例中需要开出停车场归还车位的车就应该执行V操作）。</p>
<p>V操作：</p>
<pre><code class="C++">V(s)
{
  s.value = s.value ++;     //s.value加1
  if (s.value &lt; = 0)
   //从队列中唤醒一等待进程，然后继续执行或转进程调度 
   {
    唤醒相应等待队列s.queue中等待的一个进程;
    改变其状态为就绪态，并将其插入就绪队列;
     } 
  //若相加结果大于零，则进程继续执行 
}</code></pre>
<p><img data-src="/img/in-post/1558405115200.png" alt=""></p>
</li>
</ol>
<h2 id="信号量的使用"><a href="#信号量的使用" class="headerlink" title="信号量的使用"></a>信号量的使用</h2><ul>
<li><p>使用注意事项：<strong>必须置一次且只能置一次初值，且初值不能为负数</strong>；只能执行P、V操作</p>
</li>
<li><p>用信号量P、V操作解决<strong>进程间互斥问题</strong></p>
<pre><code class="c++">mutex : semaphore; mutex:= 1;
cobegin 
 process Pi
           begin
               …
               P(mutex);               临界区；               V(mutex);
               …
           end; 
coend; </code></pre>
<ul>
<li><p>用信号量及P、V操作解决单类机票问题</p>
<pre><code class="c++">var A : ARRAY[1..m] OF integer;
mutex : semaphore;  mutex:= 1;
cobegin 
process Pi
     var Xi:integer;
begin
     L1:
      按旅客要求找到A[j];
      P(mutex)
      Xi := A[j];
Coend</code></pre>
<pre><code class="c++">f  Xi&gt;=1 
   then begin Xi:=Xi-1; A[j]:=Xi; 
       V(mutex);输出一张票;  end;
    else  begin 
       V(mutex);输出票已售完; end;
     goto L1;
 end; 
</code></pre>
</li>
</ul>
</li>
<li><p>用信号量及P、V操作<strong>解决进程间同步问题</strong></p>
<ul>
<li><p>生产者——消费者问题</p>
<p>问题描述：生产者往缓冲区中放产品，消费者从缓冲区中取产品，如下图所示</p>
<p><img data-src="/img/in-post/1558405630788.png" alt=""></p>
<p>生产者P进程不能往“满”的缓冲区中放产品，设置<strong>信号量为S1，初值为1，代表缓冲区有1个空闲空间</strong></p>
<p>消费者Q进程不能从“空”的缓冲区中取产品，设置<strong>信号量S2 ，初值为0，代表缓冲区有0个产品</strong></p>
<pre><code class="c++">P        //生产者进程
while  (true)  {
      生产一个产品;
      P(s1) ;    //初值为1
      送产品到缓冲区;
      V(s2);
}; </code></pre>
<pre><code class="c++">C    //消费者进程
while  (true)  {
     P(s2);    //初值为0
           从缓冲区取产品;
    V(s1);
             消费产品;
}; 
</code></pre>
</li>
</ul>
</li>
</ul>
<h2 id="信号量及P、V操作讨论"><a href="#信号量及P、V操作讨论" class="headerlink" title="信号量及P、V操作讨论"></a>信号量及P、V操作讨论</h2><ol>
<li><p>信号量及P、V操作的物理含义</p>
<ul>
<li>S&gt;0，表示<strong>有S个资源</strong>可用</li>
<li>S=0表示<strong>无资源</strong>可用</li>
<li>S&lt;0则<strong>|S|表示S等待队列中的进程个数</strong></li>
<li>P（S）表示申请一个资源</li>
<li>V（S）表示释放一个资源</li>
</ul>
</li>
<li><p><strong>P、V操作必须成对出现</strong>，有一个P操作就一定有一个V操作</p>
<ul>
<li>当为<strong>互斥操作时，它们处于同一进程</strong></li>
<li>当为<strong>同步操作时，则不再同一进程中出现</strong></li>
<li>如果P(S1)和P(S2)两个操作在一起，那么P操作的顺序至关重要，一个同步P操作与一个互斥P操作在一起时，<strong>同步P操作在互斥P操作前</strong>，而两个V操作无关紧要</li>
</ul>
</li>
</ol>
<ol start="3">
<li><p>信号量及P、V的优缺点</p>
<p>优点：<strong>简单且表达能力强</strong>，用P、V操作可解决任何同步、互斥问题</p>
<p>缺点：不够安全，P、V操作使用不当会出现死锁；遇到复杂同步互斥问题时实现复杂</p>
</li>
</ol>
<p>信号量与P、V操作解决经典问题如：哲学家吃通信面问题、生产者消费者问题、苹果橘子问题、读者和写者问题、理发师问题</p>
<h1 id="进程间通信"><a href="#进程间通信" class="headerlink" title="进程间通信"></a>进程间通信</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><ul>
<li><p>进程间通信：进程之间互相交互信息的工作。</p>
</li>
<li><p>根据通信内容划分：</p>
<ul>
<li>控制信息的传送：如信号量机制及P、V操作（低级通信原语）控制的进程同步和互斥</li>
<li>大批量数据传送：Send/Receive原语（高级通信原语）</li>
</ul>
</li>
</ul>
<h2 id="进程间通信方式"><a href="#进程间通信方式" class="headerlink" title="进程间通信方式"></a>进程间通信方式</h2><ul>
<li><p>主从式通信：主进程-从进程</p>
</li>
<li><p>会话式通信：使用进程-服务进程</p>
</li>
<li><p><strong>消息队列或邮箱</strong>：发送进程-接收进程</p>
</li>
<li><p><strong>共享存储区</strong>：读进程-写进程</p>
</li>
</ul>
<h3 id="Linux中的进程间通信机制"><a href="#Linux中的进程间通信机制" class="headerlink" title="Linux中的进程间通信机制"></a>Linux中的进程间通信机制</h3><ol>
<li><p>信号通信机制</p>
<ul>
<li>每个信号都对应一个正整数（signal number），代表同一用户的诸进程之间传送事先约定的信息的类型，用于通知某进程发生了某异常事件。</li>
<li>每个进程在运行时，都要通过信号机制来检查是否有信号到达。若有，便中断正在执行的程序，转向与该信号相对应的处理程序；处理结束后再返回到原来的断点继续执行</li>
<li>信号机制是对中断机制的一种模拟又称为软中断。</li>
<li>信号跟中断主要的相似点：<ol>
<li>都是异步的通信方式。</li>
<li>检测出有信号活中断请求时，都暂停正在执行的程序转而去执行响应的处理程序。</li>
<li>处理完毕后返回到原来的断点。</li>
<li>对信号或中断都可以屏蔽。</li>
</ol>
</li>
<li>信号与中断的区别主要包括：<ol>
<li>信号没有优先级，所有信号平等；而中断有优先级。</li>
<li>信号处理程序在<strong>用户态</strong>下运行；而中断处理程序是在核心态下运行；</li>
<li>信号响应通常有较大延迟；而中断响应是及时的。</li>
</ol>
</li>
</ul>
</li>
</ol>
<ol start="2">
<li><p>共享存储区机制</p>
<ul>
<li><p>通信速度最高的一种通信机制（Java就使用类似机制进行线程间通信）</p>
</li>
<li><p>共享存储区为内存中的某一个区域，映射在若干需通过该区域通信的进程的虚地址空间中。</p>
</li>
<li><p>一个进程的虚地址空间可以连接多个共享存储区。</p>
<p><img data-src="/img/in-post/1557804687065.png" alt=""></p>
</li>
<li><p>现在内存中建立一共享存储区，然后将它符街道自己的虚地址空间上。此后，进程对该区的访问操作，与对其虚地址空间的其他部分操作完全相同，通过对共享存储区的读、写来进行直接通信。</p>
</li>
<li><p><strong>共享通信机制并未提供对该区进行互斥访问及进程同步的措施。因而当用户需要使用该机制时，必须自己设置同步和互斥措施才能保证实现正确的通信。</strong></p>
</li>
</ul>
</li>
</ol>
<ol start="3">
<li><p>消息通信机制</p>
<ul>
<li><p>消息时一个格式化的可变长的信息单元</p>
</li>
<li><p>消息通信机制允许由一个进程给其他任意的进程发送一个消息</p>
</li>
<li><p>当一个进程收到多个消息时，可将它们排成一个消息队列</p>
</li>
<li><p>每个消息队列都有一个成为关键字（key）的名字，即<strong>消息队列描述符</strong>，由用户指定，其作用与用户文件描述符一样，是为了方便用户和系统对消息队列的访问。</p>
<p><img data-src="/img/in-post/1557805094747.png" alt=""></p>
<p><strong>共享存储区和消息通信机制对比</strong>：</p>
<ul>
<li>建立：<strong>消息队列的建立消耗资源更少</strong>，只是软件上的设定问题；而共享区需要对硬件操作，实现内存的映像，控制起来更复杂。如果每次都重新进行队列或共享的建立，共享区的设立没什么优势</li>
<li>使用：共享区的数据传输收到硬件的支持，不耗费多余的资源。而消息传递由软件进行控制和实现，需要消耗一定的CPU的资源。从这个意义上讲，共享区更适合频繁和大量数据传输。</li>
<li>同步：消息的传递自身就带有同步控制。而共享队列如果不借助其他机制进行同步，接收数据的一方必须进行不断地查询，浪费CPU资源。课件消息方式使用更灵活。</li>
</ul>
</li>
</ul>
</li>
<li><p>管道通信机制</p>
<ul>
<li><p>管道：能够连接一个写进程和一个读进程、并允许它们以生产者——消费者进行通信的一个共享文件，又成为pipe文件。</p>
</li>
<li><p>由写进程从管道的写入端（句柄1）将数据写入管道，而读进程则从管道的读出端（句柄0）读出数据。</p>
</li>
<li><p>通信管道的互斥问题：主要通过检查索引文件是否被上锁，上锁则进程休眠等待。</p>
<p><img data-src="/img/in-post/1557828358133.png" alt=""></p>
<p>​    </p>
<p><img data-src="/img/in-post/1557828401466.png" alt=""></p>
</li>
</ul>
</li>
</ol>
<h1 id="管程"><a href="#管程" class="headerlink" title="管程"></a>管程</h1><ul>
<li>信号量的大量同步操作分散在各个进程中不便于管理和控制，读写和维护都很困难，还有可能导致系统死锁。</li>
<li>Dijkstra于1971年提出把所有进程<strong>对某一种临界资源的同步操作都集中起来</strong>，构成一个所谓的秘书进程（即管程）。</li>
<li>凡要访问该临界资源的进程，都需先报告秘书，由秘书来实现诸进程对同一临界区资源的互斥使用。</li>
</ul>
<h2 id="管程的基本概念"><a href="#管程的基本概念" class="headerlink" title="管程的基本概念"></a>管程的基本概念</h2><h3 id="管程的提出"><a href="#管程的提出" class="headerlink" title="管程的提出"></a>管程的提出</h3><p>一个<strong>管程</strong>定义了一个数据结构和能为并发进程所执行（在该数据结构上）的一组操作，这组操作能同步进程和改变管程中的数据——Hanson</p>
<h3 id="管程的概念"><a href="#管程的概念" class="headerlink" title="管程的概念"></a>管程的概念</h3><p>管程用共享数据结构抽象地表示系统中的共享资源，而把对该共享数据结构实施的操作定义为一组过程，集中在一个模块中。操作系统或并发程序就由这样的模块构成，模块之间联系清晰，便于维护和修改，易于保证正确性。</p>
<h3 id="管程的类型定义"><a href="#管程的类型定义" class="headerlink" title="管程的类型定义"></a>管程的类型定义</h3><pre><code class="c++">monitor_name = MONITOR; 
共享变量说明;  
        //其中以若干条件变量对应需管理的各类资源
define 本管程内部定义、外部可调用的函数名表; 
use 本管程外部定义、内部可调用的函数名表; 
内部定义的函数说明和函数体 
{ 
  共享变量初始化语句; 
} </code></pre>
<h2 id="管程的特性"><a href="#管程的特性" class="headerlink" title="管程的特性"></a>管程的特性</h2><h3 id="管程的特性-1"><a href="#管程的特性-1" class="headerlink" title="管程的特性"></a>管程的特性</h3><ul>
<li>模块化：管程是一个基本程序单位，可以单独编译</li>
<li>抽象数据类型：管程中不仅有数据，而且有对数据的操作</li>
<li>信息屏蔽：管程外可以调用管程内部定义的一些函数，但函数的具体实现对外不可见</li>
</ul>
<h3 id="管程的使用"><a href="#管程的使用" class="headerlink" title="管程的使用"></a>管程的使用</h3><ul>
<li>管程相当于围墙，将共享变量和对它进行操作的若干个过程围了起来</li>
<li>任何进程要访问临界资源时，都必须进入管程通过调用其内的某个函数进行申请</li>
<li>任何进程要归还资源时，也必须进入管程通过调用其内的某个函数进行归还</li>
<li>进程必须互斥访问管程，即同一时刻只能由一个进程在调用管程内的某个函数</li>
</ul>
<h3 id="管程运行示意图"><a href="#管程运行示意图" class="headerlink" title="管程运行示意图"></a>管程运行示意图</h3><p><img data-src="/img/in-post/1557891985426.png" alt=""></p>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>操作系统</tag>
        <tag>管程</tag>
      </tags>
  </entry>
  <entry>
    <title>【基本概念篇】七、死锁</title>
    <url>/2019/04/21/2019-4-21-java-concurreny-deadlock/</url>
    <content><![CDATA[<h1 id="死锁问题"><a href="#死锁问题" class="headerlink" title="死锁问题"></a>死锁问题</h1><p><strong>当一个线程永远地持有一个锁，并且其他线程都尝试获得这个锁时，那么它们将永远地被阻塞。</strong></p>
<p>在数据库事务中存在死锁会采取检测等机制释放一个资源从而避免死锁，让其他事务继续进行；而在JVM中，解决死锁问题方便并没有数据服务那么强大，当一组Java线程发生死锁时，这些线程将永远不能使用。这可能导致子程序或者整个应用程序完全停止，恢复应用程序的唯一方式就是重启。</p>
<h1 id="死锁发生的场景"><a href="#死锁发生的场景" class="headerlink" title="死锁发生的场景"></a>死锁发生的场景</h1><h2 id="顺序死锁"><a href="#顺序死锁" class="headerlink" title="顺序死锁"></a>顺序死锁</h2><pre><code class="java">public class LeaftRightLock {
    private final Object leftLock = new Object();
    private final Object rightLock = new Object();

    public void leftRight() {
        synchronized(leftLock) {
            synchronized(rightLock) {
                //doSomething
            }
        }
    }

    public void rightLeft() {
        synchronized(rightLock) {
            synchronized(rightLock) {
                //doSomething
            }
        }
    }
}</code></pre>
<p><img data-src="/img/in-post/image-20190429231508637.png" alt=""></p>
<ul>
<li><p>死锁场景：两个线程试图以不同顺序来获得相同的锁。</p>
</li>
<li><p>死锁避免：如果按照相同的顺序来请求锁，那么就不会出现循环的加锁依赖性，因此也就不会出现死锁。要想验证锁的顺序一致性，需要对程序中的加锁行为进行全局分析。</p>
</li>
</ul>
<h2 id="动态的锁顺序死锁"><a href="#动态的锁顺序死锁" class="headerlink" title="动态的锁顺序死锁"></a>动态的锁顺序死锁</h2><p>有时候，不能清楚知道是否在锁顺序上有足够的控制权来避免死锁的发生。如下程序看似没什么问题，将资金从一个账户转入另外一个账户，在转账之前要获得者两个Account对象的锁，以确保通过原子方式来更新两个账户中的余额。</p>
<p><img data-src="/img/in-post/image-20190504230927674.png" alt=""></p>
<ul>
<li><p>死锁场景：</p>
<p><img data-src="/img/in-post/image-20190504231105232.png" alt=""></p>
</li>
<li><p>死锁避免：不要在不定的参数中获取锁。通过定义锁获取顺序，并在整个应用中都按照整个顺序来获取锁。</p>
</li>
</ul>
<h2 id="在协作对象之间发生的死锁"><a href="#在协作对象之间发生的死锁" class="headerlink" title="在协作对象之间发生的死锁"></a>在协作对象之间发生的死锁</h2><p>有些操作获取多个锁不一定是在同一个方法或者同一个类中获取，比如有一些协同的类，如下：</p>
<p><img data-src="/img/in-post/image-20190504231654991.png" alt=""></p>
<p><img data-src="/img/in-post/image-20190504231712322.png" alt=""></p>
<p> Taxi类的setLocation方法会调用Dispatcher的notifyAvailable(this)。</p>
<p>而Dispatcher的getImage方法会调用Taxit的getLocation方法。</p>
<ul>
<li>死锁场景：如果这两个对象在互相交互时出现同调用对方的方法并且已经持有当前类的锁即等待对方的锁，就会出现死锁。</li>
<li>死锁避免：如果在持有锁的方法中又要调用其他类的方法，那么就要谨慎了，需要看看其他类是否直接或间接的调用当前类的方法。</li>
</ul>
<p>如果在持有锁时调用某个外部方法，那么将出现活跃性问题。在这个外部方法中可能会获取其他锁(可能产生死锁)，如果阻塞时间过长，导致其他线程无法及时获得当前被持有的锁。</p>
<h2 id="资源死锁"><a href="#资源死锁" class="headerlink" title="资源死锁"></a>资源死锁</h2><p>当线程在相同的资源集合上等待时，也会发生死锁。</p>
<ul>
<li>例子1：两个不同数据库的连接池。采用信号量来实现资源池为空的阻塞行为。如果一个任务需要连接两个数据库，并且在请求这两个资源时不会始终遵循相同的顺序，那么线程A可能持有数据库D1的连接，并等待数据库D2的连接，而线程B则持有D2的连接并等待与D1的连接。(资源池越大，出现这种情况的可能性越小)。</li>
<li>例子2：另一种资源死锁的形式是线程<strong>饥饿死锁</strong>，例如：一个任务提交另一个任务，并且等待提交任务在单线程的Executor中执行完成。这种情况，第一个任务永远等待下去，并使得另一个任务以及在这个Executor中执行的所有其他任务都停止执行。因此，<strong>有界线程池/资源池与相互依赖的任务不能一块使用。</strong></li>
</ul>
<h1 id="其他活跃性危险"><a href="#其他活跃性危险" class="headerlink" title="其他活跃性危险"></a>其他活跃性危险</h1><p>死锁是常见的活跃性危险，但在并发程序中还存在一些其他活跃性危险，包括：饥饿、丢失信号和或活锁。</p>
<h2 id="饥饿"><a href="#饥饿" class="headerlink" title="饥饿"></a>饥饿</h2><p>当线程由于无法访问它所需要的资源而不能继续执行时，就发生了<strong>饥饿</strong>。</p>
<p>引起饥饿的最常见资源就是CPU时钟周期。例如：如果在Java应用程序中对于线程的优先级使用不当，或者在持有锁时执行一些无法结束的结构(例如无限循环、或者无限制地等待某个资源)，那么将导致<strong>饥饿</strong>，因为其他需要这个锁的线程将无法得到它。这将导致本应该获得CPU时间片的线程一直得不到时间片执行。</p>
<h2 id="活锁"><a href="#活锁" class="headerlink" title="活锁"></a>活锁</h2><p>是另外一种形式的<strong>活跃性问题</strong>，尽管不会阻塞线程，但也不能继续执行（因为线程将不断执行相同的操作，而且总会失败）。</p>
<ul>
<li>这样情况一般会出现在类似事务等消息处理任务中：</li>
</ul>
<p>如果不能成功处理某个消息，那么消息处理机制将回滚整个事务，并将它重新放到队列的开头。当正好在处理这一错误类型的事务，由于这条消息又被反复放到队列开头，因此该错误恢复会被反复执行，并返回相同的结果。虽然处理消息的线程并没有阻塞，但也无法继续执行下去。这种形式的活锁通常是由过度的错误恢复代码造成的，因为它错误地将不可恢复的错误作为可修复的错误。</p>
<ul>
<li>可以总结，当多个互相协作的线程都对彼此进行响应从而修复各自的状态，并使得任何一个线程都无法继续执行时，就发生了<strong>活锁</strong>。就好像两个人过马路，两个人同时选择让出对方的芦，这样他们就会反复避让下去。</li>
</ul>
<h1 id="死锁预防"><a href="#死锁预防" class="headerlink" title="死锁预防"></a>死锁预防</h1><h2 id="案例分析-转账与存款问题"><a href="#案例分析-转账与存款问题" class="headerlink" title="案例分析(转账与存款问题)"></a>案例分析(转账与存款问题)</h2><p>细粒度锁分别保护账户与目标账户</p>
<p><img data-src="/img/in-post/image-20190506233557203.png" alt=""></p>
<p>问题代码如下：</p>
<pre><code class="java">class Account {
  private int balance;
  // 转账
  void transfer(Account target, int amt){
    // 锁定转出账户
    synchronized(this) {              
      // 锁定转入账户
      synchronized(target) {           
        if (this.balance &gt; amt) {
          this.balance -= amt;
          target.balance += amt;
        }
      }
    }
  } 
}</code></pre>
<p>发生死锁：</p>
<p><img data-src="/img/in-post/image-20190506233658857.png" alt=""></p>
<p><img data-src="/img/in-post/image-20190506233741175.png" alt=""></p>
<h2 id="死锁发生的四个条件"><a href="#死锁发生的四个条件" class="headerlink" title="死锁发生的四个条件"></a>死锁发生的四个条件</h2><ol>
<li><p><strong>互斥</strong>：共享资源X和Y只能被一个线程占用；</p>
</li>
<li><p><strong>占有且等待</strong>：线程T1已经取得共享资源X，在等待共享资源Y的时候，不释放共享资源X；</p>
</li>
<li><p><strong>不可抢占</strong>：其他线程不能强行抢占T1占有的资源；</p>
</li>
<li><p><strong>循环等待</strong>：线程T1等待线程T2占有的资源，线程T2等待线程T1占有的资源，就是循环等待；</p>
</li>
</ol>
<p>也就是说<strong>我们只要破坏其中一个一个条件，就可以成功避免死锁的发生。</strong>对于互斥这个条件没办法破坏，因为锁本身就是互斥。其他三个条件都是有办法破坏的。</p>
<ol>
<li>对于“占用切等待“这个条件，可以一次性申请所有的资源，这样一个线程要完成一个任务就不需要等待了。</li>
<li>对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占整个条件就被破坏掉。</li>
<li>对于“循环等待”这个条件：可以考按需申请资源来预防。所谓按序申请，是指资源是有线性顺序的，申请的时候可以先申请资源序列号小的，再申请资源号大的，这样线性化后自然就不存在循环了。</li>
</ol>
<p>上面说的是理论上如何预防死锁，那具体体现在代码上是怎么样的？就按照案例分析中（转账与存款问题）的问题代码来实践下。</p>
<h2 id="解决死锁的静态方法：破坏三个条件实践"><a href="#解决死锁的静态方法：破坏三个条件实践" class="headerlink" title="解决死锁的静态方法：破坏三个条件实践"></a>解决死锁的静态方法：破坏三个条件实践</h2><h3 id="1-破坏“占用且等待”条件"><a href="#1-破坏“占用且等待”条件" class="headerlink" title="1. 破坏“占用且等待”条件"></a>1. 破坏“占用且等待”条件</h3><p>理论上讲，要破坏这个条件可以一次申请所有资源。如上面的案例，资源有两个：转出账户、转入账户。要同时申请这两个账户，怎么解决？</p>
<p>增加一个账户管理员，只允许账户管理员拿账户。当张三申请账户A和账户B，如果当前只有账户A空闲，那么就不会把账户A给张三。</p>
<p><img data-src="/img/in-post/1557199878669.png" alt=""></p>
<p>因此，“同时申请”就是一个临界区，需要新增一个角色（类）来管理整个临界区。</p>
<p>角色定义：Allocator。</p>
<p>两个功能：申请apply()和释放free()。</p>
<p>使用：账户类中持有一个Allocator单例（必须是单例，只能由一个人来分配资源）。</p>
<p>代码：</p>
<pre><code class="java">class Allocator {
  private List&lt;Object&gt; als =
    new ArrayList&lt;&gt;();
  // 一次性申请所有资源
  synchronized boolean apply(
    Object from, Object to){
    if(als.contains(from) ||
         als.contains(to)){
      return false;  
    } else {
      als.add(from);
      als.add(to);  
    }
    return true;
  }
  // 归还资源
  synchronized void free(
    Object from, Object to){
    als.remove(from);
    als.remove(to);
  }
}

class Account {
  // actr 应该为单例
  private Allocator actr;
  private int balance;
  // 转账
  void transfer(Account target, int amt){
    // 一次性申请转出账户和转入账户，直到成功
    while(!actr.apply(this, target))
      ；
    try{
      // 锁定转出账户
      synchronized(this){              
        // 锁定转入账户
        synchronized(target){           
          if (this.balance &gt; amt){
            this.balance -= amt;
            target.balance += amt;
          }
        }
      }
    } finally {
      actr.free(this, target)
    }
  } 
}
</code></pre>
<p>弊端：while(!actr.apply(this, target)) 如果在并发高的时候循环次数会非常多而且如果在其他场景下如果耗时长也是不适用的。可以使用notify来改造。参考：<a href="https://time.geekbang.org/column/article/85241" target="_blank" rel="noopener">用“等待-通知”机制优化循环等待</a></p>
<h3 id="2-破坏“不可抢占”条件"><a href="#2-破坏“不可抢占”条件" class="headerlink" title="2. 破坏“不可抢占”条件"></a>2. 破坏“不可抢占”条件</h3><p>不可抢占核心是希望线程能主动释放它占有的资源，synchronized是做不到，原因是synchronized申请资源的时候，如果申请不到线程直接进入阻塞状态了，而线程进入阻塞状态，啥都干不了，也释放不了线程占有的资源。</p>
<p>因此可以将sychronized换成java.util.concurrent包下的Lock来解决。下面一小节会详细讲定时锁。</p>
<h3 id="3-破坏“循环等待”条件"><a href="#3-破坏“循环等待”条件" class="headerlink" title="3. 破坏“循环等待”条件"></a>3. 破坏“循环等待”条件</h3><p>破坏这个资源需要对资源排序，然后申请资源。实现很简单，假设每个账户都有不同的属性id，可以用唯一属性id作为排序字段，申请的时候按照id排序来按序申请资源。</p>
<pre><code class="java">class Account {
  private int id;
  private int balance;
  // 转账
  void transfer(Account target, int amt){
    Account left = this        ①
    Account right = target;    ②
    if (this.id &gt; target.id) { ③
      left = target;           ④
      right = this;            ⑤
    }                          ⑥
    // 锁定序号小的账户
    synchronized(left){
      // 锁定序号大的账户
      synchronized(right){ 
        if (this.balance &gt; amt){
          this.balance -= amt;
          target.balance += amt;
        }
      }
    }
  } 
}
</code></pre>
<h2 id="解决死锁的动态方法"><a href="#解决死锁的动态方法" class="headerlink" title="解决死锁的动态方法"></a>解决死锁的动态方法</h2><p>该动态方法主要用在操作系统进程死锁上，作为理解和思路拓展</p>
<h3 id="基本策略"><a href="#基本策略" class="headerlink" title="基本策略"></a>基本策略</h3><ul>
<li><p>在系统运行过程中，对进程发出的系统资源申请进行动态检查，并根据检查决定是否分配资源，若分配后系统可能发生死锁，则不予分配，否则予以分配。</p>
</li>
<li><p>关键在与区分安全状态与不安全状态，安全状态一定没有死锁发生，因而对进程的申请进行试分配，分配后系统状态为安全状态则满足，否则不满足。</p>
<p><img data-src="/img/in-post/1557888026650.png" alt=""></p>
</li>
</ul>
<h3 id="一个典型的死锁避免算法：银行家算法"><a href="#一个典型的死锁避免算法：银行家算法" class="headerlink" title="一个典型的死锁避免算法：银行家算法"></a>一个典型的死锁避免算法：银行家算法</h3><ul>
<li><p>解决单种资源的场景</p>
<p>主要思想是对申请资源序列检查，如果申请的序列满足安全序列，则是安全状态，即不会发生死锁。</p>
<p>所谓<strong>安全序列</strong>就是对一个进程序列的P1 P2 PN的每个进程Pi，它以后需要的资源量不超过当前剩余资源量与所有进程Pj(j&lt;i)当前占有资源量之合，则该序列为安全序列。</p>
<p><strong>安全状态</strong>是：如果系统的所有进程能够排成一个安全序列，则系统处于安全状态。</p>
</li>
<li><p>解决单种资源的案例（存在安全序列、不存在安全序列）</p>
<p><img data-src="/img/in-post/1557889587309.png" alt=""></p>
</li>
</ul>
<p><img data-src="/img/in-post/1557889601088.png" alt=""></p>
<p>另外银行家算法还用来解决多种资源申请避免死锁的场景应用中，这里就不在展开来讲了。</p>
<h1 id="死锁的检测及解除"><a href="#死锁的检测及解除" class="headerlink" title="死锁的检测及解除"></a>死锁的检测及解除</h1><h2 id="基本策略-1"><a href="#基本策略-1" class="headerlink" title="基本策略"></a>基本策略</h2><ul>
<li>允许死锁发生</li>
<li>操作系统不断监视系统进展情况，判断死锁是否发生</li>
<li>一旦死锁发生则采取专门的措施，解除死锁并以最小的代价恢复操作系统运行</li>
</ul>
<h2 id="死锁的检测"><a href="#死锁的检测" class="headerlink" title="死锁的检测"></a>死锁的检测</h2><ul>
<li><p>检测时机：进程等待时、定时检测、资源利用率下降时</p>
</li>
<li><p>检测手段：利用<strong>进程-资源分配图</strong></p>
<ul>
<li>方框表示 资源类（资源的不同类型）</li>
<li>方框中的黑圆点表示资源实例（存在于每个资源类中）</li>
<li>圆圈中加进程名表示进程</li>
<li>资源实例指向进程的一条有向边来表示分配边</li>
<li>进程指向资源类的一条有向边来表示申请边</li>
</ul>
</li>
<li><p>进程-资源分配图中的死锁判断</p>
<ul>
<li><p>无环路，则此时系统没有发生死锁</p>
</li>
<li><p>有环路，且每个资源类中仅有一个资源，则系统中发生了死锁。此时，环路是系统发生死锁的<strong>充分条件</strong>，环路中的进程便成为死锁进程。</p>
</li>
<li><p>有环路，且涉及的资源类中有多个资源，则环路的存在只是产生死锁的<strong>必要条件</strong>而不是充分条件。</p>
<p><img data-src="/img/in-post/1557890546652.png" alt=""></p>
</li>
</ul>
</li>
</ul>
<h2 id="死锁解除"><a href="#死锁解除" class="headerlink" title="死锁解除"></a>死锁解除</h2><p>应以最小的代价恢复系统的运行</p>
<ul>
<li>资源剥夺法（操作系统进程理论）：当发现死锁后，从其他进程哪里剥夺足够数量资源给死锁进程，以解除死锁状态。</li>
<li>撤销进程法：<ul>
<li>撤销全部死锁进程，使系统恢复到正常状态。最简单但代价太大</li>
<li>按照某种顺序逐个撤销死锁进程，直到有足够的资源供其他未被撤销的进程使用，消除死锁状态为止。</li>
</ul>
</li>
</ul>
<h1 id="避免死锁良好的开发实践"><a href="#避免死锁良好的开发实践" class="headerlink" title="避免死锁良好的开发实践"></a>避免死锁良好的开发实践</h1><p>解决死锁问题，最重要的是在写代码初期就要分析代码并规避掉发生死锁的可能，以下是常用的几种死锁避免的通用方法。</p>
<h2 id="控制好锁力度"><a href="#控制好锁力度" class="headerlink" title="控制好锁力度"></a>控制好锁力度</h2><p>使用类或者方法级别的大粒度锁，在一定程度上可以避免大部分的死锁问题。但是同时会带来并发串行化的弊端，为了解决性能问题需要把锁细粒度化，但同时也增加了死锁的可能（如下面存款转账的例子）。因此需要权衡控制好。</p>
<h2 id="考虑加锁顺序（破坏循环等待条件）"><a href="#考虑加锁顺序（破坏循环等待条件）" class="headerlink" title="考虑加锁顺序（破坏循环等待条件）"></a>考虑加锁顺序（破坏循环等待条件）</h2><ul>
<li>尽量减少潜在的加锁交互数量，将获取锁时需要遵循的协议写入正式文档。</li>
<li>两阶段策略：找出在什么地方获取多个所，然后对这些实例全局分析，确保他们在整个程序中获取锁的顺序都保持一致。</li>
<li>使用开放调用，极大简化分析过程。</li>
<li>使用编号排序，来决定申请锁的顺序。整个上面已经提过了。</li>
</ul>
<h2 id="支持定时的锁（破坏不可抢占条件）"><a href="#支持定时的锁（破坏不可抢占条件）" class="headerlink" title="支持定时的锁（破坏不可抢占条件）"></a>支持定时的锁（破坏不可抢占条件）</h2><p>有一项技术可以检测死锁和从死锁中恢复过来，就是Lock类的定时tryLock功能来代替内置锁机制（见后续有关显示锁的详细总结）。</p>
<p>当使用内置锁时，只要没有获得锁，就会永远等待下去。而使用显示锁，可以指定超时时间，在等待超过该时间后tryLock会返回失败信息。如果超时时间比获得锁的时间要长很多，那么就可以在发生某个意外情况后重新获得控制权。</p>
<h2 id="开放顺序调用（将锁范围控制在当前实例内不要溢出）"><a href="#开放顺序调用（将锁范围控制在当前实例内不要溢出）" class="headerlink" title="开放顺序调用（将锁范围控制在当前实例内不要溢出）"></a>开放顺序调用（将锁范围控制在当前实例内不要溢出）</h2><p>在程序中尽量始终使用开发调用，将大大减少需要同时持有多个锁的地方。所谓<strong>开发调用</strong>就是：</p>
<p>如果在调用某个方法时不需要持有锁，那么这种调用被称为<strong>开发调用</strong>。</p>
<h2 id="死锁诊断"><a href="#死锁诊断" class="headerlink" title="死锁诊断"></a>死锁诊断</h2><h3 id="通过线程转储信息来分析死锁"><a href="#通过线程转储信息来分析死锁" class="headerlink" title="通过线程转储信息来分析死锁"></a>通过线程转储信息来分析死锁</h3><p>可以通过JVM的Thread Dump功能来分析诊断当前死锁的发生。</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
        <tag>死锁</tag>
      </tags>
  </entry>
  <entry>
    <title>【基本概念篇】八、安全性、活跃性、性能问题</title>
    <url>/2019/04/21/2019-5-07-java-concurreny-safey-performence/</url>
    <content><![CDATA[<h1 id="安全问题"><a href="#安全问题" class="headerlink" title="安全问题"></a>安全问题</h1><p>线程安全的本质就是正确性，而正确性的含义就是<strong>程序按照我们的期望执行</strong>。</p>
<p><a href="https://zhoulei17.github.io/2019/04/11/java-concurreny-concept-3Bug/" target="_blank" rel="noopener">《可见性、原子性和有序性：并发编程Bug的来源》</a>举例了很多诡异的Bug，都不是按照我们的<strong>期望</strong>来执行的。</p>
<p>如何才能写出线程安全的程序呢？</p>
<p>在<a href="https://zhoulei17.github.io/2019/04/11/java-concurreny-concept-3Bug/" target="_blank" rel="noopener">第四篇中</a>中讲到了3个并发的主要来源：原子性、可见性和有序性问题。也就是说，理论上的线程安全问题，是不能出现原子性、可见性和有序性问题。</p>
<p>实际上，只有一种情况下：<strong>存在共享数据并且数据会变化，通俗讲就是多个线程会同时读写同一数据</strong>。反过来讲如果能做到不共享数据或者数据不发生变化，就能<strong>保证线程的安全性</strong>。基于这个理论的技术有：ThreadLocal、不变模式等（后面的博客会总结）。</p>
<p>但是，现实中，<strong>必须共享且发生变化的数据</strong>的场景是很多的。</p>
<h2 id="数据竞争"><a href="#数据竞争" class="headerlink" title="数据竞争"></a>数据竞争</h2><p>当多个线程同时访问同一数据，并且至少有一个线程会写这个数据的时候，如果不采取措施就会引发Bug，这种情况叫做<strong>数据竞争(Data Race)</strong>。比如下面的示例：</p>
<pre><code class="java">public class Test {
  private long count = 0;
  void add10K() {
    int idx = 0;
    while(idx++ &lt; 10000) {
      count += 1;
    }
  }
}</code></pre>
<p>是不是只要在访问数据的地方都加上锁就线程安全了？如：</p>
<pre><code class="java">public class Test {
  private long count = 0;
  synchronized long get(){
    return count；
  }
  synchronized void set(long v){
    count = v;
  } 
  void add10K() {
    int idx = 0;
    while(idx++ &lt; 10000) {
      set(get()+1)      
    }
  }
}</code></pre>
<p>然并卵，当两个线程同时执行get()方法时返回0，两个线程执行get()+1操作，结果都是1，之后两个线程把结果1写入内存。而实际期间是2，结果却是1。这种问题叫做：<strong>竞态条件(Race Condition)</strong>。</p>
<p>所谓<strong>竞态条件，指的是程序的执行结果依赖线程执行的顺序</strong>。例如上面，如果两个线程完全同时执行，那么结果是1，如果先后执行那么结果是2。在并发环境里，线程的执行顺序是不确定的，而执行结果不确定就是个大Bug。</p>
<h2 id="竞态条件"><a href="#竞态条件" class="headerlink" title="竞态条件"></a>竞态条件</h2><p>举上一篇讲到的存款转账的例子：</p>
<pre><code class="java">class Account {
  private int balance;
  // 转账
  void transfer(
      Account target, int amt){
    if (this.balance &gt; amt) {
      this.balance -= amt;
      target.balance += amt;
    }
  } 
}
</code></pre>
<p>假设账户余额200，线程A和线程B都要转账150，同时执行到第6行，判断当前余额满足，就出现了超额转出的情况。</p>
<p>所以可以这样理解<strong>竞态条件</strong>：</p>
<pre><code class="java">if (状态变量 满足 执行条件) {
  执行操作
}</code></pre>
<p>当某个线程发现状态条件满足执行条件后，开始执行操作；可是就在这个线程执行操作的时候，其他线程修改了状态变量，导致状态不满足执行条件了。当然在很多场景下，这个条件是并不是显式的，开发的时候不容易看出来，例如上麦呢的addeOne的例子，set(get()+1)这个复合操作，其实就是隐式依赖get()的结果。</p>
<p>面对<strong>数据竞争</strong>和<strong>竞态条件</strong>问题，又改如何保证线程的安全性呢？</p>
<p>这两类问题，最直接的方法是使用<strong>互斥</strong>，而实现互斥的方案有很多，CPU提供了相关的互斥指令，操作系统、编程语言也会提供相关的API。从逻辑上来说，可以统一归类为：<strong>锁</strong>。锁前面已经讲过了<a href="https://zhoulei17.github.io/2019/04/20/java-concurrency-lock/" target="_blank" rel="noopener">互斥锁</a>以及后面会讲的Lock锁。</p>
<h1 id="活跃性问题"><a href="#活跃性问题" class="headerlink" title="活跃性问题"></a>活跃性问题</h1><p>在上篇已经讲过<a href="https://zhoulei17.github.io/2019/04/21/java-concurreny-deadlock/" target="_blank" rel="noopener">死锁</a>，除了<strong>死锁</strong>这种典型的活跃性问题，还有两种情况<strong>活锁</strong>和<strong>饥饿</strong>。</p>
<p>前面讲了，死锁后线程会互相等待，并且会一直等待下去（阻塞）。</p>
<h2 id="活锁"><a href="#活锁" class="headerlink" title="活锁"></a>活锁</h2><p>也有情况是<strong>虽然线程没有发生阻塞，但仍然会执行不下去的情况，就是“活锁”</strong>。就好比现实生活中，两个在一条比较窄的路上碰头，每个人都同时让出自己的左边给对方，这样仿佛切换两个都同时堵住了对方双方都过不去。</p>
<p>解决<strong>活锁</strong>的方案很简单，谦让时，尝试等待一个随机的时间后，一方让出一边让对方先走过去，这样碰撞的概率就很低了。</p>
<h2 id="饥饿"><a href="#饥饿" class="headerlink" title="饥饿"></a>饥饿</h2><p>所谓<strong>饥饿，指的是因线程无法访问所需资源而无法执行下去的情况</strong>。</p>
<p>最经典的例子是，线程优先级分配“不均”，在CPU繁忙的情况下，优先级低的线程得到的执行机会很小，就可能发生线程“饥饿”；持有锁的线程，如果执行时间过长，也可能导致“饥饿”问题。</p>
<p>解决“<strong>饥饿</strong>”问题的方案很简单，三种：1. 保证资源充足。2. 公平地分配资源。3. 就是避免持有锁的线程长时间执行。</p>
<p>这三钟方案中，方案1和方案3适用场景比较有限，因为很多时候资源稀缺是没办法解决的，持有锁的线程执行时间也难以控制。方案2的实用场景相对多一些。</p>
<p>如何公平低分配资源？在并发编程领域，主要是使用公平锁。所谓<strong>公平锁</strong>，是一种先来后到的方案，线程的等待是有序的，排在等待队列前面的线程会优先获得资源。</p>
<h1 id="性能问题"><a href="#性能问题" class="headerlink" title="性能问题"></a>性能问题</h1><p>使用锁的时候要谨慎，如果使用过度会出现性能问题。锁的过度使用可能导致串行化的范围过大，这样就不能发挥多线程的优势了。</p>
<h2 id="性能衡量方法"><a href="#性能衡量方法" class="headerlink" title="性能衡量方法"></a>性能衡量方法</h2><p>所以要尽量减少串行化，那串行化对性能的影响是怎么样的？假设串行百分比是5%，我们用多核多线程相比单核单线程提速多少？</p>
<p>使用阿姆达尔(Amdahl)定律，代表了处理器并行运算之后效率的提升能力，具体公式如下：</p>
<p><img data-src="/img/in-post/1557287822597.png" alt=""></p>
<p>n：CPU的核数</p>
<p>p：并行百分比</p>
<p>1-p：串行百分比，也就是我们假设的5%</p>
<p>假设n无穷大，那加速比S的极限就是20。也就是说，如果串行率是5%，那么无论采用什么技术，最高也就只能提高20倍的性能。</p>
<h2 id="性能优化方案"><a href="#性能优化方案" class="headerlink" title="性能优化方案"></a>性能优化方案</h2><p>所以使用锁的时候一定要关注对性能的影响。那怎么才能避免锁带来的性能问题呢？</p>
<p>问题比较复杂，<strong>Java SDK并发包里之所有有那么多东西，有很大一部分原因就是要提升在某个特定领域的性能</strong>。</p>
<p>从方案层面，有如下方案可以解决这个问题：</p>
<ul>
<li><p>第一，既然锁会带来性能问题，最好的方案自然就是使用无锁的算法和数据结构了。</p>
<p>相关的技术有：</p>
<ul>
<li><p>例如线程本地存储（ThreadLocal）</p>
</li>
<li><p>写入时复制（CopyOnWrite）、乐观锁等；</p>
</li>
<li><p>Java并发包里面的原子类也是一种数据结构；</p>
</li>
<li><p>Disruptor则是一个无锁的内存队列，性能都非常好。</p>
</li>
</ul>
</li>
<li><p>第二，减少锁持有的时间。互斥锁本质上是将并行的程序串行化，所以要增加并行度，一定要减少持有锁时间。</p>
<p>这个方案的技术也很多，例如</p>
<ul>
<li>使用细粒度锁，一个典型的例子就是Java并发包里的ConcurrentHashMap，它使用了所谓的分段锁技术（后面ConcurrentHashMap源码分析会详细讲到）；</li>
<li>使用读写锁，也就是读是无锁的，只有写的时候才会互斥。</li>
</ul>
</li>
</ul>
<h2 id="性能指标"><a href="#性能指标" class="headerlink" title="性能指标"></a>性能指标</h2><p> 性能方面的指标有很多，三个指标非常重要，就是：吞吐量、延迟和并发量。</p>
<ol>
<li>吞吐量：指的是单位时间内处理的请求数量。吞吐量越高，说明性能越好。</li>
<li>延迟：指的是从发出请求到收到响应的时间。延迟越小，性能越好。</li>
<li>并发量：指的是能同时处理的请求数量，一般来说随着并发量的增加、延迟也会增加。所以延迟整个指标，一般会基于并发量来说。例如并发量是1000的时候，延迟是500毫秒。</li>
</ol>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>并发编程是一个复杂的技术领域，微观上来说涉及到原子性问题、可见性问题和有序性问题，宏观则表现为安全性、活跃性以及性能问题。</p>
<p>在设计并发程序的时候，主要从宏观角度出发，就是关注它的安全性、活跃性以及性能。</p>
<p>安全性方面要注意数据竞争和静态条件</p>
<p>活跃性方面需要注意死锁、活锁、饥饿等问题</p>
<p>性能方面介绍了两个方案，但是遇到具体问题要具体分析，根据忒定场景选择合适的算法和数据结构。</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
        <tag>死锁</tag>
        <tag>线程的风险</tag>
      </tags>
  </entry>
  <entry>
    <title>【基本概念篇】六、互斥锁：解决原子性问题</title>
    <url>/2019/04/20/2019-4-20-java-concurrency-lock/</url>
    <content><![CDATA[<p>四、五两篇基本概念中提到，一个或者多个操作在CPU执行过程中不被中断的特性，称为”原子性”。理解这个特性有助于分析并发编程Bug出现的原因，例如利用它可以分析出long型变量在32位机器上读写可能出现的诡异Bug，明明已经把变量成功写入内存，重新读出来却不是自己写入的。</p>
<h1 id="原子性问题到底如何解决？"><a href="#原子性问题到底如何解决？" class="headerlink" title="原子性问题到底如何解决？"></a>原子性问题到底如何解决？</h1><p>已经知道，原子性问题的源头是<strong>线程切换</strong>，如果能够禁用线程切换是不是就能解决这个问题了？而操作系统做线程切换是依赖CPU中断的，所以禁止CPU发生中断就能禁用线程切换。</p>
<p>在早期单核CPU时代，这个方案是可行的，但不适用多核场景。</p>
<p>以64位long变量操作说明问题：long型是64位，在32位CPU上操作会被拆分成两次写操作(写高32位和写低32位，如图所示)</p>
<p><img data-src="/img/in-post/image-20190421184235794.png" alt=""></p>
<ul>
<li>在单核CPU场景下，同一时刻只有一个线程执行，禁用CPU中断，意味着操作系统不会重新调度线程，也就是禁止了线程切换，获得CPU使用权就可以不间断地执行，所以两次写操作要么都执性，要么都没有被执行，具有原子性。</li>
<li>在多核场景下，同一时刻，有可能有两个线程同时在执行，一个线程运行在CPU1上，一个线程运行在CPU2上，此时禁用CPU中断，只能保证CPU上的线程连续执行，并不能保证同一时刻只有一个线程执行，如果这两个线程同时写long变量的高32位，就可能出现诡异Bug了。</li>
</ul>
<p><strong>同一时刻只有一个线程执行</strong>这个条件非常重要，称之为<strong>互斥</strong>。如果能够保证共享变量的修改是互斥的，那么无论是单核CPU还是多核CPU，就能保证原子性了。</p>
<p>注意，在详细总结线程互斥相关内容的时候会再详细介绍Java原子类的相关内容。</p>
<h1 id="简易锁模型"><a href="#简易锁模型" class="headerlink" title="简易锁模型"></a>简易锁模型</h1><p><img data-src="/img/in-post/image-20190421185004251.png" alt=""></p>
<p>我们把一段需要互斥执行的代码称为<strong>临界区</strong>。</p>
<ol>
<li><p>线程在进入临界区之前，首先尝试加锁lock()，如果成功，则进入临界区，此时称为这个线程持有锁；</p>
</li>
<li><p>否则就等待，直到持有锁的线程解锁。</p>
</li>
<li><p>持有锁的线程执行完临界区的代码后，执行解锁unlock()。</p>
</li>
</ol>
<h2 id="改进后的锁模型"><a href="#改进后的锁模型" class="headerlink" title="改进后的锁模型"></a>改进后的锁模型</h2><p>锁和资源应该有对应关系，完善下上面的模型</p>
<p><img data-src="/img/in-post/image-20190421190045543.png" alt=""></p>
<p>受保护的资源R</p>
<p>保护资源R创建一把锁LR</p>
<p>针对这把锁LR，需要在进出临界区时添加加锁和解锁操作。</p>
<p><strong>锁与保护对象一一对象非常重要，如果出现加锁对象错乱就会出现Bug。</strong></p>
<h1 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h1><p>锁是一种通用的技术方案，Java语言提供的synchronized关键字，就是锁的一种实现。</p>
<p>synchronized关键字可以用来修饰方法，也可以用来修饰代码块。使用示例：</p>
<pre><code class="java">class X {
  // 修饰非静态方法
  synchronized void foo() {
    // 临界区
  }
  // 修饰静态方法
  synchronized static void bar() {
    // 临界区
  }
  // 修饰代码块
  Object obj = new Object()；
  void baz() {
    synchronized(obj) {
      // 临界区
    }
  }
}  
</code></pre>
<p>Java编译器会在synchronized修饰的方法或代码块前后自动加上加锁lock()和解锁unlock()，这样做的好处是加锁和解锁一定是成对出现的，避免忘记显式解锁unlock。</p>
<h2 id="锁定对象"><a href="#锁定对象" class="headerlink" title="锁定对象"></a>锁定对象</h2><ul>
<li><p>当修饰静态方式时，锁定的是当前类Class对象，在上面的例子就是Class X。</p>
<p>相当于：</p>
<pre><code class="java">class X {
  // 修饰静态方法
  synchronized(X.class) static void bar() {
    // 临界区
  }
}</code></pre>
</li>
</ul>
<ul>
<li><p>当修饰非静态方法时，锁定的是当前实例对象this。</p>
<p>相当于：</p>
<pre><code class="java">class X {
  // 修饰非静态方法
  synchronized(this) void foo() {
    // 临界区
  }
}</code></pre>
</li>
</ul>
<h1 id="用synchronized解决count-1问题"><a href="#用synchronized解决count-1问题" class="headerlink" title="用synchronized解决count+=1问题"></a>用synchronized解决count+=1问题</h1><p>看下面这段代码：</p>
<pre><code class="java">class SafeCalc {
  long value = 0L;
  long get() {
    return value;
  }
  synchronized void addOne() {
    value += 1;
  }
}</code></pre>
<p><code>addOne()</code>方法被synchronized修饰后，无论是单核CPU还是多核CPU，只有一个线程能执行addOne()方法，所以<strong>一定能保证原子操作</strong>。</p>
<ul>
<li><p>但<code>addOne()</code>是否有可见性问题？</p>
<p>分析：重温上一篇总结的<strong>管程中锁的规则</strong>：</p>
<blockquote>
<p>管程中锁的规则：对一个锁的解锁Happens-Before于后续对这个锁的加锁。</p>
</blockquote>
<p>管程，就是我们的synchronized(至于什么叫管程，后面会介绍总结)，synchronized修饰的临界区是互斥的，也就是同一时刻只有一个线程执行临界区代码；而管程中锁的规则指的就是一个线程的解锁操作对后一个线程的解锁操作可见，综合Happens-Before的<strong>传递性原则</strong>，就可以得出前一个线程在临界区修改的共享变量(该操作在解锁之前)，对后续进入临界区(该操作在加锁之后)的线程是可见的。因此执行一千次addOne()得到的结果一定是1000。</p>
</li>
</ul>
<ul>
<li><p>还有个问题就是<code>get()</code>操作是可见的吗？</p>
<p>这个可见性问题是没发保证的。管程中的规则，只保证后续对这个锁的加锁的可见性，而getI()操作没有加锁操作，所以可见性没法保证。如何解决？就是也加下synchronized修饰，完善后的代码如下：</p>
<pre><code class="java">class SafeCalc {
  long value = 0L;
  synchronized long get() {
    return value;
  }
  synchronized void addOne() {
    value += 1;
  }
}</code></pre>
<p>可以得到此例子的锁模型如下</p>
<p><img data-src="/img/in-post/image-20190421193841986.png" alt=""></p>
</li>
</ul>
<h1 id="锁和受保护资源的关系"><a href="#锁和受保护资源的关系" class="headerlink" title="锁和受保护资源的关系"></a>锁和受保护资源的关系</h1><p>受保护资源和锁之间的关联关系非常重要，它们的关系是怎么样的呢？</p>
<p>一个合理的关系是：<strong>受保护资源和锁之间关联关系是N:1关系</strong>。</p>
<p>在现实世界里，我们可以用多把锁来保护同一个资源，但在并发领域是不行的，并发领域的锁和现实世界的锁不是完全匹配的。不过可以用同一把锁来保护多个资源。</p>
<p>把上面的例子作改动，把value改成静态变量，把addOne()改成静态方法，此时get()方法和addOne()方法是否存在并发问题呢？</p>
<pre><code class="java">class SafeCalc {
  static long value = 0L;
  synchronized long get() {
    return value;
  }
  synchronized static void addOne() {
    value += 1;
  }
}</code></pre>
<p>可以看到两个方法对应的临界区分别两个锁保护的(this和SafeCalc.class)。可以得到下面的锁模型：</p>
<p><img data-src="/img/in-post/image-20190421194936340.png" alt=""></p>
<p>可以看到这两个临界区没有互斥关系，临界区addOne()对value的修改对临界区get()也没有可见性保证，这就导致并发问题了。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>互斥锁是解决共享资源并发问题的最常用手段，但是使用时一定要注意：</p>
<ol>
<li>锁与受保护资源的关系，注意考虑受保护资源的访问路径，确保加解锁的顺序(避免死锁)。</li>
<li>synchronized是Java在语言层面提供的互斥原语，其实Java里面还有很多其他类型的锁，但作为互斥锁，原理都是相通的。</li>
<li>解决原子性问题，是要保证中间状态对外不可见。</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
        <tag>互斥锁</tag>
      </tags>
  </entry>
  <entry>
    <title>【基本概念篇】五、Java内存模型：看Java如何解决可见性和有序性问题</title>
    <url>/2019/04/13/2019-4-13-java-concurreny-memory-model/</url>
    <content><![CDATA[<p>在上一篇总结了<strong>并发编程四</strong>，讲了并发编程的问题：因可见性、原子性、有序性导致的问题常常会违背我们的直觉，从而成为并发编程的Bug之源。这三者在编程领域属于共性问题，所有的编程语言都会遇到，Java在诞生之初就支持多线程，自然也有针对这三者的技术方案，而且在编程语言领域处于领先地位。理解Java解决并发问题的解决方案，对于理解其他语言的解决方案有触类旁通的效果。</p>
<p>因此篇博文就来结合王宝令老师的专栏《Java并发编程实战》以及《Java并发编程实战》一书来总结下<strong>Java内存模型</strong>的基本概念以及实现。后续我们会深入Java内存模型以及关联知识进一步总结，此篇主要是概念性的<strong>总结Java内存模型</strong>以及<strong>如何解决可见性、有序性问题。</strong></p>
<p>虽然上一篇在将并发编程的3个BUG来源时已经讲了问题来源的背景，下面从内存模型的角度详细讲下：</p>
<h1 id="什么是内存模型，为什么需要它？"><a href="#什么是内存模型，为什么需要它？" class="headerlink" title="什么是内存模型，为什么需要它？"></a>什么是内存模型，为什么需要它？</h1><p>假设有这么一条语句：</p>
<p><code>a = 3</code> </p>
<p>内存模型需要解决这个问题：什么条件下，读取a的线程将看到这个值为3？</p>
<p>如果缺少同步，会有很多因素导致线程没办法立马看到另一个线程的操作结果。</p>
<ul>
<li><p>在编译器生成的指令顺序，可以与源代码中的顺序不同,此外编译器还会把变量保存在寄存器中而不是内存中。（编译器重排或者叫指令重排）</p>
</li>
<li><p>处理器可以采用乱序或者并行等方式来执行指令；（处理器指令重排或者叫处理器优化）</p>
</li>
<li><p>缓存可能会改变写入变量提交到主内存的次序；而且，保存在处理器本地缓存中的值，对于其他处理器是不可见的。（缓存一致性问题）</p>
</li>
</ul>
<p><strong>这些因素都会使得一个线程无法看到变量的最新值。</strong></p>
<p><img data-src="/img/in-post/1555661841317.png" alt=""></p>
<p>为什么有这些因素，原因是由于计算机的发展以及优化带来的，下面说下，</p>
<h2 id="计算机发展的背景"><a href="#计算机发展的背景" class="headerlink" title="计算机发展的背景"></a>计算机发展的背景</h2><p>在<strong>单线程环境</strong>下，我们不用关注这些底层技术，因为它们提高了程序执行速度以外，不会产生什么其他影响。Java语言规范要求JVM在线程中维护类似串行的语义：只要程序的最终结果与严格串行环境执行结果相同，那么上述操作都是允许的。</p>
<ul>
<li><p>这些年，<strong>计算性能的提升</strong>：主要有这些重新排序措施、时钟频率提升、并行性提升——超标量执行单元、动态指令调度、猜测执行、完备的多级缓存。</p>
</li>
<li><p>除了计算能力提升，<strong>编译器也在不断改进</strong>：通过对指令重新排序来实现优化执行，以及使用成熟的全局寄存器分配算法。</p>
</li>
</ul>
<p>在多线程场景下，维护程序的串行性将导致很大的性开销。对并发应用程序来说，大部分时间都是各自执行各自任务，因此在线程之间的协调操作只会降低应用程序的运行速度，而不会带来任何好处。只有当多个线程要共享数据，才必须协调它们之间的操作，并且JVM依赖程序通过同步操作来协调多线程执行。</p>
<h2 id="最小保证"><a href="#最小保证" class="headerlink" title="最小保证"></a>最小保证</h2><p><strong>JMM规定了JVM必须遵循一组最小保证：规定对变量的写入操作在什么时候将对其他线程可见。（重要）</strong>JMM在设计时就在可预测性和程序的易开发性进行了权衡，从而在各种主流的处理器体系架构上实现高性能的JVM。</p>
<h2 id="缓存一致性问题、处理器优化和指令重排"><a href="#缓存一致性问题、处理器优化和指令重排" class="headerlink" title="缓存一致性问题、处理器优化和指令重排"></a>缓存一致性问题、处理器优化和指令重排</h2><p>就像上面提到的，CPU和主存之间增加了缓存，在多线程场景下会存在<strong>缓存一致性问题</strong>。</p>
<h3 id="缓存一致性"><a href="#缓存一致性" class="headerlink" title="缓存一致性"></a>缓存一致性</h3><p>在多核CPU，多线程场景中，每个核都至少有一个L1缓存。多个线程访问进程中的某个共享内存，且这个多线程分别在不同的核心上执行，则每个核心都会在各自的cache中保留一份共享内存的缓存。由于多核是可以并行的，可能会出现多个线程同时写各自的缓存的情况，而各自cache之间的数据就有可能不同。</p>
<p>在CPU和主存之间增加缓存，在多线程场景下就可能存在<strong>缓存一致性问题</strong>，也就是说，在多核CPU中，每个核自己的缓存中，关于同一个数据的缓存内容可能不一致。</p>
<p>除了这种情况，还有。</p>
<h3 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h3><p>线程是CPU调度的基本单元。CPU有时间片的概念，会根据不同的调度算法进行线程调度。所以在多线程场景下，就会发生原子性问题。因为线程在执行一个读写操作时，在执行完读改之后，时间片耗完，就会被要求放弃CPU，并等待重新调度。这种情况下，读写就不是一个原子操作。即存在<strong>原子性问题</strong>。</p>
<h3 id="有序性"><a href="#有序性" class="headerlink" title="有序性"></a>有序性</h3><p>一种硬件问题也比较重要。那就是为了使处理器内部的运算单元能够尽量被充分利用，处理器可能会对输入代码进行乱序执行处理。这就是<strong>处理器优化</strong></p>
<p>除了现在很多流行处理器会对代码进行优化乱序处理，很多编程语言的编译器也会有类似的优化，比如Java虚拟机的即时编译器（JIT）也会做<strong>指令重排</strong>。可想而知，如果任由处理器优化和编译器对指令重排，就可能导致各种各样的问题。比如load-&gt;add-&gt;save有可能会优化成load-&gt;save-&gt;add。这就是有序性问题。</p>
<p><strong>缓存一致性问题</strong>其实就是<strong>可见性问题</strong>。而<strong>处理器优化</strong>是可以导致<strong>原子性问题</strong>的（当然导致原子性问题的还可能是线程切换）。<strong>指令重排</strong>即会导致<strong>有序性问题</strong>。</p>
<h2 id="内存模型的概念"><a href="#内存模型的概念" class="headerlink" title="内存模型的概念"></a>内存模型的概念</h2><p>前面提到的，多CPU多级缓存导致缓存一致性问题、CPU时间片机制导致的原子性问题以及处理器优化和指令重排导致的有序性问题，是硬件的不断升级导致的。那么，有没有什么机制可以很好的解决上面的这些问题呢？</p>
<p>最简单直接的做法就是废除处理器和处理器的优化技术、废除CPU缓存，让CPU直接和主存交互。但是，这么做虽然可以保证多线程下的并发问题。但是，这就有点因噎废食了。</p>
<p>所以，为了保证并发编程中可以满足原子性、可见性及有序性。有一个重要的概念，那就是——<strong>内存模型</strong>。</p>
<p><strong>为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范。</strong>通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性。它与处理器有关、与缓存有关、与并发有关、与编译器也有关。他解决了CPU多级缓存、处理器优化、指令重排等导致的内存访问问题，保证了并发场景下的一致性、原子性和有序性。</p>
<p>内存模型解决并发问题主要采用两种方式：<strong>限制处理器优化</strong>和<strong>使用内存屏障</strong>。本文就不深入底层原理来展开介绍了，后续计划深入总结。</p>
<p>下面有一点摘自《Java并发编程实战》中关于内存屏障(内存栅栏)的描述：</p>
<blockquote>
<h3 id="平台的内存模型"><a href="#平台的内存模型" class="headerlink" title="平台的内存模型"></a>平台的内存模型</h3><p>在共享内存的多处理器体系架构中，每个处理器都有自己的缓存，并不定期与主内存进行协调。在不同的处理器架构中提供了不同级别的缓存一致性，其中一部分只提供最小保证，即允许不同的处理器在任意时刻从同一个存储位置上看到不同的值。操作系统、编译器以及运行时(有时甚至包括应用程序)需要弥合这种在硬件能力与线程安全需求之间的差异。</p>
<p>要确保处理器都能在任意时刻知道其他处理器的工作，需要非常大的开销。因此处理器会放宽存储一致性保证以换取性能提升。在架构定义的内存模型会告诉应用程序可以从内存系统获得怎么样的保证，此外还定义了一些特殊指令（<strong>称为内存栅栏或者栅栏</strong>），当需要共享数据时，这些指令就能实现额外的存储协调保证。为了使Java开发人员无须关心不同架构上的内存模型之间的差异，Java还提供了自己的内存模型，并且<strong>JVM通过在适当的位置上插入内存删栏来屏蔽JVM在底层平台内存模型之间的差异。</strong></p>
<p>在现代支持共享内存的多处理器（和编译器中），当跨线程共享数据时，会出现一些奇怪的情况，除非通过使用内存删栏来防止这些情况发生。幸运的是，Java程序不需要指定内存删栏的位置，而只需要正确地使用同步来找出何时将访问共享状态。</p>
</blockquote>
<h2 id="重排序案例"><a href="#重排序案例" class="headerlink" title="重排序案例"></a>重排序案例</h2><p>在没有充分同步的程序中，如果调度器采用不恰当的方式来交替执行不同线程的操作，那么将导致不正确的结果。更糟糕的是，JMM还使得不同线程看到的操作执行顺序是不同的，从而导致在缺乏同步的情况下，要推断操作的执行顺序变得更加复杂。各种使操作延迟或者看似乱序执行的不同原因，都可以归为<strong>重排序</strong>。</p>
<p><img data-src="/img/in-post/1555641870914.png" alt=""></p>
<p>PossibleReording要列举它所有可能的结果是非常困难的。内存级的重排序会使程序行为变得不可预测。如果没有同步，基本推断不出执行顺序。而要确保在程序中正确使用同步却很容易。<strong>同步</strong>将限制编译器、运行时、硬件对内存操作重排序的方式，从而在实施重排序时不会破坏JMM提供的可见性保证。</p>
<h1 id="什么是Java内存模型，为什么需要它？"><a href="#什么是Java内存模型，为什么需要它？" class="headerlink" title="什么是Java内存模型，为什么需要它？"></a>什么是Java内存模型，为什么需要它？</h1><p>已经知道，导致可见性的原因是缓存、导致有序性的原因是编译优化，那么解决可加性、有序性问题的直接办法就是<strong>禁用缓存和编译优化</strong>，虽然这样问题可以解决，但是我们程序的性能就堪忧了。</p>
<p>因此合理的方案应该是<strong>按需禁用缓存以及编译优化</strong>。那么，如何做到“按需禁用”呢？其实就是按照程序员的要求来禁用。所以，为了解决可见性、有序性问题，只需要提供给程序员按需禁用缓存和编译优化的方法即可。</p>
<p>前面介绍了计算机的内存模型，这是解决多线程场景下并发问题的一个重要规范。那么具体不同编程语言，在实现上可能有所不同。所以下面引入到Java内存模型开始讲起：</p>
<p>我们知道，Java程序是需要运行在Java虚拟机上面的，<strong>Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。</strong></p>
<p>提到Java内存模型，一般指的是JDK 5 开始使用的新的内存模型，主要由<a href="https://link.juejin.im?target=http%3A%2F%2Fwww.cs.umd.edu%2F~pugh%2Fjava%2FmemoryModel%2Fjsr133.pdf">JSR-133: JavaTM Memory Model and Thread Specification</a> 描述。感兴趣的可以参看下这份PDF文档（<a href="https://link.juejin.im?target=http%3A%2F%2Fwww.cs.umd.edu%2F~pugh%2Fjava%2FmemoryModel%2Fjsr133.pdf%25EF%25BC%2589">www.cs.umd.edu/~pugh/java/…</a></p>
<p>Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。</p>
<p>而JMM就作用于工作内存和主存之间数据同步的过程。他规定了如何做数据同步以及什么时候做数据同步。</p>
<p><img data-src="/img/in-post/image-20190420155251442.png" alt=""></p>
<p>这里提到的主存和工作内存，可简单类比成计算机内存模型的中的主存和缓存的概念。</p>
<p>注意，这里的主内存和工作内存与JVM内存结构中的Java堆、栈、方法区不是同一个层次的内存划分，无法直接类比。如果从《深入理解Java虚拟机》中认为，如果一定要勉强对应起来的话，从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分。工作内存则对应于虚拟机栈中的部分区域。</p>
<p>Java内存模型是个很复杂的规范，可以从不同的视角来解读，站在程序员的视角，<strong>本质上可以理解为，Java内存模型规范了JVM如何提供按需禁用缓存和编译优化的方法</strong>。具体来说，这些方法包括<strong>volatile、synchronized</strong>和<strong>final</strong>三个关键字等，以及主要的六项<strong>Happens-Before规则</strong>。</p>
<p>下面给出《Java并发编程》中Java内存模型简介：</p>
<blockquote>
<p>Java内存模型是通过各种操作来定义的，包括对变量的读/写操作，监视器的加锁和释放操作，以及线程的启动和合并操作。JMM为程序中所有的操作定义了一个偏序关系，这个关系就称为<strong>Happens-Before关系</strong>。如果要保证执行操作B的线程看到操作A的结果(无论A和B是否在同一个线程执行)，那么在A和B之间必须满足Happens-Before关系。如果两个操作之间缺乏Happens-Before关系，那么JVM可以对它们任意地排序。</p>
</blockquote>
<p><strong>所以，再来总结下，JMM是一种规范，目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。</strong> </p>
<p>#Java内存模型的实现</p>
<p>在Java中提供了一系列的并发处理相关的关键字，比如<code>volatile</code>、<code>synchronized</code>、<code>final</code>、<code>concurrent</code>包等。其实这些就是Java内存模型封装了底层的实现后提供给程序员使用的关键字。</p>
<p>例如，可以直接使用<code>synchronized</code>关键字来控制并发，从而不需要知道底层的编译器优化、缓存一致性等问题。所以，<strong>Java内存模型，除了定义了一套规范，还提供了了一系列原语，封装了底层实现后，供开发者使用。</strong></p>
<p>下面看下Java并发编程中提供了什么工具来解决并发领域的<strong>原子性、有序性、一致性的问题</strong>。</p>
<h2 id="原子性-1"><a href="#原子性-1" class="headerlink" title="原子性"></a>原子性</h2><p>在Java中，为了保证原子性，提供了两个高级字节码指令monitorenter和monitorexit。在后续我会总结出<strong>synchronized实现原理</strong>的文章，也可以参考人家总结的这篇文章<a href="">synchoronized实现原理</a><a href="http://www.hollischuang.com/archives/1883">http://www.hollischuang.com/archives/1883</a>，这两个字节码，在Java中对应的关键字就是<code>synchronized</code>。</p>
<p>所以，在Java中可以使用<code>synchronized</code>来保证方法和代码块内操作的原子性的。</p>
<h2 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h2><p>Java内存模型是通过在变量修改后将新值同步回主内存的，在变量读取前从主内存刷新变量值的这种依赖主内存作为传递媒介的方式来实现的。</p>
<p>Java中<code>volatile</code>关键字提供了一个功能，那就是被<strong>其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次使用之前都从主内存刷新</strong>。因此，可以使用<code>volatile</code>来保证多线程操作时变量的可见性。</p>
<p><strong>除了<code>volatile</code>，Java中的sychronized和final两个关键字也可以实现可见性。只不过实现方式不同，后续需要再展开</strong>。</p>
<h2 id="有序性-1"><a href="#有序性-1" class="headerlink" title="有序性"></a>有序性</h2><p>在Java中，可以使用synchronized和volatile来保证多线程之间操作的有序性。实现方式有所区别：</p>
<ul>
<li><code>volatile</code>关键字会禁止指令重排。</li>
<li><code>synchronized</code>关键字保证同一时刻只允许一条线程操作。</li>
</ul>
<p>可以看到<code>synchronized</code>关键字似乎是万能的，他同时满足了以上三种特性，这就是为什么很多人滥用<code>synchronized</code>的原因。</p>
<p>但是<code>sychronized</code>相对比较影响性能，虽然编译器提供了很多锁优化技术，但仍然不建议过度使用。</p>
<p>下面来看遵循JMM规范实现的Java并发编程中的具体规则，即Happens-Before规则：</p>
<h1 id="Happens-Before规则"><a href="#Happens-Before规则" class="headerlink" title="Happens-Before规则"></a>Happens-Before规则</h1><p>Happens-Before可以理解成：<strong>前一个操作对后一个操作是可见的</strong>。</p>
<h2 id="规则列表"><a href="#规则列表" class="headerlink" title="规则列表"></a>规则列表</h2><p>规则具体包括：</p>
<ul>
<li><strong>程序顺序规则</strong>：如果程序中操作A在操作B之前，那么在线程中A操作将在B操作之前执行。</li>
<li><strong>监视器锁规则</strong>：在监视器锁上的解锁操作必须在同一个监视器锁上的加锁操作之前执行。</li>
<li><strong>volatile变量规则</strong>：对volatile变量的写入操作必须在该变量的读操作之前执行。</li>
<li><strong>线程启动规则</strong>：在线程上对Thread.start的调用必须在该线程中执行任何操作之前执行。</li>
<li><strong>线程结束规则</strong>：线程中的任何操作都必须在其他线程检测到该线程已经结束之前执行，或者从Thread.join中成功返回，或者在调用Thread.isAlive时返回。</li>
<li>中断规则：当一个线程在另一个线程上调用interrupt时，必须在被中断线程检测到interrupt调用之前执行（通过抛出InterruptedException、或者调用isInterrupted和interrupted）。</li>
<li>终结器规则：如果对象的构造函数必须在启动该对象的终结器（finalize()）之前执行完成。</li>
<li><strong>传递性</strong>：如果操作A在操作B之前执行，并且操作B在操作C之前执行，那么操作A必须在操作C之前执行。</li>
</ul>
<p>例子中的6项是我们经常使用的且都是关于可见性的，下面的1~3项通过一个列子来说明，4、5、6分别举一个例子说明。</p>
<h2 id="1-程序顺序规则"><a href="#1-程序顺序规则" class="headerlink" title="1. 程序顺序规则"></a>1. 程序顺序规则</h2><p>这条规则是指在一个线程中，按照程序顺序，前面的操作Happens-Before与后续的任意操作。</p>
<pre><code class="java">// 以下代码来源于【参考 1】
class VolatileExample {
  int x = 0;
  volatile boolean v = false;
  public void writer() {
    x = 42;
    v = true;
  }
  public void reader() {
    if (v == true) {
      // 这里 x 会是多少呢？
    }
  }
}</code></pre>
<p>按照程序的顺序，第六行代码<code>x=42;</code>Happens-Before于第7行代码<code>v=true</code>，即是单线程中的思维规则：程序的某个变量的修改一定是对后续操作可见。</p>
<h2 id="2-volatile变量规则"><a href="#2-volatile变量规则" class="headerlink" title="2.volatile变量规则"></a>2.volatile变量规则</h2><p>指对一个volatile变量的写操作，Happen-Before于后续对这个volatile变量的读操作。</p>
<p>这个规则看着像是禁用了缓存的意思，貌似和JDK 1.5版本以前的语法没有变化？如果单看这个规则的确是这样，但是如果关联系规则3，就有点不一样的感觉了。在看规则3之前可以看下以下实例代码：</p>
<pre><code class="java">class VolatileExample {
  int x = 0;
  volatile boolean v = false;
  public void writer() {
    x = 42;
    v = true;
  }
  public void reader() {
    if (v == true) {
      // 这里 x 会是多少呢？
    }
  }
}</code></pre>
<p>在1.5 之前会出现x=0的情况，变量可能被CPU缓存导致了可见性问题。但是在JDK 1.5及以后，Java模型对volatile语义进行了增强。怎么增强的呢，下面就来看规则3.传递性</p>
<h2 id="3-传递性"><a href="#3-传递性" class="headerlink" title="3. 传递性"></a>3. 传递性</h2><p>这条规则是指 如果A happens-before B，且B happens-before C，那么A happens-before C。</p>
<p>将规则3的传递性运用到例子中，会发生什么？看下面这幅图</p>
<p><img data-src="/img/in-post/1555644709228.png" alt=""></p>
<p>从图中，我们可以看到：</p>
<ol>
<li>“x=42” Happens-Before 写变量 “v=true”，这是<strong>规则1.程序顺序规则</strong></li>
<li>读变量“v=true” Happens-Before 读变量 “v=true”，这是<strong>规则2的内容</strong></li>
</ol>
<p>再根据这条传递性规则，可以得到结果：”x=42” Happens-Before读变量”v=true”。这意味着：如果线程B读到了“v=true”，那么线程A设置的“x=42”对线程B是可见的。也就是说线程B能看到”x==42”，有一种恍然大悟的感觉？这就是1.5版本对volatile语义的增强，这个增强意义重大，1.5版本的并发工具包(java.util.concurrent)就是靠volatile语义来搞定可见性的。</p>
<h2 id="4-管程中的锁规则（监视器锁规则）"><a href="#4-管程中的锁规则（监视器锁规则）" class="headerlink" title="4 . 管程中的锁规则（监视器锁规则）"></a>4 . 管程中的锁规则（监视器锁规则）</h2><p>这条规则指：对一个锁的解锁Happens-Before于后续对和这个锁的加锁。</p>
<p>管程是什么？<strong>管程</strong>是一种通用的同步原语，在Java中指的就是synchronized，synchronized是Java中对管程的实现。</p>
<p>管程中的锁在Java里是隐式实现的，例如下面的代码，在进入同步快之前会自动加锁，而代码块执行结束会自动释放锁，加锁和释放锁都是编译器帮我们实现的。</p>
<pre><code class="java">synchronized (this) { // 此处自动加锁
  // x 是共享变量, 初始值 =10
  if (this.x &lt; 12) {
    this.x = 12; 
  }  
} // 此处自动解锁</code></pre>
<h2 id="5-线程start-规则（线程启动规则）"><a href="#5-线程start-规则（线程启动规则）" class="headerlink" title="5.线程start()规则（线程启动规则）"></a>5.线程start()规则（线程启动规则）</h2><p>这条规则指：主线程A启动子线程B后，子线程B能够看到主进程在启动子进程B之前的操作。</p>
<p>换句话说就是，如果线程A调用线程B的start()方法（即在线程A中启动线程B），那么该start()操作Happens-Before于线程B中的任意操作。具体可参考下面的示例代码。</p>
<pre><code class="java">Thread B = new Thread(()-&gt;{
  // 主线程调用 B.start() 之前
  // 所有对共享变量的修改，此处皆可见
  // 此例中，var==77
});
// 此处对共享变量 var 修改
var = 77;
// 主线程启动子线程
B.start();</code></pre>
<h2 id="6-线程join-规则（线程结束规则）"><a href="#6-线程join-规则（线程结束规则）" class="headerlink" title="6. 线程join()规则（线程结束规则）"></a>6. 线程join()规则（线程结束规则）</h2><p>这条是关于线程等待的。它是指主线程A等待子线程B完成（主线程A通过调用子线程join方法实现），当子线程B完成后（主线程A中join(）方法返回），主线程能够看到子线程的操作。当然所谓“看到”，指的是对共享变量的操作。</p>
<p>换句话说，如果在线程A中，调用线程B的join()并成功返回，那么线程B中的任意操作Happens-Before于该join()操作的返回。具体代码参考：</p>
<pre><code class="java">Thread B = new Thread(()-&gt;{
  // 此处对共享变量 var 修改
  var = 66;
});
// 例如此处对共享变量修改，
// 则这个修改结果对线程 B 可见
// 主线程启动子线程
B.start();
B.join()
// 子线程所有对共享变量的修改
// 在主线程调用 B.join() 之后皆可见
// 此例中，var==66
</code></pre>
<h1 id="发布"><a href="#发布" class="headerlink" title="发布"></a>发布</h1><p>造成不正确发布的真正原因，就是在“发布一个共享对象”与“另一个线程访问该对象”之前缺少一种Happens-Before排序。</p>
<h2 id="不安全的发布"><a href="#不安全的发布" class="headerlink" title="不安全的发布"></a>不安全的发布</h2><p>当缺少Happens-Before关系时，就可能出现重排序问题，这就解释了为什么在没有充分同步的情况下发布一个对象会导致另一个线程只看到一个只被<strong>部分构造的对象</strong>。在初始化一个新的对象时需要写入多个变量，即新对象中的各个域。同样，在发布一个引用时也需要写入一个变量，即新对象的引用，即新对象中的各个域。<strong>如果无法确保发布共享引用的操作在另一个线程加载该引用之前执行，那么对新对象引用的写入将与对象中各个域的写入操作重排序（从使用该对象的线程角度看）</strong>。在这种情况下，另一个线程可能看到对象引用的最新值，但同时也将看到对象的某些或全部状态中包含无效值，即一个被部分构造对象。</p>
<p>错误的延迟初始化将导致不正确的发布：</p>
<p><img data-src="/img/in-post/1555657300626.png" alt=""></p>
<p>初看起来这个程序没什么问题，实际这个代码是不安全的，因为另一个线程可能看到部分构造的Resource实例的引用。</p>
<p>假设线程A是第一个调用getInstance的线程，A将看到resource是null，并且初始化一个新的Resource，然后将resource初始化。当线程B随后调用getInstance，它能看到resource的值非空，因此使用这个已经构造好的Resource。最初看不出什么问题，但线程A写入resource操作与线程B读取resource的操作之间不存在Happens-Before关系。在发布对象时存在数据竞争问题，因此B并不一定能看到Resource的正确状态。</p>
<blockquote>
<p>除了不可变对象以外，使用被另一个线程初始化的对象通常都不是不安全的，除非对象的发布操作实在使用该对象的线程开始之前执行。</p>
</blockquote>
<h2 id="安全的发布"><a href="#安全的发布" class="headerlink" title="安全的发布"></a>安全的发布</h2><p>通过使用一个由锁保护共享变量或者使用共享的volatile类型的变量，也可以确保对该变量的读取操作和写入操作按照Happens-Before关系来排序。当然也可以把变量X放入Blocking队列中，供另外一个线程来读取，BlockingQueue内部同步确保了put方法在take方法之前执行。</p>
<h2 id="安全初始化模式"><a href="#安全初始化模式" class="headerlink" title="安全初始化模式"></a>安全初始化模式</h2><p>对上面不安全的发布的正确发布代码修改如下：</p>
<p><img data-src="/img/in-post/1555658802950.png" alt=""></p>
<p>静态初始化器是由JVM在类的初始化阶段执行，即在类被加载后并且被线程使用之前。由于JVM将在初始化期间获得一个锁，并且每个线程都至少获取一次这个锁以确保这个类已经被加载，<strong>因此在静态初始化期间，内存写入操作将自动对所有线程可见。因此无论是在被构造期间还是被引用时，静态初始化的对象都不需要显式的同步。然而，这个规则仅适用于构造时的状态，如果对象是可变的，那么在读线程和写线程之间依然需要通过同步来确保随后的修改操作是可见的，以避免数据破坏，就如上图代码。</strong></p>
<p>可以把以上代码修改成延迟初始化的版本如下代码</p>
<p><img data-src="/img/in-post/1555659121643.png" alt=""></p>
<p>并且可以和JVM的延迟加载机制结合起来，形成一种延迟初始化技术，从而在常用的代码路径中不需要同步。在下面的代码可称为“延迟初始化站位(Holder)模式”，使用一个专门的类来初始化Resource。JVM将推迟ResourceHolder的初始化操作，知道开始使用这个类才初始化，并且由于通过一个静态初始化来初始化Resource，因此不需要额外的同步。当任何一个线程第一次调用getResource时，都会使ResourceHolder被加载和被初始化，此时静态初始化器将执行Resource的初始化操作。</p>
<p><img data-src="/img/in-post/1555659329426.png" alt=""></p>
<h2 id="初始化过程中的安全性"><a href="#初始化过程中的安全性" class="headerlink" title="初始化过程中的安全性"></a>初始化过程中的安全性</h2><p>如果能确保初始化过程中的安全性，那么就可以使得被正确构造的不可变对象在没有同步的情况下也能安全地在多个线程之间共享，而不管它们是如何发布的，甚至通过某种数据竞争来发布。（这以为着如果Resources是不可变的，那么UnsafeLazyUnitialization实际上是安全的）。</p>
<p>如果不能确保初始化安全性，那么挡在发布或线程中没有使用同步时，一些本应为不可变对象（例如String）的值将会发生改变。</p>
<blockquote>
<p>初始化安全性将确保，对于正确构造的对象，所有线程都能看到构造函数为对象各个final域设置的正确值，而不管采用何种方式来发布对想。而且，对于可以通过被正确构造对象中的某个final域达到的任意变量（例如某个final数组中的元素，或者由一个final域引用的HashMap的内容)将同样对其他线程是可见的。</p>
</blockquote>
<p>对于含有final域的对象，初始化安全性可以防止对象的初始化引用被重排序到构造过程之前。当构造函数完成时，构造函数对final域的所有写入操作，以及对通过这些域可以到达的任何变量的写入操作都将被“冻结”，并且任何获得该对象引用的线程都至少能确保看到被冻结的值。对于通过final域可以到达的初始变量的写入操作，将不会与构造过程后的操作仪器被重排序。</p>
<p>初始化安全性意味着，下面的代码可以被安全地发布，即便通过不安全的延迟初始化，或者在同步的情况下将SafeStates的引用放到一个公有的静态域，或者没有使用同步以及依赖于费线程安全的HashSet。</p>
<p><img data-src="/img/in-post/1555660600515.png" alt=""></p>
<p>然而，许多对SafeStatus的细微修改都可能破坏它的安全性。如果status不是final类，或者存在构造函数以外的其他地方能修改stats，那么初始化安全性将无法确保在缺少同步的情况下安全地访问SafeStates。如果在SafeStates类海油其他非final域，那么其他线程依然可能看到这些域上的不正确值。这也导致了对象在构造过程中逸出，从而初始化安全性的保证无效。</p>
<p>下面再来补充一点<strong>final</strong>关键字对对象初始化和对象发布安全性的应用：</p>
<h3 id="被我们忽视的final-amp-安全发布"><a href="#被我们忽视的final-amp-安全发布" class="headerlink" title="被我们忽视的final&amp;安全发布"></a>被我们忽视的final&amp;安全发布</h3><p>前面讲了volatile为的是禁用缓存以及编译优化，我们再从另外一个方面来看，有没有办法告诉编译器优化得更好一点呢？就是<strong>final关键字</strong>。</p>
<p><strong>final修饰变量时，初衷是告诉编译器：这个变量生而不变，可以可劲儿优化</strong>。Java编译器在1.5以前的版本的确优化的很努力，以至于都优化错了。</p>
<p>问题类似于上一篇博客四提到的利用双重检查方法创建单例，构造函数的错误重排导致线程可能看到final变量值会变化。详细参考<a href="https://time.geekbang.org/column/article/84017" target="_blank" rel="noopener">这个文档</a>。</p>
<p>当然，在1.5以后Java内存模型对final变量的重排进行了约束。现在我们只要保证构造函数没有<strong>“逸出”</strong>，就不会出现问题。</p>
<p>解释下什么叫“逸出”，举个例子：</p>
<pre><code class="java">// 以下代码来源于【参考 1】
final int x;
// 错误的构造函数
public FinalFieldExample() { 
  x = 3;
  y = 4;
  // 此处就是讲 this 逸出，
  global.obj = this;
}</code></pre>
<p>在上面的例子里面，在构造函数里面将this赋值给了全局变量global.obj，这就是“逸出”，线程通过global.obj读取到x是有可能为0的。因此我们一定要避免逸出。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>Java的内存模型是并发编程领域的一次重要创新。在Java模型里面，最晦涩的部分就是Happens-Before规则了，Happens-Before规则最初是在一篇叫做<strong>Time，Clocks，and Ordering of Events in a Distributed System</strong>的论文中提出来的，在这篇论文中，Happens-Before的语义是一种因果关系。在现实世界里，如果A事件导致B事件的起因，那么A事件一定先于（Happens-Before）B事件发生的，这个就是Happens-Before语义的现实理解。</p>
<p>在Java语言里，Happen-Before的语义本质上是一种可见性，A Happens-Before B意味着A事件对B事件来说是可见的，无论A事件和B事件是否发生在同一个线程里。例如A事件发生在线程1上，B事件发生在线程2上，Happend-Before规则保证线程2也能看到A事件的发生。</p>
<p>Java内存模型主要分为两部分，一部分面向编写并发程序的开发人员，另一部分是面向JVM的实现人员，我们重点关注前者，也就是和编写并发程序相关的部分，这部分的核心就是<strong>Happens-Before规则</strong>。</p>
<ol>
<li><p>为什么定义Java内存模型？</p>
<p>现代计算机体系大部是采用的对称多处理器的体系架构。每个处理器均有独立的寄存器组和缓存，多个处理器可同时执行同一进程中的不同线程，这里称为处理器的乱序执行。在Java中，不同的线程可能访问同一个共享或共享变量。如果任由编译器或处理器对这些访问进行优化的话，很有可能出现无法想象的问题，这里称为编译器的重排序。除了处理器的乱序执行、编译器的重排序，还有内存系统的重排序。因此Java语言规范引入了Java内存模型，通过定义多项规则对编译器和处理器进行限制，主要是针对可见性和有序性。</p>
</li>
<li><p>三个基本原则：原子性、可见性、有序性。</p>
<p>Java内存模型涉及的几个关键词：锁、volatile字段、final修饰符与对象的安全发布。</p>
<p>其中：第一是锁，锁操作是具备happens-before关系的，解锁操作happens-before之后对同一把锁的加锁操作。实际上，在解锁的时候，JVM需要强制刷新缓存，使得当前线程所修改的内存对其他线程可见。</p>
<p>第二是volatile字段，volatile字段可以看成是一种不保证原子性的同步但保证可见性的特性，其性能往往是优于锁操作的。但是，频繁地访问 volatile字段也会出现因为不断地强制刷新缓存而影响程序的性能的问题。</p>
<p>第三是final修饰符，final修饰的实例字段则是涉及到新建对象的发布问题。当一个对象包含final修饰的实例字段时，其他线程能够看到已经初始化的final实例字段，这是安全的。</p>
</li>
<li><p>Happens-Before的7个规则：<br>(1).程序次序规则：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。<br>(2).管程锁定规则：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是同一个锁，而”后面”是指时间上的先后顺序。<br>(3).volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的”后面”同样是指时间上的先后顺序。<br>(4).线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作。<br>(5).线程终止规则：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join（）方法结束、Thread.isAlive（）的返回值等手段检测到线程已经终止执行。<br>(6).线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测到是否有中断发生。<br>(7).对象终结规则：一个对象的初始化完成(构造函数执行结束)先行发生于它的finalize()方法的开始。</p>
</li>
<li><p>Happens-Before的1个特性：传递性。</p>
</li>
<li><p><strong>Java内存模型底层怎么实现的？</strong>主要是通过内存屏障(memory barrier)禁止重排序的，即时编译器根据具体的底层体系架构，将这些内存屏障替换成具体的 CPU 指令。对于编译器而言，内存屏障将限制它所能做的重排序优化。而对于处理器而言，内存屏障将会导致缓存的刷新操作。比如，对于volatile，编译器将在volatile字段的读写操作前后各插入一些内存屏障。</p>
</li>
</ol>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://time.geekbang.org/column/article/84017" target="_blank" rel="noopener">看Java如何解决可见性和有序性问题</a></p>
<p><a href="https://www.hollischuang.com/archives/2550" target="_blank" rel="noopener">再有人问你Java内存模型是什么，就把这篇文章发给他</a></p>
<p><a href="https://www.hollischuang.com/archives/3526" target="_blank" rel="noopener">到底什么是计算机内存模型?</a></p>
<p>《深入理解Java虚拟机》、《Java并发实战》、《Java并发编程的艺术》</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>【基本概念篇】四、并发编程的3个问题（可见性、原子性、有序性问题）</title>
    <url>/2019/04/11/2019-4-11-java-concurreny-concept-3Bug/</url>
    <content><![CDATA[<p>并发编程有3个显著特征（可见性问题、原子性问题、有序性问题），也正是这样的特征才导致并发程序运行的结果往往不符合预期甚至出错，这3个特征正是并发编程BUG的源头。也可以说并发编程除了带给我们种种的好处之外（前面的blog讲过了），同样需要解决这3个特征或者叫问题。</p>
<h1 id="并发编程的背景故事"><a href="#并发编程的背景故事" class="headerlink" title="并发编程的背景故事"></a>并发编程的背景故事</h1><p>在聊并发编程的这3个BUG源头之前，我们先了解下为什么会有这3个BUG，来了解下承载并发运行的硬件和系统的背景知识。其核心矛盾就是因为我们的硬件速度之间存在着显著的差异。</p>
<h2 id="核心矛盾：硬件速度差异"><a href="#核心矛盾：硬件速度差异" class="headerlink" title="核心矛盾：硬件速度差异"></a>核心矛盾：硬件速度差异</h2><p>CPU、内存、I/O设备快速发展，但是这三者的速度差异，依然是核心矛盾。速度排序为CPU&gt;内存&gt;I/O设备。</p>
<p>为了合理利用CPU的高性能，平衡三者速度的差异，计算机体系结构、操作系统、编译程序都做出贡献，主要体现在：</p>
<ol>
<li>CPU增加了缓存，以均衡与内存的速度差异。</li>
<li>操作系统增加进程、线程，以分时复用CPU，进而均衡CPU与I/O设备的速度差异。</li>
<li>编译程序优化指令执行次数，使得缓存能够得到更加合理地利用。</li>
</ol>
<p>这些优化都是用于解决速度差异，但是在使用这些优化的同时，并发程序也因此出现很多诡异的问题。其根源也在于此。而且伴随的这些问题也一直伴随着我们。</p>
<h1 id="BUG的源头一：缓存导致的可见性问题"><a href="#BUG的源头一：缓存导致的可见性问题" class="headerlink" title="BUG的源头一：缓存导致的可见性问题"></a>BUG的源头一：缓存导致的可见性问题</h1><h2 id="单核时代"><a href="#单核时代" class="headerlink" title="单核时代"></a>单核时代</h2><p>在单核时代，所有线程在一个CPU上执行，CPU缓存与内存的数据一致性容易解决。因为所有线程都操作同一个CPU缓存，一个线程对缓存的写，对另外一个线程来说一定是可见的。例如在下图中，线程A和线程B都是操作同一个CPU里面的缓存，所以线程A更新了变量V的值，那么线程B之后再访问变量V，得到的一定是V的最新值（线程A写过的值）。</p>
<p><img data-src="/img/in-post/1555057243417.png" alt=""></p>
<p>一个线程对共享变量的修改，另外一个线程能够立即看到，我们成为<strong>可见性</strong>。</p>
<h2 id="多核时代"><a href="#多核时代" class="headerlink" title="多核时代"></a>多核时代</h2><p>在多核时代，每颗CPU都有自己的缓存，这时CPU缓存与内存的数据一致性就没那么容易解决了。当多个线程在不同CPU上执行时，这些线程操作的是不同的CPU缓存。比如下图中，线程A操作的是CPU-1上的缓存，而线程B操作的CPU2-2上的缓存，很明显，这个时候线程A对变量V的操作对于线程B而言就不具备<strong>可见性</strong>了。这就属于硬件程序员给软件程序员挖的“坑”。</p>
<p><img data-src="/img/in-post/1555057288746.png" alt=""></p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>举个例子，来说明下多核CPU场景下可见性问题。</p>
<pre><code class="java">public class TestVisibility {
    private static long count = 0 ; 
    private void add10k() {
        int idx = 0 ;
        while (idx ++ &lt; 10000) {
            count += 1;
        }
    }

    public static long cac() throws InterruptedException {
        final TestVisibility test = new TestVisibility();

        Thread th1 = new Thread(()-&gt;{
            test.add10k();
        }) ;

        Thread th2 = new Thread(()-&gt;{
            test.add10k();
        });
        th1.start();
        th2.start();

        th1.join();
        th2.join();
        return count;
    }
    public static void main(String[] args) throws InterruptedException {
        System.out.println(TestVisibility.cac());
    }
}</code></pre>
<p>运行3次：</p>
<p>第一次：</p>
<p><img data-src="/img/in-post/1555057353126.png" alt=""></p>
<p>第二次：</p>
<p><img data-src="/img/in-post/1555057398358.png" alt=""></p>
<p>第三次：</p>
<p><img data-src="/img/in-post/1555057409624.png" alt=""></p>
<p>我们的预期是20000，但是可以看到每次的结果都不正确且都不一样（10000到20000之间的随机数）。</p>
<p>原因是由于count变量th1,th2两个线程之间共享，我们假设线程A和线程B同时开始执行，那么第一次都会讲count=0读到各自的CPU缓存里，执行完count+=1之后，各自CPU缓存里面的值都是1，同时写入内存后，我们发现内存中是1，而不是我们期望的2。之后由于各自执行的CPU缓存里面都有了count的值，两个线程都是基于CPU缓存里的count值来计算，所以导致最终count的值都是小于20000的。这就是缓存的可见性问题。</p>
<p><img data-src="/img/in-post/1555057432300.png" alt=""></p>
<h1 id="BUG的源头二：线程切换带来的原子性问题"><a href="#BUG的源头二：线程切换带来的原子性问题" class="headerlink" title="BUG的源头二：线程切换带来的原子性问题"></a>BUG的源头二：线程切换带来的原子性问题</h1><p>由于IO太慢，早期的操作系统就发明了多进程，即便在单核的CPU上我们也可以一边听歌一边写Bug，这就是多进程的功劳。</p>
<p>操作系统运行某个进程执行一小段时间，例如50毫秒，过了50毫秒操作系统就会重新新选择一个进程来执行（我们成为<strong>“任务切换”</strong>），这个50毫秒成为<strong>“时间片”</strong>。</p>
<p><img data-src="/img/in-post/1555057477245.png" alt=""></p>
<p>在一个时间片内，如果一个进程进行一个IO操作，例如读文件，这个时候该进程可以把自己标记为“休眠状态”并让出CPU使用权，待文件读进内存，操作系统会把这个休眠的进程唤醒，唤醒后的进程就有机会重新获得CPU的使用权了。</p>
<p>这里的进程在等待IO时之所有会释放CPU使用权，是为了让CPU在这段等待时间里可以做别的事情，这样CPU的利用率就上来了；此外，如果这时有另外一个进程也读文件，读文件的操作就会排队，磁盘驱动在完成一个进程读操作后，发现有排队的任务，就会立即启动下一个读操作，这样IO的使用率也上来了。</p>
<p>这就是多进程的分时复用，早期的操作系统基于进程来调度CPU，不同进程间是不共享内存空间的，所以进程要做任务切换就要切换内存映射地址，而一个进程创建的所有线程，都是共享一个内存空间的，所以线程做任务切换成本就很低了。现代的操作系统都基于更轻量的线程来调度，现在我们提到的“任务切换”都是指“线程切换”。</p>
<p>Java并发程序都是基于多线程的，自然也会涉及到任务切换，也正式任务切换成为并发编程领域诡异Bug的源头之一。任务切换的时机大多数是在时间片结束的时候，高级语言里一条语句需要多条CPU指令完成，例如上面的代码<code>count+=1</code>,至少需要三条CPU指令：</p>
<ul>
<li>指令1：首先，需要把变量count从内存加载到CPU寄存器；</li>
<li>指令2：之后，在寄存器中执行+1操作；</li>
<li>指令3：最后，将结果写入内存（缓存机制导致可能希尔的是CPU缓存而不是内存）。</li>
</ul>
<p>操作系统做任务切换，可以发生在任何一条<strong>CPU指令</strong>执行完（而不是高级语言里的一条语句的粒度）。对于上面的三条指令来说，我们假设count=0，如果线程A在指令1执行完后做线程切换，线程A和线程B按照下图的序列执行，那么我们发现两个执行都执行了<code>count+=1</code>的操作，但是得到的结果不是我们期望的2，而是1</p>
<p><img data-src="/img/in-post/1555057494489.png" alt=""></p>
<p>潜意识里面，我们觉得count+=1是一个不可分割的操作整体，是原子的，即线程的切换可以发生在count+=1之前，也可以发生在count+=1之后，但是不会发生在中间，事实却不是这样。<strong>我们把一个或者多个操作在CPU执行的过程中不被中断的特性称为原子性</strong>。CPU能保证的原子操作时CPU指令级别的，而不是高级语言的操作符级别。因此，我们需要在高级语言层面保证操作的原子性来确保并发程序执行结果正确。</p>
<h1 id="BUG的源头三：编译优化带来的有序性问题"><a href="#BUG的源头三：编译优化带来的有序性问题" class="headerlink" title="BUG的源头三：编译优化带来的有序性问题"></a>BUG的源头三：编译优化带来的有序性问题</h1><p>有序性，就是指程序按照代码的先后顺序执行。编译器为了优化性能，有时候会改变程序中语句的先后顺序。例如：“a=6;b=7”编译器优化后可能变成“b=7;a=6”，这个例子中，编译器调整了语句顺序，但是不影响程序的最终结果。不过有时候编译器及解释器的优化可能导致意想不到的Bug。</p>
<p>在java领域的一个经典案例就是双重检查创建单例对象，例如下面代码：在获取实例<code>getInstance()</code>的方法中，我们首先判断instance是否为空，为空则锁定Singleton.class并再次检查instance是否为空，如果还为空则创建Singleton的一个实例。</p>
<pre><code class="java">public class Singleton {
  static Singleton instance;
  static Singleton getInstance(){
    if (instance == null) {
      synchronized(Singleton.class) {
        if (instance == null)
          instance = new Singleton();
        }
    }
    return instance;
  }
}</code></pre>
<ul>
<li>正确的逻辑是这样的：</li>
</ul>
<p>假设有两个线程A、B同时调用gentInstance()方法，他们会同时发现instance==null，于是同时对Singleton.class加锁，此时JVM保证只有一个线程能够加锁成功，另外一个线程则会处于等待状态（假设是线程B）；线程A会创建一个Singleton实例，之后释放锁，线程B被唤醒，线程B再次尝试加锁，此时是可以加锁成功，加锁成功后，线程B检查instance == null时发现，已经创建过Singleton实例了，所以线程B不会再创建一个Singleton实例。</p>
<ul>
<li>实际new是有问题的：</li>
</ul>
<p>上面正确的逻辑这看上去很完美，无懈可击，但实际上这个getInstance()方法并不完美。问题出在哪里？</p>
<p>出在new操作上面，我们以为new操作应该是：</p>
<ol>
<li>分配一块内存M；</li>
<li>在内存M上初始化Singleton对象；</li>
<li>然后M的变量地址复制给instance变量。</li>
</ol>
<p><strong>但是实际优化后的执行路径却是这样的</strong>：</p>
<ol>
<li>分配一块内存M；</li>
<li>将M的地址复制给instance变量。</li>
<li>最后在内存M上初始化Singleton对象。</li>
</ol>
<p>这样的优化会导致什么问题？我们假设A先执行getInstance()方法，当执行完指令2时恰好发生了线程切换，切换到线程B上；此时线程B也执行getInstance()方法，那么线程B在执行第一个判断时会发现instance != null，所以直接返回instance，而此时的instance是没有初始化过的，如果我们这个时候访问instance的成员变量就可能触发空指针异常。</p>
<p><img data-src="/img/in-post/1555057513742.png" alt=""></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>只要我们理解可见性、原子性、有序性在并发场景下的原理，很多并发Bug都是可以理解、可以诊断的。</p>
<p>在总结可见性、原子性、有序性的时候，提到了：</p>
<ol>
<li>缓存导致的可见性问题。</li>
<li>线程切换带来的原子性问题。</li>
<li>编译优化带来的有序性问题。</li>
</ol>
<p>这些都是硬件给我们提高程序性能的同时，带来的弊端的一方面。因此我们在使用高级语言做并发编程要了解这些优化带来的弊端，以及如何规避。关于规避的话我们除了可以使用Java自身给我们带来的一些确保并发程序正确的工具意外，也要自己合理处理代码来规避以上问题。解决这些问题的工具我下面会一一总结。</p>
<p>关于可见性、原子性、有序问题的操作系统及硬件层面的知识后面也应该会深入总结下去，以帮助我们理解和写出正确、健壮的并发程序。</p>
<p>关于文章中提到的缓存、CPU等概念可以看第一篇<a href="https://zhoulei17.github.io/2019/03/04/java-concurrency-system/" target="_blank" rel="noopener">系统知识篇</a></p>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>【基本概念篇】三、控制线程</title>
    <url>/2019/03/09/2019-3-09-java-concurreny-control-thread/</url>
    <content><![CDATA[<h1 id="控制Java线程"><a href="#控制Java线程" class="headerlink" title="控制Java线程"></a>控制Java线程</h1><h2 id="线程休眠sleep"><a href="#线程休眠sleep" class="headerlink" title="线程休眠sleep"></a>线程休眠sleep</h2><p>如果想让当前线程暂停执行一段时间并进入<strong>阻塞</strong>状态，调用Thread的静态方法sleep()。</p>
<p>在调用sleep后，当前线程会睡眠（即阻塞）。</p>
<h2 id="线程让步yield"><a href="#线程让步yield" class="headerlink" title="线程让步yield"></a>线程让步yield</h2><p>yield暗示线程调度器来做出CPU时间片切换。当调用yield时，是在建议具有相同优先级的其他线程可运行。注：实际任何机制都不能依赖于yield来控制线程的调度和执行。</p>
<h3 id="sleep与yield的区别"><a href="#sleep与yield的区别" class="headerlink" title="sleep与yield的区别"></a>sleep与yield的区别</h3><ul>
<li><p>优先级区别：</p>
<p>sleep方法暂停当前线程后，会给其他线程执行机会，不会理会其他线程的优先级；</p>
<p>但yield只会给优先级相同，或优先级更好的线程执行机会。</p>
</li>
<li><p>状态区别：</p>
<p>sleep方法会将当前线程转入阻塞状态，直到经过阻塞时间才会进入就绪状态；</p>
<p>而yield不会将线程装入阻塞状态，只是强制当前线程进入就绪状态。因此完全有可能某个线程调用yield方法暂停后，立即再次获得处理器资源被执行。</p>
</li>
<li><p>异常区别：</p>
<p>sleep方法声明抛出了InterruptedException异常，而yield方法则没有声明抛出任何异常。</p>
</li>
<li><p>可移植：</p>
<p>sleep相比yield方法有更好的可以执行，通常不建议使用yield方法控制并发线程执行。</p>
</li>
</ul>
<h2 id="优先级"><a href="#优先级" class="headerlink" title="优先级"></a>优先级</h2><p>Thread.<em>currentThread</em>().setPriority 设置线程优先级</p>
<p>getPriority()来获取现有线程的优先级</p>
<p>JDK一共分为十个优先级，定义为Thread常量的有：</p>
<pre><code class="java">    /**
     * The minimum priority that a thread can have.
     */
    public final static int MIN_PRIORITY = 1;

   /**
     * The default priority that is assigned to a thread.
     */
    public final static int NORM_PRIORITY = 5;

    /**
     * The maximum priority that a thread can have.
     */
    public final static int MAX_PRIORITY = 10;
</code></pre>
<h2 id="后台线程daemon"><a href="#后台线程daemon" class="headerlink" title="后台线程daemon"></a>后台线程daemon</h2><p>后台线程是指在程序运行时在后台提供一种通用服务的线程，一般这种线程并不属于程序中不可获取的一部分。</p>
<p>因此，</p>
<p><strong>对于后台线程来说：当程序（父线程）中止时，后台线程也会中止，既程序中止会杀死所有后台线程。</strong></p>
<p><strong>对于非后台线程来说：而所有非后台线程全部中止时，程序（父线程）才会中止。既只要有非后台线程在运行，程序就不会中止。</strong></p>
<pre><code class="java">public class SimpleDaemons implements Runnable{

    verride
    public void run() {
        // TODO Auto-generated method stub
        while(true)
        {
            try {
                TimeUnit.MILLISECONDS.sleep(100);
                System.out.println(Thread.currentThread() + &quot; &quot; + this);
            } catch (Exception e) {
                // TODO: handle exception
            }
        }
    }

    public static void main(String[] args) throws InterruptedException
    {
        for (int i = 0 ; i &lt; 10 ; i++)
        {
            Thread daemon = new Thread(new SimpleDaemons());
            daemon.setDaemon(true);
            daemon.start();
        }
        System.out.println(&quot;All daemons started&quot;);
        TimeUnit.MILLISECONDS.sleep(175);
    }

}</code></pre>
<p>输出：</p>
<pre><code class="java">All daemons started
Thread[Thread-7,5,main] thread.SimpleDaemons@33ee7f84
Thread[Thread-1,5,main] thread.SimpleDaemons@2be3518e
Thread[Thread-4,5,main] thread.SimpleDaemons@34803d73
Thread[Thread-5,5,main] thread.SimpleDaemons@7765af09
Thread[Thread-0,5,main] thread.SimpleDaemons@130cbd68
Thread[Thread-6,5,main] thread.SimpleDaemons@1c193015
Thread[Thread-2,5,main] thread.SimpleDaemons@36e52fd4
Thread[Thread-9,5,main] thread.SimpleDaemons@300ba5d1
Thread[Thread-8,5,main] thread.SimpleDaemons@41823c32
Thread[Thread-3,5,main] thread.SimpleDaemons@2a57e4d</code></pre>
<p>必须在线程启动前调用setDaemon</p>
<h2 id="加入线程join"><a href="#加入线程join" class="headerlink" title="加入线程join"></a>加入线程join</h2><p>Thread提供了让一个线程等待另一个线程完成的方法——Join方法。当在某个程序执行流中调用其他线程的join()方法时，调用线程将被阻塞，直到被join()方法加入的线程执行完成为止。</p>
<p>join()方法通常由使用线程的程序调用，以将大问题划分成很多个小问题，每个小问题分配一个线程。当所有的小问题都得到处理后，再调用主线程来进一步操作。</p>
<pre><code class="java">public class JoinThread implements Runnable{

    public static void main(String[] args) throws InterruptedException
    {
        new Thread(new JoinThread(),&quot;新线程&quot;).start();
        for(int i = 0 ; i &lt; 10; i++)
        {
            if (i == 5)
            {
                JoinThread jt = new JoinThread();
                Thread t = new Thread(jt,&quot;被join的线程&quot;);
                //main线程调用了jt的join方法，调用必须等待jt线程执行完后，才能继续往下执行
                t.start();
                t.join();
            }
            Thread.sleep(100);
            System.out.println(Thread.currentThread().getName()+ &quot; &quot; + i);
        }

    }

    verride
    public void run() {
        // TODO Auto-generated method stub
        System.out.println(Thread.currentThread().getName()+&quot; join thread&quot;);
    }
}</code></pre>
<p>输出</p>
<pre><code class="java">新线程 join thread
main 0
main 1
main 2
main 3
main 4
被join的线程 join thread
main 5
main 6
main 7
main 8
main 9</code></pre>
<h2 id="终结任务"><a href="#终结任务" class="headerlink" title="终结任务"></a>终结任务</h2><h3 id="正常终结"><a href="#正常终结" class="headerlink" title="正常终结"></a>正常终结</h3><p>当调用Future的cancel方法来终止任务，并且任务自身通过isCanceled来确定何时终止他们自己。</p>
<h3 id="在阻塞时终结任务"><a href="#在阻塞时终结任务" class="headerlink" title="在阻塞时终结任务"></a>在阻塞时终结任务</h3><p>进入阻塞状态的可能原因：</p>
<ol>
<li>通过sleep使任务进入休眠状态，这种情况下，任务在指定时间内不会运行。</li>
<li>通过wait将线程挂起，直到线程得到notify或者notifyAll消息，线程才会进入就绪状态。</li>
<li>任务在等待某个输入/输出完成。</li>
<li>任务在某个对象上调用同步方法，但是对象锁不可用。</li>
</ol>
<p>当任务进入阻塞状态时，需要终止就必须强制让这个任务跳出阻塞状态。</p>
<h3 id="中断"><a href="#中断" class="headerlink" title="中断"></a>中断</h3><p>提供给开发者控制线程中断的方式主要有如下：</p>
<ul>
<li><p>异常控制：</p>
<p>在任务在Runnable.run期间，一种结束当前任务的方式是抛出异常。当然这不是一种恰当的做法，因为从来不推荐通过异常来控制代码流程。</p>
</li>
<li><p>interrupt方法：</p>
<p>通过调用Thread类的interrupt()方法可以终止被阻塞的任务，通过这个方法将设置线程的中断状态。如果一个线程已经被阻塞，或者试图执行一个阻塞操作，那么设置这个线程的中断状态将抛出InterruptedException。</p>
<p>当抛出该异常或者该任务调用Thread.interrupted()时，中断状态将被复位。</p>
</li>
<li><p>cancel方法：</p>
<p>当调用Executor时，subimit后返回Future对象，则可以调用cancel方法来终止特定任务，并且true传给cancel()方法则，会调用该线程的interrupt方法以停止当前线程。因此cancel是一种由中断由Executor启动的单个线程的一种方式。</p>
<pre><code class="java">    public boolean cancel(boolean mayInterruptIfRunning) {
        if (!(state == NEW &amp;&amp;
              UNSAFE.compareAndSwapInt(this, stateOffset, NEW,
                  mayInterruptIfRunning ? INTERRUPTING : CANCELLED)))
            return false;
        try {    // in case call to interrupt throws exception
            if (mayInterruptIfRunning) {
                try {
                    Thread t = runner;
                    if (t != null)
                        t.interrupt();
                } finally { // final state
                    UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED);
                }
            }
        } finally {
            finishCompletion();
        }
        return true;
    }</code></pre>
</li>
</ul>
<h4 id="三种中断场景"><a href="#三种中断场景" class="headerlink" title="三种中断场景"></a>三种中断场景</h4><p>下面我们来看个示例，用来<strong>说明常见的三种不同场景下的线程处理对于中断的反应</strong>:</p>
<ul>
<li>场景1. 中断线程中sleep()方法（SleepBlocked类）</li>
<li>场景2. 中断IO阻塞（IOBlocked 类）</li>
<li>场景3. 中断synchronized方法(SynchronizedBlocked类：线程内逻辑是在在阻塞等待锁) </li>
</ul>
<pre><code class="java">/** Interrupting a blocked thread
 * @author Alonso
 *
 */
public class Interrupting {
    private static ExecutorService exec = Executors.newCachedThreadPool();
    static void test(Runnable r) throws InterruptedException {
        Future&lt;?&gt; f = exec.submit(r);
        TimeUnit.MILLISECONDS.sleep(100);
        System.out.println(&quot;Interrupting &quot; + r.getClass().getName());
        f.cancel(true);
        System.out.println(&quot;Interrupt sent to &quot;+ r.getClass().getName());
    }

    public static void main(String[] args) throws InterruptedException
    {
        test(new SleepBlocked());
        test(new IOBlocked(System.in));
        test(new SynchronizedBlocked());
        TimeUnit.SECONDS.sleep(3);
        System.out.println(&quot;Aborting with System.exit(0)&quot;);
        System.exit(0);
    }
}

class SleepBlocked implements Runnable {

    verride
    public void run() {
        try {
            TimeUnit.SECONDS.sleep(100);
        } catch (InterruptedException e) {
            System.out.println(&quot;InterruptedException&quot;);
        }
        System.out.println(&quot;Exiting SleepBlocked.run()&quot;);
    }
}

class IOBlocked implements Runnable {
    private InputStream in;

    public IOBlocked(InputStream in) {
        this.in = in;
    }

    verride
    public void run() {
        try {
            System.out.println(&quot;Waiting for read():&quot;);
            in.read();
            System.out.println(&quot;Waiting for read() after:&quot;);
        } catch (IOException e) {
            if (Thread.currentThread().isInterrupted()) {
                System.out.println(&quot;Interrupted from blocked I/O&quot;);
            } else {
                System.out.println(&quot;Other IOException from blocked I/O&quot;);
                throw new RuntimeException(e);
            }
        }finally
        {
            System.out.println(&quot;Finally,Exiting IOBlocked.run()&quot;);
        }
        System.out.println(&quot;Exiting IOBlocked.run()&quot;);
    }
}

class SynchronizedBlocked implements Runnable {
    public SynchronizedBlocked() {
        new Thread() {
            public void run() {
                f();
            }
        }.start();
    }

    verride
    public void run() {
        System.out.println(&quot;Trying to call f()&quot;);
        f();
        System.out.println(&quot;Existing SynchronizedBlocked.run()&quot;);
    }

    public synchronized void f() {
        while(true)
            Thread.yield();
    }
}</code></pre>
<p>输出：</p>
<pre><code class="java">Interrupt sent to thread.interrupt.SleepBlocked
InterruptedException
Exiting SleepBlocked.run()
Waiting for read():
Interrupting thread.interrupt.IOBlocked
Interrupt sent to thread.interrupt.IOBlocked
Trying to call f()
Interrupting thread.interrupt.SynchronizedBlocked
Interrupt sent to thread.interrupt.SynchronizedBlocked
Aborting with System.exit(0)</code></pre>
<p>从结果可以分析出：</p>
<ul>
<li><p>场景1. SleepBlocked 中断线程中sleep()方法，是<strong>可中断的示例</strong>，能够中断对sleep()的调用（或者任何要求抛出InterruptedException的调用）。</p>
</li>
<li><p>场景2.和场景3，即IOBlocked和SynchronizedBlocked是<strong>不可中断的示例</strong>，IOBlocked中在read()处阻塞而中断对此IO是无效的。同样在SynchronizedBlocked的构造方法中（main任务1获得）先获取了对象锁并且f()永远不返回即不释放锁，导致在线程内（任务2）再次调用f()申请同一个对象锁时阻塞住（因为同一个对象锁在同一个线程或者叫任务是可以被多次获得的，因此示例是演示的两个多线程征用同一把对象锁，这种叫互斥阻塞），而调用cancel尝试中断也是无效的。</p>
</li>
<li><p><strong>总结</strong>：</p>
<ul>
<li><p>能够中断对sleep()的调用，但是不能中断正在试图获取synchronized锁或者试图执行I/O操作的线程。</p>
</li>
<li><p>当线程在I/O锁住，有一个解决方式就是：关闭任务在其发生阻塞的底层资源。还有一种方法是使用NIO代替IO。</p>
</li>
</ul>
</li>
</ul>
<h4 id="关闭IO底层资源解决IO阻塞无法中断从而无法锁的问题"><a href="#关闭IO底层资源解决IO阻塞无法中断从而无法锁的问题" class="headerlink" title="关闭IO底层资源解决IO阻塞无法中断从而无法锁的问题"></a>关闭IO底层资源解决IO阻塞无法中断从而无法锁的问题</h4><p>如下示例：</p>
<pre><code class="java">public class CloseResource {

    public static void main(String[] args) throws IOException, InterruptedException {
        ExecutorService exec = Executors.newCachedThreadPool();
        ServerSocket server = new ServerSocket(8080);
        InputStream socketInput = new Socket(&quot;localhost&quot;,8080).getInputStream();
        exec.execute(new IOBlocked(socketInput));
        exec.execute( new IOBlocked(System.in));

        TimeUnit.MILLISECONDS.sleep(100);
        System.out.println(&quot;Shutting down all thread&quot;);
        exec.shutdown();

        TimeUnit.SECONDS.sleep(1);
        System.out.println(&quot;Closing &quot; + socketInput.getClass().getName());
        socketInput.close();

        TimeUnit.SECONDS.sleep(1);
        System.out.println(&quot;Closing &quot; + System.in.getClass().getName());
        System.in.close();

    }

}</code></pre>
<h4 id="NIO解决IO阻塞无法中断从而无法释放锁的问题"><a href="#NIO解决IO阻塞无法中断从而无法释放锁的问题" class="headerlink" title="NIO解决IO阻塞无法中断从而无法释放锁的问题"></a>NIO解决IO阻塞无法中断从而无法释放锁的问题</h4><p>针对IO阻塞无法中断的问题，可以通过JDK 1.4 NIO来解决：</p>
<p>下面示例两种方式中断NIO线程：</p>
<pre><code class="java">public class NIOInterruption {

    public static void main(String[] args) throws IOException, InterruptedException {

        ExecutorService exec = Executors.newCachedThreadPool();
        ServerSocket server = new ServerSocket(8080);
        InetSocketAddress isa = new InetSocketAddress(&quot;localhost&quot;, 8080);
        SocketChannel sc1 = SocketChannel.open(isa);
        SocketChannel sc2 = SocketChannel.open(isa);
        Future&lt;?&gt; f = exec.submit(new NIOBlocked(sc1));
        exec.execute(new NIOBlocked(sc2));
        exec.shutdown();

        f.cancel(true);//casuse to ClosedByInterruptException
        TimeUnit.SECONDS.sleep(1);
        sc2.close();//cause to AsynchronousCloseException
    }

}

class NIOBlocked implements Runnable {
    private final SocketChannel sc;

    public NIOBlocked(SocketChannel sc) {
        this.sc = sc;
    }

    verride
    public void run() {
        try {
            System.out.println(&quot;Waiting for read() in &quot; + this);
            sc.read(ByteBuffer.allocate(1));
        } catch (ClosedByInterruptException e) {
            // TODO Auto-generated catch block
            System.out.println(&quot;ClosedByInterruptException&quot;);
        } catch (AsynchronousCloseException e) {
            System.out.println(&quot;AsynchronousCloseException&quot;);
        } catch (IOException e) {
            throw new RuntimeException(e);
        }
        System.out.println(&quot;Exiting NIOBlocked.run() &quot; + this);
    }</code></pre>
<p>输出：</p>
<pre><code class="java">Waiting for read() in thread.sleep.nio.blocked.NIOBlocked@25531342
Waiting for read() in thread.sleep.nio.blocked.NIOBlocked@7f31a9f9
ClosedByInterruptException
Exiting NIOBlocked.run() thread.sleep.nio.blocked.NIOBlocked@25531342
AsynchronousCloseException
Exiting NIOBlocked.run() thread.sleep.nio.blocked.NIOBlocked@7f31a9f9</code></pre>
<p>*<em><code>sc2.close();</code> *</em>可以触发出异常<code>AsynchronousCloseException</code>，即可以通过关闭底层IO资源来释放锁。</p>
<p><strong><code>f.cancel(true)</code></strong>可以触发出异常<code>ClosedByInterruptException</code>，即可以直接通过中断NIO线程来释放锁。</p>
<h4 id="同一任务中是否会因为互斥阻塞问题？"><a href="#同一任务中是否会因为互斥阻塞问题？" class="headerlink" title="同一任务中是否会因为互斥阻塞问题？"></a>同一任务中是否会因为互斥阻塞问题？</h4><p>在上面例子Interrupting例子中的SynchronizedBlocked中，由于构造方法中新建的任务1与当前运行的任务2调用了方法synchronized方法<code>f()</code>，对象锁被任务1持有，任务2因此阻塞挂起，无法继续执行下去。这是针对多个不同任务获取同一对象锁而言会产生阻塞。</p>
<p>而针对同一线程对同一对象锁是可以重入的，即可以反复调用当前对象多个synchronized方法。如下示例：</p>
<pre><code class="java">public class MultiLock {

    public synchronized void f1(int count) {
        if (count-- &gt; 0) {
            System.out.println(&quot;f1() calling f2() with count &quot; + count);
            f2(count);
        }
    }

    public synchronized void f2(int count) {
        if (count-- &gt; 0) {
            System.out.println(&quot;f2() calling f1() with count &quot; + count);
            f1(count);
        }
    }

    public static void main(String[] args) {
        final MultiLock multiLock = new MultiLock();
        new Thread()  {
            public void run() { 
                multiLock.f1(10);
            }
        }.start();
    }

}</code></pre>
<p>输出：</p>
<pre><code class="java">f1() calling f2() with count 9
f2() calling f1() with count 8
f1() calling f2() with count 7
f2() calling f1() with count 6
f1() calling f2() with count 5
f2() calling f1() with count 4
f1() calling f2() with count 3
f2() calling f1() with count 2
f1() calling f2() with count 1
f2() calling f1() with count 0</code></pre>
<p>在main（）中创建了一个调用f1的Thread，然后f1()和f2()互相调用直到count变为0。</p>
<p>由于这个任务在第一次调用f1()时已经获得了multiLock对象的锁了，因此同一个任务将在对f2()调用中再次获得该索，依次类推。</p>
<p>因此总结可以这样理解：同一个任务可以调用同一个对象的锁，即可以反复调用其他synchronized方法，因为这个任务已经持有锁了。</p>
<h4 id="天然可中断的锁"><a href="#天然可中断的锁" class="headerlink" title="天然可中断的锁"></a>天然可中断的锁</h4><p>在前面Intrrupting中的不可中断的例子中看到的那样，无论在任何时刻，只要任务以不可中断的方式被阻塞，那么程序就会存在潜在的被锁住的可能性。在<strong>java 5</strong>的并发库中添加了一个特性，即<code>ReentrantLock</code>上阻塞的任务具备可以被中断的能力，这解决了synchronized方法或临界区上阻塞不可中断的缺点。</p>
<pre><code class="java">public class Interrupting2 {
    public static void main(String[] args) throws InterruptedException {
        Thread t = new Thread(new Blocked2());
        t.start();
        TimeUnit.SECONDS.sleep(1);
        System.out.println(&quot;Issuing t.interrupt&quot;);
        t.interrupt();
    }
}

class BlockedMutex {
    private Lock lock = new ReentrantLock();
    public BlockedMutex() {
        lock.lock(); // (1)
    }

    public void f() {
        try {
            lock.lockInterruptibly();
            System.out.println(&quot;lock acquired in f()&quot;);
        } catch (InterruptedException e) {
            // TODO Auto-generated catch block
            System.out.println(&quot;Interrupted from lock acquisition in f()&quot;);
        }
    }
}

class Blocked2 implements Runnable {
    BlockedMutex blocked = new BlockedMutex();

    verride
    public void run() {
        // TODO Auto-generated method stub
        System.out.println(&quot;Waiting for f() in BlockedMutex()&quot;);
        blocked.f();(2)
        System.out.println(&quot;Broken out of blocked call&quot;);
    }
}</code></pre>
<p>输出：</p>
<pre><code class="java">Waiting for f() in BlockedMutex()
Issuing t.interrupt
Interrupted from lock acquisition in f()
Broken out of blocked call</code></pre>
<p>BlockedMutex的类构造器获取当前对象中的ReentrantLock类型锁lock（1），并且不释放锁。</p>
<p>当Blocked2任务运行调用BlockedMutex对象的f()方法，并在方法内获取当前BlockedMutex自带的lock类型锁，而此时的lock被位置(1)调用锁住了，因此位置2获取锁阻塞等待。</p>
<p>但是因为lock获取方式为<code>lock.lockInterruptibly()</code>因此方式的锁阻塞可以被中断。</p>
<h3 id="检查中断"><a href="#检查中断" class="headerlink" title="检查中断"></a>检查中断</h3><p>通过上面总结可以知道主要有<strong>正常终结、阻塞时终结任务、中断方式终结任务</strong>三种终结任务的方式。其中只有在阻塞时或者进入阻塞中调用interrupt才会中断阻塞。</p>
<pre><code class="java">public class InterruptingIdiom {

    public static void main(String[] args) throws NumberFormatException, InterruptedException {
        if (args.length != 1) {
            System.out.println(&quot;usage: java InterruptingIdiom delay-in-ms&quot;);
        }
        Thread t = new Thread(new Blocked3());
        t.start();
        TimeUnit.MILLISECONDS.sleep(new Integer(1100));
        t.interrupt();
    }
}

class Blocked3 implements Runnable {
    private volatile double d = 0.0;

    verride
    public void run() {
        // TODO Auto-generated method stub
        NeedsCleanup n1 = null;
        NeedsCleanup n2 = null;
        try {
            while (!Thread.interrupted()) {
                // point(1)
                n1 = new NeedsCleanup(1);
                try {
                    System.out.println(&quot;Sleeping&quot;);
                    TimeUnit.SECONDS.sleep(1);
                    // point(2)
                    n2 = new NeedsCleanup(2);
                    try {
                        System.out.println(&quot;Calculating&quot;);
                        for (int i = 1; i &lt; 2500000; i++) {
                            d = d + (Math.PI + Math.E) / d;
                        }
                        System.out.println(&quot;Finished time-consuming operation&quot;);
                    } finally {
                        n2.cleanup();
                    }
                } finally {
                    n1.cleanup();
                }
            }
            System.out.println(&quot;Exiting via while() test&quot;);
        } catch (InterruptedException e) {
            // TODO Auto-generated catch block
            System.out.println(&quot;Exiting via InterruptedExcetion&quot;);
        }

    }
}

class NeedsCleanup {
    private final int id;

    public NeedsCleanup(int ident) {
        this.id = ident;
        System.out.println(&quot;NeedsCleanup &quot; + id);
    }

    public void cleanup() {
        System.out.println(&quot;Cleaning up &quot; + id);
    }
}</code></pre>
<ul>
<li>设置1100ms后调用interrupt输出：</li>
</ul>
<pre><code class="java">usage: java InterruptingIdiom delay-in-ms
NeedsCleanup 1
Sleeping
NeedsCleanup 2
Calculating
Finished time-consuming operation
Cleaning up 2
Cleaning up 1
NeedsCleanup 1
Sleeping
Cleaning up 1
Exiting via InterruptedExcetion</code></pre>
<p>中断发生在ponit(1)和ponit(2)之间，即在while之后sleep之前或者sleep之中，那么这个任务就会在第一次试图调用阻塞操作之前，经有InterruptedException异常退出（此时c1资源依然会在finally中被回收）。</p>
<ul>
<li>设置1000ms后调用interrupt输出：</li>
</ul>
<pre><code class="java">usage: java InterruptingIdiom delay-in-ms
NeedsCleanup 1
Sleeping
NeedsCleanup 2
Calculating
Finished time-consuming operation
Cleaning up 2
Cleaning up 1
Exiting via while() test</code></pre>
<p>中断发生在ponit(2)之后（即非阻塞操作之中），那么首先循环将判断interrupted标志位并结束掉，然后从内部try开始所有finally中的资源将以此销毁，并经由while循环条件退出。</p>
<ul>
<li><p>总结：</p>
<p>在所有需要清理对象的操作中必须要跟着try-finally，这样能够确保无论以什么方式退出（InterruptedException方式或者正常结束）需要清理的资源都会被清理掉。这在编码的时候要尤其注意。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>【基本概念篇】二、线程基本使用</title>
    <url>/2019/03/08/2019-3-08-java-concurreny-use-thread/</url>
    <content><![CDATA[<h1 id="Java线程的创建、启动"><a href="#Java线程的创建、启动" class="headerlink" title="Java线程的创建、启动"></a>Java线程的创建、启动</h1><h2 id="通过继承Thread定义任务、启动"><a href="#通过继承Thread定义任务、启动" class="headerlink" title="通过继承Thread定义任务、启动"></a>通过继承Thread定义任务、启动</h2><pre><code class="java">public class ThreadDefinition extends Thread{

    private static int id = 0;
    verride
    public void run() {
        System.out.println(id++);
    }

    public static void main(String[] args)
    {
        for (int i = 0 ; i &lt; 10 ; i++)
        {
            new ThreadDefinition().start();
        }
    }

}</code></pre>
<h2 id="通过实现Runnable接口定义任务、启动"><a href="#通过实现Runnable接口定义任务、启动" class="headerlink" title="通过实现Runnable接口定义任务、启动"></a>通过实现Runnable接口定义任务、启动</h2><pre><code class="java">public class BasictThreads {
    public static void main(String[] args){
        Thread t = new Thread(new RunnableDefinition());
        t.start();
        System.out.println(&quot;Waiting for liftOff&quot;);
    }
}
</code></pre>
<h2 id="通过实现Callable接口定义任务、启动"><a href="#通过实现Callable接口定义任务、启动" class="headerlink" title="通过实现Callable接口定义任务、启动"></a>通过实现Callable接口定义任务、启动</h2><p>使用FutureTask包装Callable，并将FutureTask作为Thread的target来创建任务、启动。</p>
<p>使用FutureTask的get()方法获取线程之后结束后的返回值。</p>
<pre><code class="java">public class CallableThread {

    public static void main(String[] args)
    {
        CallableTask ct = new CallableTask();
        FutureTask&lt;Integer&gt; ft = new FutureTask&lt;Integer&gt;(ct);
        Executor exec = Executors.newCachedThreadPool();
        exec.execute(ft);
        try {
            System.out.println(&quot;获取callable线程的返回值: &quot; + ft.get());
        } catch (InterruptedException e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
        } catch (ExecutionException e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
        }
    }

    //实际编码中用lambda表达式代替
    static class CallableTask implements Callable&lt;Integer&gt;
    {
        verride
        public Integer call() throws Exception {
            // TODO Auto-generated method stub
            return new Integer(1);
        }

    }
}
</code></pre>
<p>Callable接口功能与Runnable类似，Callable只有一个call()方法，增加两种特性：</p>
<ol>
<li>call()有返回值</li>
<li>call()可以声明抛出异常</li>
</ol>
<h2 id="三种线程创建方式对比"><a href="#三种线程创建方式对比" class="headerlink" title="三种线程创建方式对比"></a>三种线程创建方式对比</h2><p>通过集成Thread类或实现Runnable、Callable接口都可以实现多线程，不过实现Runnable接口与实现Callable接口的方式基本相同，只是Callable接口里定义的方法有返回值，可以声明抛出异常而已。因此可以将实现Runnable接口和实现Callable归为一种方式。</p>
<p>采用Runnable、Callable接口的方式创建多线程的优缺点：</p>
<ul>
<li>线程采用实现方式，还可以实现或继承其他类。</li>
<li>在这种方式下，多个线程共享同一个target对象，适合多个线程处理同一份资源的情况。体现面向对象思想。</li>
<li>劣势是，编程稍显复杂，需要访问当前线程，只能使用Thread.currentTread()方法。</li>
</ul>
<p>采用Thread类的方式创建多线程的优缺点：</p>
<ul>
<li>劣势是，继承了Thread类后，不能再继承其他类。</li>
<li>优势是，编写简单访问当前线程上下文直接调动当前方法。</li>
</ul>
<p>建议一般采用Runnable、Callable创建任务。</p>
<h2 id="通过Executor启动"><a href="#通过Executor启动" class="headerlink" title="通过Executor启动"></a>通过Executor启动</h2><pre><code class="java">public class ThreadByExecutor {

    public static void main(String[] args) {
        ExecutorService exec = Executors.newCachedThreadPool();
        for (int i = 0 ; i &lt; 5 ; i++)
        {
            exec.execute(new RunnableDefinition());
        }
        exec.shutdown();
    }
}
</code></pre>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>【目录】</title>
    <url>/2019/03/04/2019-3-04-java-concurrency-catalog/</url>
    <content><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><p>Java并发编程的博客主要分为一下五大主题：</p>
<h2 id="基本概念篇"><a href="#基本概念篇" class="headerlink" title="基本概念篇"></a>基本概念篇</h2><p>3.6 认识线程：讲下线程定义、优势，线程基本使用（创建、启动、执行）。</p>
<p>3.7 控制线程：操控线程的基本方法。</p>
<p>并发概念：这篇要分为好多个小专题来讲，主要会讲下</p>
<ul>
<li>3.8 线程的3个特征</li>
<li>3.9 内存模型  </li>
<li>3.10 互斥锁</li>
<li>3.11 线程的生命周期、线程数计算、执行原理</li>
<li>3.12 安全性</li>
<li>3.13 活跃性问题</li>
<li>3.14 性能问题</li>
<li>3.15 管程</li>
</ul>
<h2 id="线程之间的协作"><a href="#线程之间的协作" class="headerlink" title="线程之间的协作"></a>线程之间的协作</h2><ul>
<li>3.16 wait，notify、notifyAll</li>
<li>3.17 阻塞队列控制协作</li>
<li>3.18 管程Mointor（Lock&amp;Condition、synchronized）</li>
<li>3.19 信号量Semaphore</li>
<li>3.20 CountdownLatch</li>
<li>3.21 CyclicBarrier</li>
<li>3.22 Phaser</li>
<li>3.23 Exchanger</li>
<li>3.24 死锁</li>
</ul>
<h2 id="线程之间的互斥"><a href="#线程之间的互斥" class="headerlink" title="线程之间的互斥"></a>线程之间的互斥</h2><p>互斥主要是为了保证线程执行的正确性或者叫做安全性，一般采用有锁和无锁的方案。</p>
<ul>
<li>有锁：讲下synchronized、Lock、读写锁<ul>
<li>3.25 synchronzied</li>
<li>3.26 Lock，读写锁</li>
</ul>
</li>
<li>无锁：不变模式、可见保证volatile、原子保证Atomic相关。<ul>
<li>3.27 final模式</li>
<li>3.28 可见性volatile</li>
<li>3.29 原子Atomic</li>
</ul>
</li>
</ul>
<h2 id="线程之间的分工问题"><a href="#线程之间的分工问题" class="headerlink" title="线程之间的分工问题"></a>线程之间的分工问题</h2><p>主要会讲下并发线程中的并发设计模式。</p>
<ul>
<li>Executor与线程池</li>
<li>Fork/Join</li>
<li>Future</li>
<li>Guarded Susepension模式</li>
<li>Thread-Per-Message模式</li>
<li>生产者-消费者模式</li>
<li>Worker-Thread模式</li>
<li>两阶段终止模式</li>
</ul>
<h2 id="并发线程工具类"><a href="#并发线程工具类" class="headerlink" title="并发线程工具类"></a>并发线程工具类</h2><p>这个主题主要继续深入讲解各个并发工具的使用和原理，并会有锁侧重的分析这些并发工具类的源码。</p>
<ul>
<li><p>3.30 Lock</p>
</li>
<li><p>3.31 Semaphore</p>
</li>
<li><p>4.1 ReadWriteLock</p>
</li>
<li><p>4.2 原子类</p>
</li>
<li><p>4.3 Executor与线程池、阻塞队列</p>
</li>
<li><p>4.4 Future</p>
</li>
<li><p>4.5 Fork/Join</p>
</li>
<li><p>4.6 并发容器</p>
</li>
<li><p>4.7 CountDownLatch&amp;CyclicBarrier</p>
</li>
<li><p>4.8 CountDownLatch</p>
</li>
<li><p>4.9 StampedLock</p>
</li>
<li><p>4.10 CompletableFuture</p>
</li>
<li><p>4.11 CompletionService</p>
<p>等。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>【基本概念篇】一、认识进程与线程</title>
    <url>/2019/03/04/2019-3-06-java-concurrency-system/</url>
    <content><![CDATA[<p>总结Java线程基本概念之前，首先先来了解下操作系统层面的进程与线程的相关知识</p>
<h1 id="进程管理和调度"><a href="#进程管理和调度" class="headerlink" title="进程管理和调度"></a>进程管理和调度</h1><h2 id="CPU的构成与基本工作方式"><a href="#CPU的构成与基本工作方式" class="headerlink" title="CPU的构成与基本工作方式"></a>CPU的构成与基本工作方式</h2><ul>
<li><p>CPU由<strong>运算器</strong>、<strong>控制器</strong>、一系列的<strong>寄存器以及高速缓存</strong>构成。</p>
<p>运算器：主要负责指令中的算术和逻辑运算、是计算机的核心。</p>
<p>控制器：主要负责控制程序运行的流程，包括取指令、维护CPU状态、CPU与内存的交互等。</p>
<p>寄存器：主要负责指令在CPU内部处理的过程中暂存数据、地址以及指令信息的存储指令。</p>
<p>寄存器有两类：<strong>用户可见寄存器</strong>、控制寄存器。</p>
<p>其中用户可见寄存器是高级语言编译器通过算法分配使用的，以减少程序访问主存次数。</p>
<p>控制寄存器用来控制处理器的操作，由OS的特权代码使用，以控制其它程序的执行。</p>
</li>
<li><p><strong>用户可见寄存器：包括通用寄存器、数据寄存器、地址寄存器</strong></p>
<ul>
<li>数据寄存器：主要用来存放操作数</li>
<li>地址寄存器：简单来讲是用来存储数据和指令的物理地址、线性地址或者有效地址，用来某种特定方式的寻址。</li>
<li>I/O地址寄存器</li>
<li>I/O缓冲寄存器</li>
</ul>
</li>
<li><p>控制寄存器</p>
<p>控制寄存器主要有：程序计数器PC，指令寄存器IR，程序状态字PSW，中断寄存器，存储器和I/O模块控制的寄存器，因为高级语言（Java）运行时不直接参与这块的运算，因此不细讲。</p>
</li>
<li><p>高速缓存（内、外）：处于CPU和物理内存之间一般由控制器的内存管理单元（MMU：Memory Mangement Unit）管理，访问速度快鱼内存、低于寄存器。利用程序局部性原理使得高速指令处理和低速内存访问得以匹配，从而提高CPU效率。</p>
</li>
</ul>
<h2 id="进程的定义"><a href="#进程的定义" class="headerlink" title="进程的定义"></a>进程的定义</h2><p>Process(“任务”task或活动active)，进程是具有独立功能的程序关于某个数据集合上的一次运行活动，是系统进行资源分配、调度和保护的独立单位。</p>
<ul>
<li><p>进程有什么用？为什么要引入进程概念？</p>
<p>原因1.为了刻画系统的动态性，发挥系统的并发性，提高系统的资源利用率。</p>
<p>原因2.它能解决系统的“共享性”，正确描述程序执行状态。一一种“可再入”、“可再用”的程序。</p>
</li>
<li><p>进程的状态和转换</p>
<ul>
<li><p>三种进程状态：运行态、就绪态、等待态</p>
<ul>
<li><p>就绪-&gt;运行：调度程序选择一个新的程序运行</p>
</li>
<li><p>运行-&gt;就绪：</p>
<p>运行进程用完了时间片</p>
<p>运行进程被中断，因为高一优先级进程处于就绪状态</p>
</li>
<li><p>运行-&gt;等待</p>
<p>当一进程必须等待时</p>
<p>OS尚未完成服务</p>
<p>对一资源的访问尚不能进行</p>
<p>初始化I/O且必须等待结果</p>
<p>等待某一进程提供输入</p>
</li>
<li><p>等待-&gt;就绪</p>
<p>当所等待的事件发生时</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>五种进程状态：增加 创建状态、终止状态</p>
<p>NULL-&gt;新建态：创建一个子进程</p>
<p>新建态-&gt;就绪态：系统完成了进程创建操作，且当前系统的性能和内存的容量均允许。</p>
<p>运行态-&gt;终止态：一个进程到达自然结束点，或者出现无法克服的错误，或被操作系统终结，或被其他有终止权的进程所终结。</p>
<p>终止态-&gt;NULL：完成善后操作。</p>
<p>就绪态-&gt;终止态：某些操作系统允许父进程终结子进程。</p>
<p>等待态-&gt;终止态：某些操作系统允许父进程终结子进程。</p>
</li>
<li><p>七种进程状态：增加 “挂起”、“激活”状态</p>
<ul>
<li><p>为什么要有挂起状态？</p>
<p>由于进程的不断创建，系统资源已不能满足进程运行的要求，就必须把某些进程挂起，对换到磁盘镜像区中，暂时不参与进程调度，起到平滑系统操作负载的目的。</p>
</li>
<li><p>“挂起”：把一个进程从内存转到外存可能有以下几种情况：</p>
<p>阻塞-&gt;阻塞挂起：没有进程处于就绪状或就绪进程要求更多内存资源时，发生这种转换，以提交新进程或运行就绪进程。</p>
<p>就绪-&gt;就绪挂起：当有高优先级阻塞（系统认为很快就绪）进程和低优先级就绪就绪进程时，系统选择挂起低优先级就绪进程。</p>
<p>运行-&gt;就绪挂起：对<strong>抢占式</strong>系统，当<strong>高优先级</strong>阻塞挂起进程因事件出现而进入就绪挂起时，系统可能会把运行进程转到就绪挂起状态。</p>
</li>
<li><p>激活：把一个进程从外存转到内存，可能有以下几种情况：</p>
<p>就绪挂起-&gt;就绪：没有就绪进程或挂起就绪进程优先级高于就绪进程时，发生转换。</p>
<p>阻塞挂起-&gt;阻塞：当一个进程释放足够内存时，系统会把一个高优先级阻塞挂起（系统认为会很快出现所等待的事件）进程转换为阻塞状态。</p>
</li>
</ul>
</li>
</ul>
<h2 id="进程控制块"><a href="#进程控制块" class="headerlink" title="进程控制块"></a>进程控制块</h2><p>PBC是系统为了控制和管理进程设置的一个专门的数据结构，用来记录进程的外部特征，描述进程运动变化的过程。PBC是系统感知进程存在的唯一标志。一个进程与一个PCB是一一对应的。PBC主要有如下构成：</p>
<ol>
<li><p>进程描述信息</p>
<p>进程描述符、进程名、用户标识符、进程组关系</p>
</li>
<li><p>进程控制信息</p>
<p>当前状态、优先级、代码执行入口、程序的外存地址、运行统计信息（执行时间、页面调度）、进程间同步和通信、阻塞原因、进程的队列指针、进程的消息队列指针</p>
</li>
<li><p>所拥有的资源和使用情况</p>
<p>虚拟地址空间的现状、打开文件列表</p>
</li>
<li><p>CPU现场保护信息</p>
<p>寄存器值（通用、程序计数器PC、状态PSW，地址包括栈指针）</p>
<p>指向赋予该进程段/页表的指针</p>
</li>
</ol>
<p>系统负责PBC组织在一起构成PBC表，PBC表的大小决定了系统的并发度。系统有3个队列：运行队列、就绪队列、等待队列</p>
<p><img data-src="/img/in-post/1551924989622.png" alt=""></p>
<h2 id="进程的要素"><a href="#进程的要素" class="headerlink" title="进程的要素"></a>进程的要素</h2><ul>
<li>构成：进程程序、进程数据、栈、进程控制块（PBC） 构成。</li>
</ul>
<p><img data-src="/img/in-post/1551925210276.png" alt=""></p>
<ul>
<li><p>进程上下文</p>
<p>进程本身+运行环境对进程执行活动全过程的静态描述。由进程的用户地址空间内容、硬件寄存器内容、进程相关的核心数据结构组成。</p>
<ul>
<li>用户级上下文：进程的用户地址空间，包括用户正文段、用户数据段、和用户栈。</li>
<li>寄存器级上下文：PSW寄存器、处理器状态寄存器、栈指针、通用寄存器的值。</li>
<li>系统级上下文：静态部分（PCB和资源表格）、动态部分（核心栈）</li>
</ul>
</li>
<li><p>进程上下文切换</p>
<p>让处于运行态的进程中断运行，让出处理器，这时要做一次进程上下文切换，即保存老进程状态而装入被保护了的新进程的状态，以便新进程运行。步骤：</p>
<ul>
<li>保存被中断进程的处理器现场信息</li>
<li>修改被中断进程的进程控制块的有关信息，如进程状态等。</li>
<li>把被中断进程的进程控制块加入有关队列。</li>
<li>选择下一个占有处理器运行的进程。</li>
<li>修改被选中进程的进程控制块的有关信息。</li>
<li>根据被选中进程设置操作系统用到的地址转换和存储保护信息。</li>
<li>根据被选中进程恢复处理器现场。</li>
</ul>
</li>
</ul>
<h2 id="进程的控制"><a href="#进程的控制" class="headerlink" title="进程的控制"></a>进程的控制</h2><p>处理器管理的一个主要工作时对进程控制，进程控制是系统使用一些具有特定功能的程序段来创建、撤销进程以及完成进程各个状态的转换，从而达到多进程并发高效率并发执行和协调、实现资源共享的目的。</p>
<p>包括：<strong>创建进程、阻塞进程、唤醒进程、挂起进程、激活进程、终止进程和撤销进程等</strong>。</p>
<h3 id="原语：进程控制的实现方式"><a href="#原语：进程控制的实现方式" class="headerlink" title="原语：进程控制的实现方式"></a>原语：进程控制的实现方式</h3><ul>
<li><p>进程的控制和管理是由操作系统的原语来实现的。原语在操作系统的管态下执行、完成操作系统特定功能的过程。</p>
</li>
<li><p>原语与机器指令类似、特点是执行过程中不允许被中断，是一个不可分割的基本单位，原语的执行时顺序的而不是并发的。</p>
</li>
<li><p>一种原语的实现方式是以系统调用方式提供原语接口，且采用<strong>屏蔽中断</strong>的方式来实现原语功能，以保证原语操作不被打断的特性。</p>
</li>
</ul>
<h3 id="进程的创建"><a href="#进程的创建" class="headerlink" title="进程的创建"></a>进程的创建</h3><ul>
<li>创建方式：（1）由系统程序模块统一创建（2）由父进程创建</li>
<li>创建过程：<ul>
<li>父进程建子进程时，系统在进程表中增加一项，并从PCB池中取一个空白PCB。</li>
<li>为新进程的进程映像分配地址空间。传递环境变量，构造共享地址。</li>
<li>为新进程分配资源，除内存空间外，还有其他各种资源。</li>
<li>查找辅存，找到进程正文段并装到正文区。</li>
<li>初始化进程控制块，为新进程分配进程标识符，初始化PSW。</li>
<li>加入就绪队列，将进程投入运行。</li>
<li>通知操作系统的某些模块，如记账程序、性能监控程序。</li>
</ul>
</li>
</ul>
<h3 id="进程的阻塞"><a href="#进程的阻塞" class="headerlink" title="进程的阻塞"></a>进程的阻塞</h3><p><img data-src="/img/in-post/1551926911639.png" alt=""></p>
<ul>
<li>阻塞原语在一个进程期待某一事件（比如键盘输入数据、写盘）发生，但发生条件尚不具备，被该进程调用来阻塞自己。</li>
<li>阻塞原语在阻塞一个进程时，由于该进程正处于执行状态，故应先中断处理机和保存该进程CPU现场，保存现场信息到PSW。</li>
<li>然后，将被阻塞进程设置“阻塞”状态后插入等待队列中，再转进程调度程序选择新的就绪进程投入运行。</li>
</ul>
<h3 id="进程唤醒"><a href="#进程唤醒" class="headerlink" title="进程唤醒"></a>进程唤醒</h3><p><img data-src="/img/in-post/1551927138694.png" alt=""></p>
<ul>
<li>一种是由系统进程唤醒。系统进程统一控制事件的发生并将“事件发生”这一消息通知等待队列，从而使得该进程因等待时间已发生而进程就绪队列。</li>
<li>另一种是由事件发生进程唤醒。事件发生进程和被唤醒进程之间是合作关系。因此，唤醒原语既可被系统进程调用，也可被事件发生进程调用。</li>
</ul>
<h3 id="进程撤销"><a href="#进程撤销" class="headerlink" title="进程撤销"></a>进程撤销</h3><ol>
<li><p>以下情况导致进程被撤销：</p>
<ul>
<li>进程已完成所要求的功能而正常终止。</li>
<li>由于某种错误导致非正常终止。</li>
<li>祖先进程要求撤销子进程。</li>
</ul>
</li>
<li><p>撤销原语终止进程具体步骤：</p>
<p><img data-src="/img/in-post/1551927619381.png" alt=""></p>
<ul>
<li>根据撤销进程标识号，从相应队列中找到它的PCB；</li>
<li>将该进程拥有的资源归还给父进程或操作系统；</li>
<li>若该进程拥有子进程，应先撤销它所有子孙进程，以防止他们脱离控制。</li>
<li>撤销进程出队，将它的PCB归还给PCB池。</li>
</ul>
</li>
</ol>
<h3 id="进程的挂起和激活"><a href="#进程的挂起和激活" class="headerlink" title="进程的挂起和激活"></a>进程的挂起和激活</h3><ul>
<li><p>挂起原语执行过程：</p>
<p>检查被挂起进程的状态，若处于活动就绪态就修改为挂起就绪，若处于阻塞态，则修改为挂起阻塞态。</p>
<p>被挂起进程PCB的非常驻部分要交换到磁盘交换区。</p>
</li>
<li><p>激活原语执行过程：</p>
<p>激活原语的主要工作：把进程PCB非常驻部分调进内存，修改它的状态，挂起等待态改为等待态，挂起就绪态改为就绪态，排入相应队列中。</p>
<p>挂起原语既可由进程自己也可由其他进程调用，但激活原语却只能由其他进程调用。</p>
</li>
</ul>
<h2 id="处理器调度"><a href="#处理器调度" class="headerlink" title="处理器调度"></a>处理器调度</h2><p>这一部分主要说处理器级别的调度以及处理器调度与进程调度的区别，以及高级、中级、调度模式，与进程状态转换，以及处理器的调度模型。详细略。</p>
<h1 id="线程的定义"><a href="#线程的定义" class="headerlink" title="线程的定义"></a>线程的定义</h1><h2 id="操作系统的线程定义"><a href="#操作系统的线程定义" class="headerlink" title="操作系统的线程定义"></a>操作系统的线程定义</h2><ul>
<li>引入线程的基本目的是将进程以更细粒度加以切分，以低开销进一步提高系统的并发度。</li>
<li>所谓线程，有的系统称之为轻量级进程，是进程中的一个运行实体，作为CPU调度单位。</li>
<li>在多线程系统中，资源分配的单位，或是资源的拥有者还是进程。</li>
</ul>
<h3 id="线程的内容"><a href="#线程的内容" class="headerlink" title="线程的内容"></a>线程的内容</h3><ul>
<li>线程是进程的一条执行路径，它包含独立的堆栈和CPU寄存器状态，每个线程共享其所附属的进程的所有资源，包括打开的文件、页表（因此也就是共享整个用户态地址空间）、信号标识及动态分配的内存等等。</li>
<li>线程是属于进程的，线程运行在进程空间内，同一进程所产生的线程共享同一物理内存空间，当进程退出时该进程所产生的线层都会被强制退出并清除。</li>
<li>线程有生命周期，即它由创建而产生，由撤销而消亡。</li>
</ul>
<h3 id="线程的结构"><a href="#线程的结构" class="headerlink" title="线程的结构"></a>线程的结构</h3><ul>
<li><p>传统进程与多线程进程模型</p>
<ul>
<li><p>在传统进程模型中，进程控制块（PCB）纪录进程的所有信息，进程拥有一个虚地址空间，一个用户栈用于执行用户程序，一个核心栈用于执行核心程序。</p>
</li>
<li><p>在多线程进程模型中，除了进程控制块和进程虚空间外，每个线程拥有一个线程控制块TCB，每个线程都有一个用户栈和核心栈。</p>
<p><img data-src="/img/in-post/image-20190307222634901-1968817.png" alt=""></p>
</li>
</ul>
</li>
<li><p>线程控制块</p>
<ul>
<li>线程标识信息</li>
<li>线程运行状态（如运行、就绪等）和调度优先级等调度信息。</li>
<li>分别在用户态和核心态下使用的两个栈。用于保存现场信息、子程序局部变量等。</li>
<li>一个线程关联的私有存储区。</li>
<li>与进程描述信息的连接信息。进程内的每个线程都共享进程描述信息，如地址空间、使用资源等。</li>
</ul>
</li>
</ul>
<h2 id="进程与线程的联系和区别"><a href="#进程与线程的联系和区别" class="headerlink" title="进程与线程的联系和区别"></a>进程与线程的联系和区别</h2><ul>
<li>进程是资源分配的基本单元。进程也是抢占处理机的调度单位，它拥有一个完整虚拟地址空间。而线程与资源分配无关，它属于某一个进程，并与进程内的其他线程一起共享进程的资源。</li>
<li>当进程发生调度时，不同的进程拥有不同的虚拟地址空间，而同一进程内的不同线程共享同一地址空间。</li>
<li>线程只由相关堆栈寄存器和线程控制块组成。寄存器可被用来存储线程内的局部变量，但不能存储其他线程的相关变量。</li>
<li>进程切换涉及到有关资源指针保存以及地址空间变化等问题；线程切换时，由于不同线程共享资源和地址空间，将不涉及资源信息的保存和地址变化问题，从而减少操作系统的开销。而且，进程的调度与切换都是由操作系统内核完成，而线程则即可由操作系统内核完成，也可由用户程序进行。</li>
<li>进程间的关系比较疏远。各个进程是在自己独有的地址空间内进行，不但寄存器和堆栈是独有的，动态数据栈、静态数据区和程序代码也相互独立。而线程间的关系则要紧密得多，虽然各线程为保持自己的控制流而独有寄存器和堆栈，但由于两线程从属同一进程他们共享同一地址空间，所以动态堆、静态数据区及程序代码为各线程共享。</li>
</ul>
<h2 id="线程的实现"><a href="#线程的实现" class="headerlink" title="线程的实现"></a>线程的实现</h2><ol>
<li><p>用户级线程</p>
<ul>
<li>用户线程是在没有操作系统内核的支持下，完全在用户级提供一个库程序来实现多线程。这些库提供了创建、同步、调度与管理线程的所有功能，无需操作系统特别支持。</li>
<li>由于对线程的所有操作都不涉及内核，因此，用户级的线程创建、结束、调度、线程保护与切换开销非常少。</li>
<li>与线程相关的控制结构TCB保存在目态空间并由运行系统维护，由于线程对操作系统不可见，系统调度仍以进程为单位。</li>
<li><img data-src="/img/in-post/image-20190307231435487.png" alt=""></li>
</ul>
</li>
<li><p>核心级线程</p>
<ul>
<li><p>核心级线程是由操作系统支持实现的线程，操作系统维护核心级线程的各种管理表格，负责线程在处理机上的调度和切换，线程是CPU调度的基本单位。</p>
</li>
<li><p>操作系统提供了一些列系统调用界面，让用户程序请求操作系统进行线程创建、结束、同步等操作。</p>
</li>
<li><p><img data-src="/img/in-post/image-20190307231814540.png" alt=""></p>
</li>
</ul>
</li>
</ol>
<h2 id="线程的优势"><a href="#线程的优势" class="headerlink" title="线程的优势"></a>线程的优势</h2><ol>
<li><p>从操作系统看进程与线程的对比看线程的优势有如下</p>
<ul>
<li><p>快速的关联切换</p>
<p>由于操作系统级的进程独占自己的虚地址空间，调度进程时，系统必须交换地址空间，因而进程切换时间长。在同一地址内的多个线程共享同一地址空间，因而能使线程快速切换。</p>
</li>
<li><p>系统额外开销小</p>
<p>对多个进程的管理（创建、调度等）有比较大的系统开销。在需要动态创建新进程应用中，这种开销比较显著。而对线程的管理虽然也会有系统开销，但比进程小得多。</p>
</li>
<li><p>通信很容易实现</p>
<p>为了实现协作，进程或线程之间需要进行数据交换。对于自动共享同一地址空间的各线程来说，所有的全局数据都可以访问，因而不需要什么特殊手段就能实现数据共享。而进程之间的通信要复杂的多。</p>
</li>
<li><p>线程个数比进程个数多得多</p>
<p>许多多任务系统限制用户进程总数，这对许多并发应用来说远远不够。在多线程系统中，虽然在线程总数限额，但个数多得多。</p>
</li>
</ul>
</li>
<li><p>从多线程在高级语言应用层面的优势来说有如下：</p>
<ul>
<li><p>发挥了多处理器的强大能力</p>
<p>即使在单核处理器系统上也能获得更高的吞吐率。多线程系统中不仅能获得更高的吞吐率，更能提高硬件资源的利用率。</p>
</li>
<li><p>建模的简单性</p>
<p>使用线程，可以将复杂并且异步的工作流进一步分解为一组简单并且同步的工作流，每个工作流在一个单独的线程中运行，并在特定的同步位置进行交互。例如Servlet不需要了解有多少请求在同一时刻要被处理，也不需要了解套接字的输入流和输出流是否被阻塞。</p>
</li>
<li><p>异步事件的简化处理</p>
<p>在同步I/O的并发系统下，单线程会阻塞影响处理后续请求。为了避免这个问题单线程服务器必须使用非阻塞I/O，这种I./O复杂性远远高于同步I/O，且容易出错。然后如果每个请求都有自己的处理线程，那么在处理某个请求时发生的阻塞将不会影响其他线程。</p>
<p>操作系统提供了一些高校的方法来实现多路I/O，例如Unix的select和poll等系统调用，要调用这些方法，Java类库提供了非阻塞I/O包（java.nio）。</p>
</li>
</ul>
</li>
</ol>
<h2 id="线程的风险"><a href="#线程的风险" class="headerlink" title="线程的风险"></a>线程的风险</h2><ul>
<li><p>安全性问题</p>
<p>安全性问题也即并发线程执行的正确性（或有序性）问题，后面章节会通过有锁和无锁的方案来讲解如果解决线程的安全性问题。</p>
</li>
<li><p>活跃性问题</p>
<p>在并发线程互斥场景下，由于线程可能存在依赖关系因此互斥锁之间可能会产生死锁、活锁、饥饿等活跃性问题。</p>
</li>
<li><p>性能问题</p>
<p>与活跃性相关的是性能问题，一方面多线程下会频繁出现线程上下文切换，这种操作将带来极大的开销：保存和恢复执行上下文，丢失局部性，并且CPU时间将更多地花在线程调度而不是线程运行上。另一方面，当线程共享数据时，必须使用同步机制，而这些机制往往会抑制编译器优化，是内存缓存区中的数据无效，以及增加共享内存总线的同步流量。所以这两方面因素都会带来额外的性能开销，后面章节会单独讲如何分析和减少这些开销。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
        <tag>进程</tag>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title>【开篇】-全景图</title>
    <url>/2019/02/27/2019-2-27-java-concurrency-overview/</url>
    <content><![CDATA[<h1 id="Java并发编程知识总结——开篇词"><a href="#Java并发编程知识总结——开篇词" class="headerlink" title="Java并发编程知识总结——开篇词"></a>Java并发编程知识总结——开篇词</h1><p>这篇博客是开始总结Java并发的开篇，主要说下下面总结Java并发编程相关知识的思路、呈现出自己理解的Java并发知识的全景图，为后面Java并发知识总结的复习提供线索和记忆脉络。主要学习和借鉴的主要资料有：《极客时间》并发编程专栏、《Java并发实战》等。</p>
<h1 id="Java并发编程总结思路"><a href="#Java并发编程总结思路" class="headerlink" title="Java并发编程总结思路"></a>Java并发编程总结思路</h1><ul>
<li><p>之前有粗有细的看了一遍《Java并发实战》，看完后过段时间又全部忘记了；究其原因，是因为没有看到Java并发的全局，只看到了局部零散的知识点，记住的是点，难有线和面。因此需要从一个个单一的知识和技术中“跳出来”，建立一张全景图。</p>
</li>
<li><p>并发编程领域主要可以抽象成<strong>三个核心问题：分工、同步、互斥</strong></p>
</li>
</ul>
<ol>
<li><p>分工：</p>
<p>  在多核处理器时代，利用多核处理优势，将一个大的任务拆解成一个个小任务分工去完成提高效率。比如要建一条马路，划分成不同的任务：打地基、铺路、铺砖、土建等不同的子任务、分工去完成，提供了工作的效率（性能）。抽象到Java并发上，比如：生产者-消费者模式、Fork/Join、Future（同异步分工协同）等。</p>
</li>
<li><p>同步（协作）：</p>
<p>  在分工的基础上，子任务之间可能存在依赖关系，比如在造路过程中，土建完成之后需要通知铺路小组去完成铺路，这就是子任务之间的同步。</p>
<p>  像这类问题抽象到Java并发上就是：<strong>一个线程执行完成了一个任务、如何通知执行后续任务的线程开工</strong>的问题。Java提供的Future、同步工具类（CountDownLatch、Notify机制、栏栅CyclicBarrier）等都是解决同步问题的工具。</p>
<p>  工作中遇到的线程协作问题，基本可以描述成：<strong>当某个条件不满足时，线程需要等待，当某个条件满足时，线程需要被唤醒执行</strong>。</p>
</li>
<li><p>互斥（安全性）：</p>
<p>  分工、同步主要强调的是性能，而并发程序里还有一部分关于正确性的的问题，叫<strong>“线程安全”</strong>。</p>
<p>  并发程序里多个线程同时访问同一个共享变量的时候，结果是不确定的。不确定意味着可能正确，也可能错误，事先是不不确定的。而不确定的主要源头是<strong>可见性问题</strong>、<strong>有序性问题</strong>、和<strong>原子性问题</strong>。为了解决这三个问题，Java语言引入内存模型，内存模型提供了一系列的规则，利用这些规则，可以避免可见性问题、有序性问题，但还是不足以完全解决线程安全问题。解决线程安全问题的核心方案还是互斥。</p>
<p>  <strong>互斥，指同一时刻，只允许一个线程访问共享变量</strong></p>
<p>  互斥的核心就是锁，Java中的synchronized、SDK里的各种Lock都能解决互斥问题。虽说锁解决了安全问题，但同时也带来了性能问题，如何保证安全性的同时有能尽可能提高性能呢？</p>
<p>  可以分场景优化，Java SDK里提供ReadWriteLock、StampedLock就可以优化读多写少场景下的锁性能。当然还可以使用无锁的数据结构，例如Java SDK里提供的原子类都是基于<strong>无锁技术</strong>实现的。</p>
<p>  除此之外，还有一些其他的方案，原理是不共享变量或者变量只允许读。这方面，Java提供了ThreadLocal和final关键字，还有一种Copy-on-write模式。</p>
</li>
</ol>
<p>​    </p>
<h1 id="Java并发编程全景图"><a href="#Java并发编程全景图" class="headerlink" title="Java并发编程全景图"></a>Java并发编程全景图</h1><ul>
<li><p>主要根据《极客时间》并发编程专栏的全景图的基础上加上自己的理解补充完善出来的。后面总结主要会围绕全景图的脉络并以全景图的部分和一个标题分支来命名博客标题。这样我觉得会更方便记忆和查找。</p>
</li>
<li><p>后面全景图会根据反复阅读《并发编程实战》来补充更新完善。</p>
<p><img data-src="/img/in-post/java-concurreny-overview.png" alt=""></p>
</li>
<li><p>并发概念</p>
<p><img data-src="/img/in-post/java-concurrency-concept.png" alt=""></p>
</li>
<li><p>并发工具</p>
<p><img data-src="/img/in-post/java-concurrency-tools.png" alt=""></p>
</li>
</ul>
<p>（图片不知道能不能看清楚，思维导图附件我会放到我的博客后台根目录下的xmind目录下）。</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>【Java集合】-LinkedHashMap</title>
    <url>/2019/01/31/2019-1-31-java-collection-LinkedHashMap/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>在大部分情况下，只要不涉及线程安全且没有特殊要求，都推荐使用HashMap作为键值对存储数据结构。但是HashMap不具备一个特征就是：迭代HashMap的顺序并不是HashMap放置的顺序，也就是无序的。HashMap的这一缺点往往会带来困扰，因为有些场景我们期待有个有序的Map，例如需要实现一个某种过期策略的缓存。这时候应该使用LinkedHashMap，它在遍历时保持了与插入时一致的熟悉，虽然增加了时间和空间上的消耗，但是通过维护一个运行与所有条目的双向链表，LinkedHashMap保证了元素迭代的顺序。类定义</p>
<p><code>public class LinkedHashMap&lt;K,V&gt;
    extends HashMap&lt;K,V&gt;
    implements Map&lt;K,V&gt;</code></p>
<p>可以看到其核心算法继承HashMap。</p>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><ul>
<li>数据节点定义<pre><code class="java">  static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; {
      Entry&lt;K,V&gt; before, after;
      Entry(int hash, K key, V value, Node&lt;K,V&gt; next) {
          super(hash, key, value, next);
      }
  }</code></pre>
</li>
</ul>
<p>LinkedHashMap的数据节点定义 继承了HashMap的数据节点Node&lt;K,V&gt;。</p>
<p>新增：before 、after两个指针，用来维护插入顺序。</p>
<p>用图来列一下：</p>
<table>
<thead>
<tr>
<th>LinkedHashMap的节点Entry&lt;K,V&gt;定义</th>
</tr>
</thead>
<tbody><tr>
<td>Entry&lt;K,V&gt; before（新增）</td>
</tr>
<tr>
<td>Entry&lt;K,V&gt; after（新增）</td>
</tr>
<tr>
<td>int hash</td>
</tr>
<tr>
<td>K key</td>
</tr>
<tr>
<td>V value</td>
</tr>
<tr>
<td>Node&lt;K,V&gt; next</td>
</tr>
</tbody></table>
<p>​        </p>
<ul>
<li>LinkedHashMap定义</li>
</ul>
<pre><code class="java">    /**
     * The head (eldest) of the doubly linked list.
     */
    transient LinkedHashMap.Entry&lt;K,V&gt; head;

    /**
     * The tail (youngest) of the doubly linked list.
     */
    transient LinkedHashMap.Entry&lt;K,V&gt; tail;

    final boolean accessOrder;
</code></pre>
<p>head是双向链表的头，tail是双向链表的尾。</p>
<p>accessOrder 表示：</p>
<ol>
<li>false，所有的Entry按照插入的顺序排列。</li>
<li>true，所有的Entry按照访问的顺序排列。</li>
</ol>
<h2 id="初始化LinkedHashMap"><a href="#初始化LinkedHashMap" class="headerlink" title="初始化LinkedHashMap"></a>初始化LinkedHashMap</h2><pre><code class="java">    public LinkedHashMap() {
        super();
        accessOrder = false;
    }</code></pre>
<p>super()调用父类HashMap()</p>
<pre><code class="java">    public HashMap() {
        this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
    }</code></pre>
<h2 id="源码算法分析"><a href="#源码算法分析" class="headerlink" title="源码算法分析"></a>源码算法分析</h2><h3 id="新增-修改元素"><a href="#新增-修改元素" class="headerlink" title="新增/修改元素"></a>新增/修改元素</h3><p>先来看一段代码：</p>
<pre><code class="java">    public static void main(String[] args)
    {
        LinkedHashMap&lt;String,String&gt; linkedHashMap = new LinkedHashMap&lt;String,String&gt;();
        linkedHashMap.put(&quot;111&quot;, &quot;111&quot;);
        linkedHashMap.put(&quot;222&quot;, &quot;222&quot;);
        System.out.println(linkedHashMap);

    }</code></pre>
<p>put操作调用的还是HashMap的put方法，然后利用多态特性再去调用子类LinkedHashMap：</p>
<pre><code class="java">    /**
     * Implements Map.put and related methods
     *
     * @param hash hash for key
     * @param key the key
     * @param value the value to put
     * @param onlyIfAbsent if true, don&#39;t change existing value
     * @param evict if false, the table is in creation mode.
     * @return previous value, or null if none
     */
    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
        if ((p = tab[i = (n - 1) &amp; hash]) == null)
            tab[i] = newNode(hash, key, value, null);//1.
        else {
                ...
            }
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e); //2.
                return oldValue;
            }
        }
        ++modCount;
        if (++size &gt; threshold)
            resize();
        afterNodeInsertion(evict);//3.
        return null;
    }</code></pre>
<ol>
<li><p>在新增或其他创建节点操作时会调用子类覆写的newNode方法，见源码</p>
<pre><code class="java">    Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; e) {
        LinkedHashMap.Entry&lt;K,V&gt; p =
            new LinkedHashMap.Entry&lt;K,V&gt;(hash, key, value, e);
        linkNodeLast(p);
        return p;
    }</code></pre>
<p>其中当创建Node的子类Entry时，同步调用<code>linkNodeLast(p)</code>方法，该方法是创建、修改的LinkedHashMap元素时的核心方法：</p>
<pre><code class="java">    // link at the end of list
    private void linkNodeLast(LinkedHashMap.Entry&lt;K,V&gt; p) {
        LinkedHashMap.Entry&lt;K,V&gt; last = tail;
        tail = p;
        if (last == null)
            head = p;
        else {
            p.before = last;
            last.after = p;
        }
    }</code></pre>
<p>如上代码，尾部节点为last=tail，tail=p，然后把p与last连接起来。如果last是null，说明链表中还没元素，即说明LinkedHashMap是空，把p作为head和tail。</p>
</li>
</ol>
<ol start="2">
<li>在把值value保存到e节点后，调用子类<code>afterNodeAccess(e);</code>把加入节点e保存到LinkedHashMap的双向链表中。<code>afterNodeAccess(e)</code>的源码分析，下面马上介绍。</li>
</ol>
<ol start="3">
<li><p>每次在put完Map完中的元素后，调用子类<code>afterNodeInsertion(boolean evict)</code>来删除eldest元素。</p>
<p>源码：</p>
<pre><code class="java">    void afterNodeInsertion(boolean evict) { // possibly remove eldest
        LinkedHashMap.Entry&lt;K,V&gt; first;
        if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) {
            K key = first.key;
            removeNode(hash(key), key, null, false, true);
        }
    }</code></pre>
</li>
</ol>
<p>   下面着重分析下<code>afterNodeAccess(e)</code>，该方法主要是把新增修改过的节点e移动到顺序双链表的尾部，看源码：</p>
<pre><code class="java">   void afterNodeAccess(Node&lt;K,V&gt; e) { // move node to last
       LinkedHashMap.Entry&lt;K,V&gt; last;
       if (accessOrder &amp;&amp; (last = tail) != e) {
           LinkedHashMap.Entry&lt;K,V&gt; p =
               (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after;
           p.after = null;
           if (b == null)// 1.
               head = a;
           else
               b.after = a;
           if (a != null)
               a.before = b;
           else
               last = b;
           if (last == null)
               head = p;
           else {
               p.before = last;
               last.after = p;
           }
           tail = p;
           ++modCount;
       }
   }</code></pre>
<pre><code>将新修改过的节点(p)移到双项链表的队尾。b是p的前置节点，a是p的后置节点。

![](/img/in-post/1549007671676.png)</code></pre><p>   下面说下详细步骤：</p>
<ol>
<li><p>如果b是空，则把a作为链表头节点；否则把b的after指针指向a。</p>
</li>
<li><p>如果a是空，则把b设为last节点；否则把a的before指针指向b。</p>
</li>
<li><p>如果last节点为空，说明p的前后节点都是空，则p作为链表头head；</p>
<p>否则把p移动last的后面，作为链表的最后一个节点。</p>
</li>
</ol>
<h3 id="读取元素"><a href="#读取元素" class="headerlink" title="读取元素"></a>读取元素</h3><p>看源码</p>
<pre><code class="java">    public V get(Object key) {
        Node&lt;K,V&gt; e;
        if ((e = getNode(hash(key), key)) == null)
            return null;
        if (accessOrder)
            afterNodeAccess(e);
        return e.value;
    }</code></pre>
<p>首先直接调用父类getNode直接查找元素（与HashMap get调用的方法一样），获取到查找的元素，</p>
<p>然后看<code>accessOrder</code> = true说面顺序双向链表的顺序是访问的顺序，因此需要调用afterNodeAccess(e)把刚刚调用的e放到链表尾，以此保持双向链表最常访问的顺序（头部是最不常访问的，尾部是最常访问的）。</p>
<h3 id="删除元素"><a href="#删除元素" class="headerlink" title="删除元素"></a>删除元素</h3><p>在调用HashMap的删除</p>
<pre><code class="java">    void afterNodeRemoval(Node&lt;K,V&gt; e) { // unlink
        LinkedHashMap.Entry&lt;K,V&gt; p =
            (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after;
        p.before = p.after = null;
        if (b == null)
            head = a;
        else
            b.after = a;
        if (a == null)
            tail = b;
        else
            a.before = b;
    }</code></pre>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>LinkedHashMap比HashMap多维护了一个双向链表，用来维持元素访问和插入顺序，遍历时就按照访问和插入的顺序访问双向链表。其他特性与HashMap一致 见 <a href="https://zhoulei17.github.io/2019/01/20/java-collection-HashMap/" target="_blank" rel="noopener">[JAVA基础-集合3:HashMap]</a> 。</p>
]]></content>
      <categories>
        <category>Java</category>
        <category>集合</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Collection</tag>
        <tag>集合</tag>
        <tag>LinkedHashMap</tag>
      </tags>
  </entry>
  <entry>
    <title>【数据结构与算法】Java中Map用到的数据结构:红黑树</title>
    <url>/2019/01/31/2019-2-1-java-collection-red-black-tree/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>为什么会单独拿出一个篇幅总结介绍下红黑树？在HashMap的哈希冲突后，同一个数组下的节点会变成一个链表，而链表数量一旦到达8个会将链表数化成红黑树以提高查找性能。</p>
<p>TreeMap 则是基于红黑树的一种提供顺序访问的Map（这里并不是指LinkedHashMap的插入访问顺序），提供时间法再度是logn的查找时间。</p>
<p>因此本文，先单独介绍下红黑树算法的相关内容，以方面后面专门讲解的HashMap树化操作和TreeMap的介绍。</p>
<h2 id="二叉顺序树"><a href="#二叉顺序树" class="headerlink" title="二叉顺序树"></a>二叉顺序树</h2><h2 id="平衡二叉树"><a href="#平衡二叉树" class="headerlink" title="平衡二叉树"></a>平衡二叉树</h2><h2 id="红黑树"><a href="#红黑树" class="headerlink" title="红黑树"></a>红黑树</h2><h3 id="红黑树解决的问题"><a href="#红黑树解决的问题" class="headerlink" title="红黑树解决的问题"></a>红黑树解决的问题</h3><h3 id="红黑树的规则定义"><a href="#红黑树的规则定义" class="headerlink" title="红黑树的规则定义"></a>红黑树的规则定义</h3><h3 id="红黑树的操作"><a href="#红黑树的操作" class="headerlink" title="红黑树的操作"></a>红黑树的操作</h3>]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>Collection</tag>
        <tag>算法</tag>
        <tag>java红黑树</tag>
      </tags>
  </entry>
  <entry>
    <title>【Java集合】-HashMap</title>
    <url>/2019/01/20/2019-1-20-java-collection-HashMap/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Hashtable、HashMap、TreeMap都是最常见的一些Map实现，是以键值对的形式存储和操作数据的容器类型。</p>
<p>Hashtable：早期java类库提供的一个 哈希表 实现，同步的，不支持null键和值，由于同步开销，很少被推荐使用。</p>
<p>HashMap：应用更加广泛的哈希表的实现，行为大致与Hashtable一致。主要区别是HashMap不是同步的，支持null键和值等。通常情况下，HashMap进行put、get可以达到常数时间的性能，所以它是绝大部分利用键值对存取场景的首选。</p>
<p>TreeMap：则是基于红黑树的一种提供顺序访问的Map，get put remove之类的操作都是O(log(n))的时间复杂度，具体熟悉由Comparator来决定。</p>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><ul>
<li>桶数组（哈希表）</li>
</ul>
<p>桶数组(Buckets)：数组（Node&lt;K,V&gt; table）和链表结合组成的复合结构，数组被分成一个个桶（bucket），通过hash值决定键值对在这个数组的寻址；hash值相同的键值对，则以链表形式存储，如下面的示意图。如果链表大小超过阈值(TREEIFY_THRESHOLD,8),图中的链表就会被改造成树形结构。 </p>
<p><img data-src="/img/in-post/image20190122234040237.png" alt=""></p>
<ul>
<li><p>数据节点定义</p>
<pre><code class="java">static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {
    final int hash;
    final K key;
    V value;
    Node&lt;K,V&gt; next;
    ...
}</code></pre>
</li>
</ul>
<p>可见是个单向链表节点，而链表数组的定义如下</p>
<ul>
<li><p>链表数组</p>
<pre><code class="java">    /**
     * The table, initialized on first use, and resized as
     * necessary. When allocated, length is always a power of two.
     * (We also tolerate length zero in some operations to allow
     * bootstrapping mechanics that are currently not needed.)
     */
    transient Node&lt;K,V&gt;[] table;</code></pre>
</li>
</ul>
<h2 id="四个特性关注点"><a href="#四个特性关注点" class="headerlink" title="四个特性关注点"></a>四个特性关注点</h2><table>
<thead>
<tr>
<th align="center">关注点</th>
<th align="center">结论</th>
</tr>
</thead>
<tbody><tr>
<td align="center">HashMap是否允许空</td>
<td align="center">Key和Value都允许为空</td>
</tr>
<tr>
<td align="center">HashMap是否允许重复数据</td>
<td align="center">Key重复会覆盖，Value允许重复</td>
</tr>
<tr>
<td align="center">HashMap是否有序</td>
<td align="center">无序，指遍历HashMap的时候，得到元素的顺序基本不可能是put的顺序</td>
</tr>
<tr>
<td align="center">HashMap是否线程安全</td>
<td align="center">非线程安全</td>
</tr>
</tbody></table>
<h2 id="源码算法分析"><a href="#源码算法分析" class="headerlink" title="源码算法分析"></a>源码算法分析</h2><p>假设有这么一段代码代码：</p>
<pre><code class="java">    public static void main(String[] args)
    {
        Map&lt;String,String&gt; map = new HashMap&lt;&gt;();
        map.put(&quot;111&quot;, &quot;111&quot;);
        map.put(&quot;222&quot;, &quot;222&quot;);
    }</code></pre>
<h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><ul>
<li><p>无参初始化</p>
<pre><code class="java">    /**
     * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity
     * (16) and the default load factor (0.75).
     */
    public HashMap() {
        this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
    }</code></pre>
<p>只初始化负载因此，默认为0.75，负载因子=预估容量/容量</p>
</li>
<li><p>带初始容量或负载因子的 参数的初始化</p>
<pre><code class="java">    public HashMap(int initialCapacity, float loadFactor) {
        if (initialCapacity &lt; 0)
            throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; +
                                               initialCapacity);
        if (initialCapacity &gt; MAXIMUM_CAPACITY)
            initialCapacity = MAXIMUM_CAPACITY;
        if (loadFactor &lt;= 0 || Float.isNaN(loadFactor))
            throw new IllegalArgumentException(&quot;Illegal load factor: &quot; +
                                               loadFactor);
        this.loadFactor = loadFactor;
        this.threshold = tableSizeFor(initialCapacity);
    }</code></pre>
<p>初始化初始容量、负载因子、以及扩容阈值。</p>
<p>看下阈值的说明:</p>
<pre><code class="java">    /**
     * The next size value at which to resize (capacity * load factor).
     *
     * @serial
     */
    // (The javadoc description is true upon serialization.
    // Additionally, if the table array has not been allocated, this
    // field holds the initial array capacity, or zero signifying
    // DEFAULT_INITIAL_CAPACITY.)
    int threshold;</code></pre>
<p>当超过扩容阈值时，需要调用resize进行扩容(resize下面会介绍)。</p>
<p><strong>而阈值是如何计算出来的？</strong>这是JAVA 8的优化，看下tableSizeFor的代码：</p>
<pre><code class="java">    /**
     * Returns a power of two size for the given target capacity.
     */
    static final int tableSizeFor(int cap) {
        int n = cap - 1;
        n |= n &gt;&gt;&gt; 1;
        n |= n &gt;&gt;&gt; 2;
        n |= n &gt;&gt;&gt; 4;
        n |= n &gt;&gt;&gt; 8;
        n |= n &gt;&gt;&gt; 16;
        return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
    }
</code></pre>
<p>返回<strong>大于输入参数且最近的2的整数次幂的数</strong>，分析下怎么做到的：</p>
<p>比如输入10，n=9 二进制为1001(4位二进制）：</p>
<p><code>n |= n &gt;&gt;&gt; 1</code>  右移一位等于100，或运算=1101 </p>
<p><code>n |= n &gt;&gt;&gt; 2</code>   右移二位等于11，或运算=1111 </p>
<p>…</p>
<p>1111=15后续位移和或运算结果不变。相当于将当前位都置1（4个1）。最后n+1，即得到了2的整数次幂的值了。</p>
<p>再来看下<code>int n = cap - 1</code>再复制的目的是找到的目标值大于或<strong>等于</strong>原值。例如二进制1000，十进制为8。如果不对它减1而直接操作，得到答案16，显然不是结果。减1后二进制为111，再进行操作则会得到原来的数值1000，即8。这是为了解决当前输入值正好等于<strong>最近的2的整数次幂的数</strong>，</p>
</li>
</ul>
<p>  为什么需要位移1、2…16次，一共是30次，是因为容量最大是2的30次方。</p>
<p>  <code>MAXIMUM_CAPACITY</code>是2的30次方。</p>
<pre><code class="java">      /**
       * The maximum capacity, used if a higher value is implicitly specified
       * by either of the constructors with arguments.
       * MUST be a power of two &lt;= 1&lt;&lt;30.
       */
      static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;</code></pre>
<p>  这种找出阈值的方法非常高效，可见JAVA 8对容器优化了很多。</p>
<ul>
<li><p>参数为另外一个map的初始化</p>
<pre><code class="java">    /**
     * Constructs a new &lt;tt&gt;HashMap&lt;/tt&gt; with the same mappings as the
     * specified &lt;tt&gt;Map&lt;/tt&gt;.  The &lt;tt&gt;HashMap&lt;/tt&gt; is created with
     * default load factor (0.75) and an initial capacity sufficient to
     * hold the mappings in the specified &lt;tt&gt;Map&lt;/tt&gt;.
     *
     * @param   m the map whose mappings are to be placed in this map
     * hrows  NullPointerException if the specified map is null
     */
    public HashMap(Map&lt;? extends K, ? extends V&gt; m) {
        this.loadFactor = DEFAULT_LOAD_FACTOR;
        putMapEntries(m, false);
    }

    /**
     * Implements Map.putAll and Map constructor
     *
     * @param m the map
     * @param evict false when initially constructing this map, else
     * true (relayed to method afterNodeInsertion).
     */
    final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) {
        int s = m.size();
        if (s &gt; 0) {
            if (table == null) { // pre-size
                float ft = ((float)s / loadFactor) + 1.0F;
                int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ?
                         (int)ft : MAXIMUM_CAPACITY);
                if (t &gt; threshold)
                    threshold = tableSizeFor(t);
            }
            else if (s &gt; threshold)
                resize();
            for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) {
                K key = e.getKey();
                V value = e.getValue();
                putVal(hash(key), key, value, false, evict);
            }
        }
    }
</code></pre>
<p>这段代码比较简单，这里面主要的操作<code>putVal(hash(key), key, value, false, evict);</code>在下面put的操作的时候阐述。</p>
</li>
</ul>
<h3 id="新增-修改操作"><a href="#新增-修改操作" class="headerlink" title="新增/修改操作"></a>新增/修改操作</h3><p>看下put方法的源码：</p>
<pre><code class="java">    public V put(K key, V value) {
        return putVal(hash(key), key, value, false, true);
    }</code></pre>
<p>就一个方法<code>putVal(hash(key), key, value, false, true);</code>，其源码如下：</p>
<pre><code class="java">    final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; 
        if ((tab = table) == null || (n = tab.length) == 0) //(1)
            n = (tab = resize()).length;
        if ((p = tab[i = (n - 1) &amp; hash]) == null) //(2)
            tab[i] = newNode(hash, key, value, null);
        else { //(3)
            Node&lt;K,V&gt; e; K k;
            if (p.hash == hash &amp;&amp;
                ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) //(3.1)
                e = p;
            else if (p instanceof TreeNode)//(3.2)
                e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);
            else { //（3.3）
                for (int binCount = 0; ; ++binCount) {
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
                        if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            treeifyBin(tab, hash);
                        break;
                    }
                    if (e.hash == hash &amp;&amp;
                        ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
                        break;
                    p = e;
                }
            }
            if (e != null) { // existing mapping for key  (4)
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
        if (++size &gt; threshold)
            resize(); //（4）
        afterNodeInsertion(evict);
        return null;
    }</code></pre>
<p>下面按照putValue操作按照操作流程的主题脉络和关键方法来阐述：</p>
<ol>
<li><p>(1) 如果链表数组table是空的，则调用resize初始化容量（可以理解为懒加载）。</p>
</li>
<li><p>(2) 如果插入的位置<code>tab[i = (n - 1) &amp; hash]</code>为空，就基于当前插入元素新建一个链表节点，保存到当前链表数组的位置。</p>
</li>
<li><p>(3) 如果插入的链表数组的位置已经有其他元素节点保存过了（p节点）.</p>
<ol>
<li><p>(3.1)如果当前位置的元素(hash和key相等)与将要插入的元素相等，则<code>e=p</code>。</p>
</li>
<li><p>(3.2)如果当前位置的元素节点p属于TreeNode，则进行树化插入。</p>
</li>
<li><p>(3.3)如果当前插入位置已存在的元素节点p与插入元素不相等，且非TreeNdoe节点。则已p节点为头节点进行链表的next操作遍历插入。</p>
<ul>
<li><p>如果遍历到达p链表的尾部（p.next是null）则插入元素。</p>
</li>
<li><p>如果链表长度（next的次数）超过或达到树化阈值TREEIFY_THRESHOLD - 1，则会树化<code>treeifyBin</code>（下面会讲）。</p>
</li>
<li><p>如果插入遍历next的时候发现节点与插入节点相等，则返回停止遍历。</p>
</li>
</ul>
</li>
</ol>
</li>
<li><p>(4) 元素数量大于阈值<code>threshold</code>则调用<code>resize</code>扩容。</p>
</li>
</ol>
<p>扩容resize和树化操作<code>putTreeVal</code>下面会单独进行讲解。</p>
<h3 id="删除元素"><a href="#删除元素" class="headerlink" title="删除元素"></a>删除元素</h3><p>删除元素有两个方法：</p>
<ol>
<li><p><code>remove(Object key)</code></p>
</li>
<li><p><code>remove(Object key, Object value)</code></p>
</li>
</ol>
<p>这两个方法都是调用的<code>removeNode(int hash, Object key, Object value,
                               boolean matchValue, boolean movable)</code>。其中value值是在删除的时候判断下</p>
<p>我们看下最常用的第一种删除方式的源码：</p>
<pre><code class="java">    public V remove(Object key) {
        Node&lt;K,V&gt; e;
        return (e = removeNode(hash(key), key, null, false, true)) == null ?
            null : e.value;
    }</code></pre>
<p>核心是调用removeNode方法，分析下它的代码：</p>
<pre><code class="java">    final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value,
                               boolean matchValue, boolean movable) {
        Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index;
        if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;
            (p = tab[index = (n - 1) &amp; hash]) != null) {
            Node&lt;K,V&gt; node = null, e; K k; V v;
            if (p.hash == hash &amp;&amp;
                ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))
                node = p; //(1)
            else if ((e = p.next) != null) {//(2)
                if (p instanceof TreeNode)
                    node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key);//
                else {
                    do {
                        if (e.hash == hash &amp;&amp;
                            ((k = e.key) == key ||
                             (key != null &amp;&amp; key.equals(k)))) {
                            node = e;
                            break;
                        }
                        p = e;
                    } while ((e = e.next) != null);
                }
            }
            if (node != null &amp;&amp; (!matchValue || (v = node.value) == value ||
                                 (value != null &amp;&amp; value.equals(v)))) { //(3)
                if (node instanceof TreeNode)
                    ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable);
                else if (node == p)
                    tab[index] = node.next;
                else
                    p.next = node.next;
                ++modCount;
                --size;
                afterNodeRemoval(node);
                return node;
            }
        }
        return null;
    }</code></pre>
<p>删除与新增操作算法类似，主要包含以下算法步骤其中：</p>
<ol>
<li>(1)按照hash计算出的索引index位置数组桶中存的链表头节点元素是否为当前删除元素。如果是记为<code>node</code>变量。</li>
<li>(2)头节点不是当前删除元素节点，且当前头节点链表下一个节点非空。<ol>
<li>头节点是数节点类型<code>TreeNode</code>，则<code>node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key);</code></li>
<li>如果否且链表下一个节点非空，则开始从当前索引位置的链表头节点开始往后遍历。</li>
</ol>
</li>
<li>找到了元素node，按照node的不同删除的情况分为：<ol>
<li>找到的节点node如果是TreeNode则按照<code>((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable);</code>方式删除。</li>
<li>如果node是数组桶中的链表头节点p，则将node的得下一个节点覆盖到当前数组桶的index位置上。对</li>
<li>如果node不是数组桶的头元素，则将删除元素的上一个节点得next指针指向删除节点的next指针指向的节点，即将当前删除节点脱离链表。</li>
</ol>
</li>
</ol>
<p>总结删除、插入元素的算法还是比较简单的，下面来看下操作元素过程中用到的几个比较快件的算法。</p>
<p>扩容（resize）、树化操作、hash算法。</p>
<h3 id="扩容resize算法"><a href="#扩容resize算法" class="headerlink" title="扩容resize算法"></a>扩容resize算法</h3><p>先来看下resize的源码（阅读过程中的主干算法都用1.2.3等按步骤编号标识，其他注释不标注编号）：</p>
<pre><code class="java">    final Node&lt;K,V&gt;[] resize() {
        Node&lt;K,V&gt;[] oldTab = table;//当前所有元素所在数组，称为老的元素数组
        int oldCap = (oldTab == null) ? 0 : oldTab.length;//老元素的数组长度
        int oldThr = threshold;//老的扩容阈值设置
        int newCap, newThr = 0;//新数组的容量，新数组的扩容阈值都初始化为0
        if (oldCap &gt; 0) { //如果老数组长度大于0，说明已经存在元素
            if (oldCap &gt;= MAXIMUM_CAPACITY) {//如果数组元素个数大于等于限定的最大容量（2的30次方）
                threshold = Integer.MAX_VALUE;
                return oldTab;
            }
            /*
            1.如果数组元素个数在正常范围内，那么新的数组容量为老的数组容量的2倍（左移1位）
            如果扩容之后的新容量小于最大容量 并且老的数组容量大于等于默认初始化容量，那么新数组的扩容阈值设置为老阈值的2倍。
            （老的数组容量大于16的初始化容量值，要么已经经历了至少一次扩容）
            */
            else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;
                     oldCap &gt;= DEFAULT_INITIAL_CAPACITY)
                newThr = oldThr &lt;&lt; 1; // double threshold
        }
        //PS1:运行到这个else if，说明老数组没有任何元素
        //如果老数组的扩容阈值大于0，那么设置新数组的容量为该阈值
        //这一步也就意味着构造该map的时候，指定了初始化容量
        else if (oldThr &gt; 0) // initial capacity was placed in threshold
            newCap = oldThr;
        else {               // zero initial threshold signifies using defaults
            //如果能运行到这里，说明调用了无参构造函数初始化map，并且第一次添加元素
            newCap = DEFAULT_INITIAL_CAPACITY;//设置新数组容量为16
            //新数组扩容阈值为16*0.75=12。0.75位默认负载因子（当元素个数达到4分支3，那么扩容）
            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
        }
           //如果扩容阈值为0（PS1的情况），扩容后阈值=新的容量*负载因子
        if (newThr == 0) {
            float ft = (float)newCap * loadFactor;
            newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?
                      (int)ft : Integer.MAX_VALUE);
        }
        threshold = newThr;//设置map的扩容阈值为新的阈值
        @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;})
        //创建新的数组（对于第一次添加元素，这个数组是第一个数组；
        //2.对于存在oldTab的情况，那么这个数组需要扩容到新数组
        Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];
        table = newTab;//将该map的table属性指向到该新数组
        if (oldTab != null) {//3.如果老数组不为空，说明是扩容操作，涉及到元素的转移操作
            for (int j = 0; j &lt; oldCap; ++j) {//遍历老数组
                Node&lt;K,V&gt; e;
                if ((e = oldTab[j]) != null) {//如果当前位置不为空，需要转移元素
                    oldTab[j] = null;//释放老数组中药转移走的元素的引用
                    if (e.next == null)//3.1如果元素没有下一个节点，说明链表只有一个节点（不冲突)
                        newTab[e.hash &amp; (newCap - 1)] = e;//按照新的容量hash确定存储位置
                    else if (e instanceof TreeNode)//如果转移元素是树化节点，树化操作（省略，会另外开一篇文章单独讨论树化）
                        ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);
                    else { // preserve order
                        //3.2 如果原数组的链表节点有next节点，说明链表有多冲突有多个节点，确定要将链表中的所有节点重新计算放到新位置（跟着老链表走）还是扩容后放到新的数组中
                        Node&lt;K,V&gt; loHead = null, loTail = null;//理解为：低位头尾节点
                        Node&lt;K,V&gt; hiHead = null, hiTail = null;//理解为：高位头尾节点
                        Node&lt;K,V&gt; next;
                        do {//这个循环就是在遍历数组中链表头节点开始遍历链表，下面会在文中详细解析该算法
                            next = e.next;
                            //如果遍历节点不需要转移位置，该元素放在低位链表中。
                            if ((e.hash &amp; oldCap) == 0) {
                                if (loTail == null)
                                    loHead = e;
                                else
                                    loTail.next = e;
                                loTail = e;
                            }
                            else {//如果遍历节点需要转移位置，该元素放在高位链表中
                                if (hiTail == null)
                                    hiHead = e;
                                else
                                    hiTail.next = e;
                                hiTail = e;
                            }
                        } while ((e = next) != null);//3.2.1 将低位链表的头节点放到到新数组的原先的位置
                        if (loTail != null) {
                            loTail.next = null;
                            newTab[j] = loHead;
                        }
                        if (hiTail != null) {//3.2.2 将高位链表的头节点放到新库容数组的高位位置j + oldCap
                            hiTail.next = null;
                            newTab[j + oldCap] = hiHead;
                        }
                    }
                }
            }
        }
        return newTab;
    }</code></pre>
<p>resize的流程主要分为三步：</p>
<ol>
<li><p>计算库容、及扩容后的阈等参数的调整（详细见代码注解）。扩容的参数调整主要分成几种情况</p>
<ul>
<li>数组中已经有元素存在，新增元素时进行扩容的参数调整。</li>
<li>数组中没有元素，使用初始化容量参数的构造函数初始化map。</li>
<li>数组中没有元素，使用无参的构造函数初始化map。</li>
</ul>
</li>
<li><p>需要new一个新扩容后的数组桶table出来。<strong>一般来说如果如果是有元素的数组库扩容，数组桶table得扩容是原先的2倍。</strong> 其他情况的扩容参数见1.中对应的代码注释。</p>
</li>
<li><p>旧桶的元素往扩容新桶中进行拷贝。</p>
<ul>
<li><p>3.1 如果同数组的链表节点没有next节点，说明这个链表只有一个节点（hash不冲突），那么就直接按照新的容量hash确定存储引用的位置。</p>
</li>
<li><p>3.2 如果原数组的链表节点有next节点，说明当前Hash位置有冲突，链表中有多个节点。需要将链表中的所有节点重新计算位置（把原链表的元素遍历，分别放到高低两个链表中，然后把高低位两个链表分别放到原位置和新增容量的位置中）。下面详细介绍下转移的算法：</p>
<ul>
<li><p>首先，需要判断原链表中的元素是放在老位置还是新位置：</p>
<p><code>(e.hash &amp; oldCap) == 0</code>   </p>
<p><strong>算法思想</strong>：数组的长度一定是2的N次方（例如16），<strong>如果hash值和该长度做与运算，结果为0，就说明该hash值和数组长度取模后的值一定小于数组长度（例如mod值为1）</strong>，<br> 该hash值再和新数组的长度取摸的话mod值也不会放生变化，所以该元素的在新数组的位置和在老数组的位置是相同的，所以该元素可以放置在低位链表中。反之元素放到高位得链表中。</p>
<p>注意：不是(e.hash &amp; (oldCap-1));而是(e.hash &amp; oldCap)，(e.hash &amp; oldCap) 得到的是元素的在数组中的位置是否需要移动。</p>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="树化算法"><a href="#树化算法" class="headerlink" title="树化算法"></a>树化算法</h3><p>在增加、扩容、删除等操作上都会涉及树化节点的操作，树化操作篇幅较长，因此我会开一篇新的博客来总结介绍HashMap的树化操作。届时会把文章链接更新在此。</p>
<h3 id="hash算法及hash碰撞"><a href="#hash算法及hash碰撞" class="headerlink" title="hash算法及hash碰撞"></a>hash算法及hash碰撞</h3><p>注意到在桶数组（哈希表）中保存数据的位置通过：hash与数组长度-1与得到，</p>
<pre><code class="java">i = (n - 1) &amp; hash</code></pre>
<p>这里的hash值并不是key本身的hashcode，而是来自hashmap内部的一个方法得到：</p>
<pre><code class="java">    static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);
    }</code></pre>
<p>举例hash的调用：</p>
<pre><code class="java">    public V put(K key, V value) {
        return putVal(hash(key), key, value, false, true);
    }</code></pre>
<p>JDK1.8的实现中，优化了高位运算的算法，将hashCode的高16位与hashCode进行异或运算，这是因为有些数据计算出的哈希值差异主要在高位，而 HashMap里的哈希寻址是忽略容量以上的高位的，那么这种处理就可以有效避免类似情况下的<strong>hash碰撞</strong>。注同一个hashcode计算出的hash值一定相等。</p>
<ul>
<li><p>解决hash冲突，有哪些典型的方法？</p>
<p>开发地址法、再哈希法、链地址法</p>
</li>
</ul>
<h3 id="hashcode、equals注意点"><a href="#hashcode、equals注意点" class="headerlink" title="hashcode、equals注意点"></a>hashcode、equals注意点</h3><ul>
<li>equals相等，hashcode一定要相等。<ul>
<li>如果equals相等、hashcode不相等，元素就会被存到不同的桶位置。</li>
<li>如果eqauls不相等、hashcode相等，元素虽然会保存同一个桶位置，但是在equals比较的时候发现不相等，会当做两个元素保存当前桶位置的链表中。这同样会导致重复元素被存储，链表变长，从而性能下降。</li>
</ul>
</li>
<li>重写了hashcode也要重写equals。</li>
<li>hashcode需要保持一致性，状态改变返回的哈希值仍然要一致。</li>
<li>equals的对称、反射、传递等特性。</li>
</ul>
<h2 id="使用场景选择"><a href="#使用场景选择" class="headerlink" title="使用场景选择"></a>使用场景选择</h2><p>一般来说没有顺序要求，都会选择HashMap，而与HashMap相似的还有Hashtable的键值对组合，他们的区别也往往在面试时经常被问到，下面来总结下两者区别，也能知道其使用场景：</p>
<ol>
<li>Hashtable是线程安全的，    Hashtable对外提供的方法都使用<code>synchronized</code>修饰，也就是同步的，而HashMap就是线程非安全的。</li>
<li>Hashtable不允许空的value，空的value将导致空指针异常，而HashMap则无所谓，没有这方面的限制，HashMap的key是null只允许存在一个，而value是null可以无数个。</li>
<li>HashMap的默认初始容量是16，Hashtable是11。</li>
<li>HashMap的hash值重新计算过，Hashtable直接使用hashCode。</li>
<li>HashMap继承自AbsractMap，Hashtable继承自Dictionary类。</li>
<li>两个容器的的rehash算法不同。</li>
</ol>
<h2 id="HashMap总结"><a href="#HashMap总结" class="headerlink" title="HashMap总结"></a>HashMap总结</h2><ol>
<li>HashMap底层是一个Node数组（Node&lt;K,V&gt; [] table），在数组的具体索引位置，如果存在多个节点（hash冲突），则可能是以链表或红黑树的形式存在。</li>
<li>增加、删除、查找键值对时，定位到哈希桶数组的是很关键的一步，通过3个操作来完成：1）拿到key的hashcode值；2）将hashcode的高位参与与或运算，重新计算hash值。3）将计算出来的hash值与（table.length-1）进行&amp;运算。</li>
<li>HashMap的初始容量（capacity）是16，capactiy必须是2的幂次方（如果不是会采用tableForSize算法取最接近大于等于当前初始化容量的2次幂的值）；默认负载因子load factor是0.75；实际能存放的节点个数（容量阈值）=capacity*load factor。</li>
<li>HashMap在触发扩容后，阈值会变成原来的2倍，并且会重新hash，重hash后的索引位置index的节点新分布位置最多只有2种情况：原索引位置或原索引位置+oldCap位置。例如capacity为16，索引位置5的节点扩容后，只可能分布在原索引位置5和索引位置（5+16）21。</li>
<li>导致HashMap扩容后，同一个索引位置的节点重hash最多分布在两个位置的根本原因是：1）table的长度始终为2的n次方；2）索引位置的计算方法“(table.length-1)&amp;hash”。HashMap扩容是一个比较耗时的操作，定义HashMap时尽量给个接近的初始容量值。</li>
<li>HashMap有threshold属性和loadFactor属性，但是没有capacity属性。初始化时，如果传了初始容量值，该值是会存为threshold变量，并且Node数组是在第一次put时才会进行初始化，初始化时会将此时的threshold值作为新表的capacity值，然后用capacity和loaderFactor计算新表的真正threshold值。</li>
<li>当同一个索引位置的节点在增加后达到9个时，会触发链表节点（Node）转成红黑树（TreeNode，间接继承Node），转成红黑树节点后，其实链表的结构还在，通过next属性维持。链表节点转红黑树节点的具体方法为源码treeifyBin(Node&lt;K,V&gt;[] tab, int hash)方法。</li>
<li>当同一个索引位置的节点在移除后到达6个时，并且该索引位置的节点为红黑树节点，会触发红黑树节点转链表节点。红黑树节点转链表节点的具体方法为untreeify(HashMap&lt;K,V&gt; map)方法。</li>
<li>HashMap在JDK1.8之后不再有死循环的问题，JDK1.8之前存在死循环的根本原因是在扩容后同一索引位置的节点顺序会反掉。</li>
<li>HashMap是非线程安全的，在并发场景下使用ConcurrentHashMap来代替。</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.csdn.net/v123411739/article/details/78996181" target="_blank" rel="noopener">https://blog.csdn.net/v123411739/article/details/78996181</a><br><a href="https://www.cnblogs.com/xrq730/p/5030920.html" target="_blank" rel="noopener">https://www.cnblogs.com/xrq730/p/5030920.html</a></p>
]]></content>
      <categories>
        <category>Java</category>
        <category>集合</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Collection</tag>
        <tag>集合</tag>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title>【Java集合】-LinkedList</title>
    <url>/2019/01/16/2019-1-16-java-collection-LinkedList/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>LinkedList底层是双向链表数据结构的的列表，双向列表的特征主要有两个：</p>
<ol>
<li>链表中任意节点都可以通过向前和向后寻址来找到前一个存储单元和后一个存储单元。</li>
<li>链表的尾节点的都下一个节点指向头节点，而头节点的上一个节点寻址可以找到尾节点。</li>
</ol>
<p>单独看一个JAVA集合需要关注以下6个方面：</p>
<ul>
<li>数据结构：数据是这么样存储的。</li>
<li>算法：是通过什么算法操作数据结构 达到对应功能的。</li>
<li>特性关注点：对于集合需要关注以下四个方面<ul>
<li>是否允许空</li>
<li>是否允许重复数据</li>
<li>是否有序（有序的意思是读取数据的顺序和存放的顺序是否一致）</li>
<li>是否线程安全</li>
</ul>
</li>
<li>场景选择：该集合的技术特点，应该在什么场景下使用。</li>
<li>源码阅读：要清楚以上特点，需要阅读代码来理解</li>
</ul>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>LinkedList对数据结构的操作依赖如下几个变量：</p>
<pre><code class="java">    transient int size = 0;

    /**
     * Pointer to first node.
     * Invariant: (first == null &amp;&amp; last == null) ||
     *            (first.prev == null &amp;&amp; first.item != null)
     */
    transient Node&lt;E&gt; first;

    /**
     * Pointer to last node.
     * Invariant: (first == null &amp;&amp; last == null) ||
     *            (last.next == null &amp;&amp; last.item != null)
     */
    transient Node&lt;E&gt; last;</code></pre>
<p>其中Node<E>就是LinkedList的存储单元，而first和last就是初始状态下空LinkedList自带的头节点和尾节点。</p>
<p>下面看下LinkedList的数据结构Node<E></p>
<pre><code class="java">    private static class Node&lt;E&gt; {
        E item;
        Node&lt;E&gt; next;
        Node&lt;E&gt; prev;

        Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) {
            this.item = element;
            this.next = next;
            this.prev = prev;
        }
    }</code></pre>
<p>其中item是数据本身，</p>
<p>next与pre都是指向前一个和后一个Node<E>的引用。</p>
<h2 id="特性关注点"><a href="#特性关注点" class="headerlink" title="特性关注点"></a>特性关注点</h2><table>
<thead>
<tr>
<th align="center">关注点</th>
<th align="center">结论</th>
</tr>
</thead>
<tbody><tr>
<td align="center">LinkedList是否允许为空</td>
<td align="center">允许</td>
</tr>
<tr>
<td align="center">LinkedList是否允许重复数据</td>
<td align="center">允许</td>
</tr>
<tr>
<td align="center">LinkedList是否有序</td>
<td align="center">有序</td>
</tr>
<tr>
<td align="center">LinkedList是否线程安全</td>
<td align="center">非线程安全</td>
</tr>
</tbody></table>
<h2 id="算法及源码解读"><a href="#算法及源码解读" class="headerlink" title="算法及源码解读"></a>算法及源码解读</h2><h3 id="新增元素"><a href="#新增元素" class="headerlink" title="新增元素"></a>新增元素</h3><p>先看下LinkedList一段代码：</p>
<pre><code class="java">    public static void main(String[] args)
    {
        List&lt;String&gt; list = new LinkedList&lt;&gt;();
        list.add(&quot;111&quot;);
        list.add(&quot;222&quot;);
    }</code></pre>
<p>增加两个元素”000”,”001”，下面看看源码是怎么运行的。</p>
<pre><code class="java">    /**
     * Appends the specified element to the end of this list.
     *
     * &lt;p&gt;This method is equivalent to {@link #addLast}.
     *
     * @param e element to be appended to this list
     * @return {ode true} (as specified by {@link Collection#add})
     */
    public boolean add(E e) {
        linkLast(e);
        return true;
    }</code></pre>
<p>如上：只有一个linkLast(e)方法，说明新增元素默认使用的是后插的方法即新增元素插入到链表的尾部。看下linkLast源码：</p>
<pre><code class="java">    /**
     * Links e as last element.
     */
    void linkLast(E e) {
        final Node&lt;E&gt; l = last;(1)
        final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null);(2)
        last = newNode;(3)
        if (l == null)(4)
            first = newNode;
        else
            l.next = newNode;
        size++;
        modCount++;
    }</code></pre>
<p>插入的步骤，分为如下几步：</p>
<p>(1) 将linkedList的last尾节点赋值给临时节点l。</p>
<p>(2) new一个新的节点newNode：<code>new Node&lt;&gt;(l, e, null)</code>。将新增元素存储到新节点，新节点的的前指针指向尾节点，后指针值为空。</p>
<p>(3) 将新节点替换为新的尾节点。</p>
<p>(4) 判断当前的原尾节是否是null，如果是null就将新增节点作为头节点。如果不是空，说明当前至少存在一个尾节点，将尾节点的后指针指向新增的尾节点。</p>
<h3 id="插入元素"><a href="#插入元素" class="headerlink" title="插入元素"></a>插入元素</h3><pre><code class="java">    /**
     * Inserts the specified element at the specified position in this list.
     * Shifts the element currently at that position (if any) and any
     * subsequent elements to the right (adds one to their indices).
     *
     * @param index index at which the specified element is to be inserted
     * @param element element to be inserted
     * hrows IndexOutOfBoundsException {@inheritDoc}
     */
    public void add(int index, E element) {
        checkPositionIndex(index);

        if (index == size)
            linkLast(element);
        else
            linkBefore(element, node(index));
    }</code></pre>
<p>首先校验下当前位置是否合法，然后判断当前位置是不是要查到最后一位，如果是就还是采用与默认的add一致的尾插方式，如果不是则采用<code>linkBefore</code>的方式（上面讲解的头插的方式逻辑正好想法），本文称为前插。前插比较麻烦的是，需要根据位置来查到对应的节点，如源码<code>node(index)</code>：</p>
<pre><code class="java">    /**
     * Returns the (non-null) Node at the specified element index.
     */
    Node&lt;E&gt; node(int index) {
        // assert isElementIndex(index);

        if (index &lt; (size &gt;&gt; 1)) { (1)
            Node&lt;E&gt; x = first;
            for (int i = 0; i &lt; index; i++)
                x = x.next;
            return x;
        } else {
            Node&lt;E&gt; x = last;
            for (int i = size - 1; i &gt; index; i--)
                x = x.prev;
            return x;
        }
    }</code></pre>
<p>可以看到，因为链表是没有位置信息的，因此要找到index的处的下一个节点或者前一个节点，查找方式：</p>
<p>见(1) 判断index位置处于链表的前半部分还是后半部分。</p>
<ol>
<li><p>如果index位于链表的前半部分：则从first开始把下标往后移动index-1次找到index位置的<strong>元素。</strong></p>
</li>
<li><p>如果index位于链表的后半部分：则从last开始往把下标往前移动 size-1-index次 找到index位置的<strong>元素</strong>。</p>
</li>
</ol>
<p>找到元素以后，调用<code>linkBefore(element, node(index));</code>前插方法插入元素，下面粗略看下前插方法的源码：</p>
<pre><code class="java">    /**
     * Inserts element e before non-null Node succ.
     */
    void linkBefore(E e, Node&lt;E&gt; succ) {
        // assert succ != null;
        final Node&lt;E&gt; pred = succ.prev;
        final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ);
        succ.prev = newNode;
        if (pred == null)
            first = newNode;
        else
            pred.next = newNode;
        size++;
        modCount++;
    }</code></pre>
<p>与尾插的算法类似，只不过这里是在succ的位置插入新元素，新元素的前指针指向succ元素的前一个节点，后指针指向succ元素。succc的前指针指向新元素。</p>
<h3 id="查找元素"><a href="#查找元素" class="headerlink" title="查找元素"></a>查找元素</h3><p>与ArrayList支持两种方式查找元素不同，LinkedList只有根据index来查找获取元素。源码如下：</p>
<pre><code class="java">    public E get(int index) {
        checkElementIndex(index);(1)
        return node(index).item;
    }</code></pre>
<ol>
<li>首先(1)检查index是否超过当前长度范围，如果超过抛运行时异常IndexOutOfBoundsException异常。</li>
<li>然后查找调用<code>node(index)</code>方法来查找或者改位置存储的元素item。<code>node(index)</code>的源码解析见上按照位置插入元素的源码分析。</li>
</ol>
<h3 id="删除元素"><a href="#删除元素" class="headerlink" title="删除元素"></a>删除元素</h3><p>LinkedList与ArrayList一样支持两种方式（按位置、按元素）删除元素。如：</p>
<pre><code class="java">        list.remove(&quot;111&quot;);//按元素
        list.remove(1);//按下标</code></pre>
<p>下面来解读下，两种删除方式的源码。</p>
<ol>
<li><p>按照下标删除元素</p>
<pre><code class="java">    public E remove(int index) {
        checkElementIndex(index);
        return unlink(node(index));
    }</code></pre>
<p>主要步骤先调用node(index)查找对应元素。然后调用<code>unlink(Node&lt;E&gt; x)</code>删除元素，下面看下核心的删除元素的源码：</p>
<pre><code class="java">    /**
     * Unlinks non-null node x.
     */
    E unlink(Node&lt;E&gt; x) {
        // assert x != null;
        final E element = x.item;
        final Node&lt;E&gt; next = x.next;（1）
        final Node&lt;E&gt; prev = x.prev;

        if (prev == null) { (2)
            first = next;
        } else {
            prev.next = next;
            x.prev = null;
        }

        if (next == null) {（3）
            last = prev;
        } else {
            next.prev = prev;
            x.next = null;
        }

        x.item = null; （4）
        size--;
        modCount++;
        return element;
    }</code></pre>
<p>（1）先把当前节点的前面和后面一个节点保存到临时变量prev和next。</p>
<p>（2）把当前节点前一个节点的后指针指向当前节点的下一个节点，并将当前节点的前指针置空。如果当前节点是第一个节点，直接把下一个节点记为第一个节点first。</p>
<p>（3）把当前节点的后一个节点的前指针指向当前节点的前一个指针，并将当前节点后指针置空。如果当前节点是最后一个节点，则把前一个节点直接置为最后一个节点。</p>
<p>（4）将当前节点的元素置为null，等待垃圾回收。</p>
<ol start="2">
<li><p>按照元素本身删除元素</p>
<p>源码如下：</p>
<pre><code class="java">    public boolean remove(Object o) {
        if (o == null) {
            for (Node&lt;E&gt; x = first; x != null; x = x.next) {
                if (x.item == null) {
                    unlink(x);
                    return true;
                }
            }
        } else {
            for (Node&lt;E&gt; x = first; x != null; x = x.next) {
                if (o.equals(x.item)) {
                    unlink(x);
                    return true;
                }
            }
        }
        return false;
    }</code></pre>
<p>从源码可以看出，按照元素本身删除，需要把链表从头开始遍历一遍直到找到待删除元素，才进行指针修改删除。可见LinkedList的插入、删除动作还是会耗费一些寻址的时间。</p>
</li>
</ol>
</li>
</ol>
<h2 id="使用场景选择"><a href="#使用场景选择" class="headerlink" title="使用场景选择"></a>使用场景选择</h2><p>要讲清楚LinkedList应该怎么用，要先说明LinkedList的优缺点点是什么，一般来说LinkedList的选择都是伴随ArrayList的比较来讲的。因此讲下这两个列表在不同场景下的优缺点比较：</p>
<ul>
<li><p>插入(删除)速度</p>
<ul>
<li><p>顺序插入（新增元素）</p>
<p><strong>分析</strong>：对于顺序插入来说，ArrayList的速度会比较快，因为ArrayList是基于数组实现的，数组是事先new好的，只要往指定位置塞一个数据就好。</p>
<p>而对于LinkedList则每次顺序插入的时候将new一个对象出来，如果对象比较大，那么new的时间会长一点，再加上一些引用赋值的操作。所以</p>
<p><strong>结论</strong>：顺序插入总的来说：ArrayList &gt; LinkedList，此结论是针对ArrayList已经预分配好了足够的数组长度，如果长度不够，ArrayList会有额外的数组拷贝动作，速度会慢于LinkedList。</p>
</li>
<li><p>随机插入</p>
<p><strong>分析</strong>：</p>
<ol>
<li><p>对于随机插入来说，不同于顺序插入都是从列表的尾部直接插入，随机插入是在指定位置插入一个元素。</p>
</li>
<li><p>对于LinkeList来说，往index位置上插入一个元素需要遍历找到该位置对应的元素并修改指针，没有元素拷贝。因此性能损耗在<strong>遍历寻址</strong>上。</p>
<p>最好情况：如果index正好落在链表的首尾，这样一下子就找到了插入的位置元素只要进行一次指针修改。</p>
<p>最坏情况：如果index正好落在链表的中间，这样需要至少size/2次遍历才能找到对应插入位置的元素。</p>
</li>
<li><p>对应ArrayList来说，不同于顺序插入到数组的末尾，没有元素拷贝。如果插入在列表的中间或者前面那么插入位置后面的所有元素都为往后移动一位。因此性能损耗在<strong>元素拷贝</strong>上。</p>
<p>最好情况：插入到列表末尾。</p>
<p>最坏情况：插入到列表第一位。</p>
</li>
</ol>
<p><strong>结论</strong>：</p>
<ol>
<li><p>LinkedList在插入、删除的时候，<strong>慢在</strong>寻址，<strong>快在</strong>改变前后Node的引用地址。ArrayList在插入、删除的时候，<strong>慢在</strong>元素拷贝，<strong>快在</strong>寻址。</p>
</li>
<li><p>说LinkedList比ArrayList插入、删除更快的说法 其实不一定准确。是因为在不同场景下的结论并不一定是这样的。一般情况下：</p>
<p><strong>元素在列表前半段</strong>：LinkedList速度优于ArrayList。</p>
<p><strong>元素在列表中间</strong>：LinkedList速度与ArrayList不相上下，LinkedList需要从首或尾遍历到中间位置（最坏情况），而ArrayList只需要拷贝一半元素。</p>
<p><strong>元素在列表后半段</strong>：插入位置越往后，LinkedList的遍历速度与元素在前半段的速度一致（双向链表可以往前往后寻址）也越来越快，而ArrayList需要拷贝的元素也越来越少，因此此时ArrayList的速度可能赶上甚至超过ArrayList。</p>
</li>
<li><p>ArrayList一旦存在频繁插入的场景时，数组随时需要扩容，则扩容需要做整体拷贝，既消耗时间也消耗空间。而LinkedList则没这种问题。</p>
</li>
</ol>
</li>
</ul>
</li>
<li><p>内存消耗</p>
<p>因为LinkedList里面不仅维护了待插入的元素，还维护了Node的前置和后置Node的引用(32位），如果一个LinkedList的Node非常多。</p>
<p><strong>结论</strong> ： LinkedList比ArrayList更耗内存一点。</p>
</li>
<li><p>遍历速度</p>
<p><strong>结论</strong>：使用各自遍历效率最高的方式，ArrayList的遍历效率会比LinkedList的遍历效率高一些。</p>
</li>
<li><p>随机访问速度</p>
<p><strong>结论</strong>：ArrayList &gt; LinkedList</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
        <category>集合</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Collection</tag>
        <tag>集合</tag>
        <tag>LinkedList</tag>
      </tags>
  </entry>
  <entry>
    <title>【Java集合】-ArrayList</title>
    <url>/2019/01/15/2019-1-15-java-collection-ArrayList/</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>ArrayList是JAVA集合中的使用广泛的有序集合，提供按照位置定位、添加、删除、查询的操作。提供迭代器以遍历其内容等。单独看一个JAVA集合需要关注以下6个方面：</p>
<ul>
<li>数据结构：数据是这么样存储的。</li>
<li>算法：是通过什么算法操作数据结构 达到对应功能的。</li>
<li>特性关注点：对于集合需要关注以下四个方面<ul>
<li>是否允许空</li>
<li>是否允许重复数据</li>
<li>是否有序（有序的意思是读取数据的顺序和存放的顺序是否一致）</li>
<li>是否线程安全</li>
</ul>
</li>
<li>场景选择：该集合的技术特点，应该在什么场景下使用。</li>
<li>源码阅读：要清楚以上特点，需要阅读代码来理解</li>
</ul>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><table>
<thead>
<tr>
<th align="center">元素</th>
<th align="center">作用</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>transient</strong> Object[] elementData;</td>
<td align="center">基于数组实现，elementData就是底层的数组</td>
</tr>
<tr>
<td align="center">private int size;</td>
<td align="center">ArrayList里面元素的个数，size是按照调用add、remove方法的次数进行自增或自减得，所以add了一个null进入ArrayList，size也会加1</td>
</tr>
</tbody></table>
<h2 id="特性关注点"><a href="#特性关注点" class="headerlink" title="特性关注点"></a>特性关注点</h2><table>
<thead>
<tr>
<th align="center">关注点</th>
<th align="center">结论</th>
</tr>
</thead>
<tbody><tr>
<td align="center">ArrayList是否允许为空</td>
<td align="center">允许</td>
</tr>
<tr>
<td align="center">ArrayList是否允许重复数据</td>
<td align="center">允许</td>
</tr>
<tr>
<td align="center">ArrayList是否有序</td>
<td align="center">有序</td>
</tr>
<tr>
<td align="center">ArrayList是否线程安全</td>
<td align="center">非线程安全</td>
</tr>
</tbody></table>
<h2 id="使用场景选择"><a href="#使用场景选择" class="headerlink" title="使用场景选择"></a>使用场景选择</h2><p>先总结下ArrayList的优缺点，结合优缺点才能知道适用场景：</p>
<ul>
<li><p>优点：</p>
<ul>
<li>ArrayList底层以数组实现，是一种<strong>随机访问</strong>模式，再加上它实现了<strong>RandomAccess</strong>接口，因此查找（get）的时候非常的块。</li>
<li>ArrayList在<strong>顺序</strong>添加一个元素的时候非常方便，只是往数组添加一个元素而已，没有元素移动。</li>
</ul>
</li>
<li><p>缺点：</p>
<ul>
<li>删除元素的时候，涉及到一次元素复制，如果要复制的元素很多，就会比较耗费性能。</li>
<li>插入元素的时候，涉及到一次元素复制，如果要复制的元素很多，那么就会比较耗时。</li>
</ul>
</li>
<li><p>补充：</p>
<p>最快：一般来说插入与删除因为涉及元素复制，但是如果元素在数组的末尾，性能为O(1)。</p>
<p>最慢：元素在数组的第一个是最耗时的。</p>
</li>
</ul>
<h2 id="算法及源码解读"><a href="#算法及源码解读" class="headerlink" title="算法及源码解读"></a>算法及源码解读</h2><pre><code class="java">    public static void main(String[] args)
    {
        ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();
        list.add(&quot;000&quot;);
        list.add(&quot;001&quot;);
    }</code></pre>
<p>如上代码代码示例，增加两个元素”000”,”001”，下面看看源码是怎么运行的。</p>
<h3 id="添加元素"><a href="#添加元素" class="headerlink" title="添加元素"></a>添加元素</h3><pre><code class="java">    public boolean add(E e) {
        ensureCapacityInternal(size + 1);  // Increments modCount!!
        elementData[size++] = e;
        return true;
    }</code></pre>
<ul>
<li><p><code>ensureCapacityInternal(size + 1)</code>用来扩容。</p>
</li>
<li><p><code>elementData[size++] = e</code>在底层数组中增加元素e（保存着元素的引用），数组类型为Object。如下图所示:</p>
<p><img data-src="/img/in-post/1547610506727.png" alt=""></p>
</li>
<li><p>size表示当前数组元素的数量</p>
</li>
</ul>
<h3 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h3><ul>
<li>默认构造函数</li>
</ul>
<p>ArrayList的默认构造函数如下：</p>
<pre><code class="java">    /**
     * Constructs an empty list with an initial capacity of ten.
     */
    public ArrayList() {
        this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;
    }</code></pre>
<p>DEFAULTCAPACITY_EMPTY_ELEMENTDATA 为</p>
<pre><code class="java">    /**
     * Shared empty array instance used for default sized empty instances. We
     * distinguish this from EMPTY_ELEMENTDATA to know how much to inflate when
     * first element is added.
     */
    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};</code></pre>
<ul>
<li><p>当新增元素时，数组元素不够时，数组需要扩容。</p>
<pre><code class="java">    public boolean add(E e) {
        ensureCapacityInternal(size + 1);  // Increments modCount!!
        elementData[size++] = e;
        return true;
    }</code></pre>
</li>
</ul>
<p>其中<code>ensureCapacityInternal(size + 1)</code>用来扩容。size+1表示需要扩容一个元素后的数组长度的最小大小。</p>
<pre><code class="java">    private void ensureCapacityInternal(int minCapacity) {
        ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));
    }</code></pre>
<p><code>calculateCapacity(elementData, minCapacity)</code>用来计算实际扩容的最小大小，当第一次添加元素时，数组则准备扩容至默认初始大小10。注意ArrayList默认构造函数初始，初始化的数组默认是空的，当第一次加入元素时才初始化为10。</p>
<p>在确定了扩容的大小之后，调用</p>
<pre><code class="java">    private void ensureExplicitCapacity(int minCapacity) {
        modCount++;

        // overflow-conscious code
        if (minCapacity - elementData.length &gt; 0)
            grow(minCapacity);
    }</code></pre>
<p>进行扩容。</p>
<p>其中<code>modCount++;</code>用来当迭代器iterator在迭代元素时出现元素被修改时，抛出<code>ConcurrentModificationException</code>使用。</p>
<ul>
<li><p>下面是计算出待扩容的数组大小minCapacity后，实际数组进行扩容的源码</p>
<pre><code class="java">    /**
     * Increases the capacity to ensure that it can hold at least the
     * number of elements specified by the minimum capacity argument.
     *
     * @param minCapacity the desired minimum capacity
     */
    private void grow(int minCapacity) {
        // overflow-conscious code
        int oldCapacity = elementData.length;
        int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);
        if (newCapacity - minCapacity &lt; 0)
            newCapacity = minCapacity;
        if (newCapacity - MAX_ARRAY_SIZE &gt; 0)
            newCapacity = hugeCapacity(minCapacity);
        // minCapacity is usually close to size, so this is a win:
        elementData = Arrays.copyOf(elementData, newCapacity);
    }</code></pre>
<p>可以看出newCapacity是原数组大小的1.5倍。我当前的java源码对应的jdk版本是jdk 1.8_191，jdk老版本的扩容大小是1.5倍+1。</p>
<p>如果newCapacity不够，则使用minCapacity作为newCapacity扩容大小。</p>
<p>如果newCapacity比最大数组大小（<strong>MAX_ARRAY_SIZE</strong> = Integer.<strong>MAX_VALUE</strong> - 8）还要大，则调用</p>
<pre><code class="java">    private static int hugeCapacity(int minCapacity) {
        if (minCapacity &lt; 0) // overflow
            throw new OutOfMemoryError();
        return (minCapacity &gt; MAX_ARRAY_SIZE) ?
            Integer.MAX_VALUE :
            MAX_ARRAY_SIZE;
    }</code></pre>
<p>如果最小扩容大小大于MAX_ARRAY_SIZE则使用Integer.MAX_VALUE扩容，如果小于，则使用MAX_ARRAY_SIZE。</p>
<p>下面则使用确定的newCapacity扩容新大小进行原有数组拷贝，并将拷贝的新长度的数组并赋值给elementData：</p>
<pre><code class="java">        elementData = Arrays.copyOf(elementData, newCapacity);</code></pre>
<p>用一张图表示如下：</p>
<p><img data-src="/img/in-post/image-20190116000729476.png" alt=""></p>
<p>最后，调用<code>elementData[size++] = e;</code>将元素保存在当前元素大小为size的位置上，并且size++更新。</p>
<p>至此，ArrayList添加元素，底层数组扩容完毕。其中Arrays.copyOf(elementData, newCapacity);也是可以展开来讲的。</p>
</li>
</ul>
<h3 id="删除元素"><a href="#删除元素" class="headerlink" title="删除元素"></a>删除元素</h3><p>看下删除元素。ArrayList支持两种删除方式：</p>
<ol>
<li>按照下标删除</li>
<li>按照元素删除，这会删除ArrayList中与指定要删除的元素匹配的第一个元素。</li>
</ol>
<ul>
<li><p>按照下标删除元素，源码：</p>
<pre><code class="java">    public E remove(int index) {
        rangeCheck(index); (1)

        modCount++;
        E oldValue = elementData(index); 

        int numMoved = size - index - 1;  (2)
        if (numMoved &gt; 0)
            System.arraycopy(elementData, index+1, elementData, index,
                             numMoved);   (3)
        elementData[--size] = null; // clear to let GC do its work (4)

        return oldValue;
    }</code></pre>
<p>(1)  rangCheck(index)检查当前index的范围，超出size或者小于0，抛数组越界异常。</p>
<p>(2)  计算出需要移动元素的个数numMoved</p>
<p>(3) 元素不在数组最末尾（即有元素需要移动），则使用System.arraycopy拷贝元素，将该index+1位置的numMoved个元素往前挪一位，覆盖掉index位置的元素。</p>
<p>(4) 将移动前数组末尾的元素置null，供垃圾回收。并且将size-1。</p>
<p><strong>总结就是：</strong></p>
<ul>
<li><p>把指定位置的元素的后面所有元素，利用System.arraycopy方法整体往前移动一个位置。</p>
</li>
<li><p>最后一个位置的元素指定为null，这样gc可以回收它。</p>
<p>如下图所示，比如要删除在3位置上的”333”元素。</p>
</li>
</ul>
</li>
</ul>
<p><img data-src="/img/in-post/image-20190116002108395.png" alt=""></p>
<ul>
<li>按照元素删除，源码：</li>
</ul>
<pre><code class="java">    public boolean remove(Object o) {
        if (o == null) {
            for (int index = 0; index &lt; size; index++)
                if (elementData[index] == null) {
                    fastRemove(index);
                    return true;
                }
        } else {
            for (int index = 0; index &lt; size; index++)
                if (o.equals(elementData[index])) {
                    fastRemove(index);
                    return true;
                }
        }
        return false;
    }</code></pre>
<p>删除元素就是在已有数组中，从头到size范围内查找待删除元素，查找到之后按照下标位置删除元素（与下标位置删除方式一致），如果查找失败返回false。</p>
<h3 id="插入元素"><a href="#插入元素" class="headerlink" title="插入元素"></a>插入元素</h3><p>看下插入元素的代码</p>
<pre><code class="java">  public static void main(String[] args)
  {
      List&lt;String&gt; list = new ArrayList&lt;String&gt;();
      list.add(&quot;111&quot;);
      list.add(&quot;222&quot;);
      list.add(&quot;333&quot;);
      list.add(&quot;444&quot;);
      list.add(&quot;555&quot;);
      list.add(&quot;666&quot;);
      list.add(&quot;777&quot;);
      list.add(&quot;888&quot;);
      list.add(2, &quot;000&quot;); (1)
      System.out.println(list);
  } </code></pre>
<p>运行：[111, 222, 000, 333, 444, 555, 666, 777, 888]</p>
<p>(1) 插入的含义就是往位置2插入元素，并且原先位置2及其后面所有元素往后移动一位。</p>
<ul>
<li><p>插入元素的源码</p>
<pre><code class="java">    public void add(int index, E element) {
        rangeCheckForAdd(index);

        ensureCapacityInternal(size + 1);  // Increments modCount!!
        System.arraycopy(elementData, index, elementData, index + 1,
                         size - index);
        elementData[index] = element;
        size++;
    }</code></pre>
<p>如上示例所示，源码可以清晰的看到：</p>
<p>(1) 检查插入的位置index &gt; size 或 index &lt; 0 都会抛出数组越界异常。</p>
<p>(2) 与新增元素一致的数组扩容算法。</p>
<p>(3) 将数组的当前位置的元素（index）的size-index个元素（即包含当前元素的后面所有元素），整体往后移动一位（index+1）。</p>
<p>(4) 当前腾出来的位置赋值。</p>
</li>
</ul>
<h2 id="使用场景选择-1"><a href="#使用场景选择-1" class="headerlink" title="使用场景选择"></a>使用场景选择</h2><p>先总结下ArrayList的优缺点，结合优缺点才能知道适用场景：</p>
<ul>
<li><p>优点：</p>
<ul>
<li>ArrayList底层以数组实现，是一种<strong>随机访问</strong>模式，再加上它实现了<strong>RandomAccess</strong>接口，因此查找（get）的时候非常的块。</li>
<li>ArrayList在<strong>顺序</strong>添加一个元素的时候非常方便，只是往数组添加一个元素而已，没有元素移动。</li>
</ul>
</li>
<li><p>缺点：</p>
<ul>
<li>删除元素的时候，涉及到一次元素复制，如果要复制的元素很多，就会比较耗费性能。</li>
<li>插入元素的时候，涉及到一次元素复制，如果要复制的元素很多，那么就会比较耗时。</li>
</ul>
</li>
<li><p>补充：</p>
<p>最快：一般来说插入与删除因为涉及元素复制，但是如果元素在数组的末尾，性能为O(1)。</p>
<p>最慢：元素在数组的第一个是最耗时的。</p>
</li>
</ul>
<h2 id="ArrayList与Vector的区别"><a href="#ArrayList与Vector的区别" class="headerlink" title="ArrayList与Vector的区别"></a>ArrayList与Vector的区别</h2><ul>
<li><p>ArrayList</p>
<p>未做任何同步，因此是非线程安全，如果要使用线程安全的List，可以借助<code>Collections.synchronizedList(list)</code>包装。</p>
</li>
<li><p>Vector</p>
<p>是ArrayList的线程安全版本，数据结构和实现与ArrayList基本一致，只是在其操作的方法上增加了 <code>synchronized</code>关键字。</p>
</li>
</ul>
<p><strong>总结区别：</strong></p>
<ul>
<li><p>Vector是线程安全的，ArrayList是非线程安全的。</p>
</li>
<li><p>Vector可以指定增长因子<code>capacityIncrement</code> ，如果指定了增长因子按照增长因子进行扩容，如果没有指定则容量增加两倍。如下面源码(1)所示：</p>
<ul>
<li><p>Vector扩容源码：</p>
<pre><code class="java">    private void grow(int minCapacity) {
        // overflow-conscious code
        int oldCapacity = elementData.length;
        int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ?
                                         capacityIncrement : oldCapacity);(1)
        if (newCapacity - minCapacity &lt; 0)
            newCapacity = minCapacity;
        if (newCapacity - MAX_ARRAY_SIZE &gt; 0)
            newCapacity = hugeCapacity(minCapacity);
        elementData = Arrays.copyOf(elementData, newCapacity);
    }</code></pre>
</li>
</ul>
</li>
</ul>
<h2 id="扩展：为什么ArrayList的elementData是用transient修饰的？"><a href="#扩展：为什么ArrayList的elementData是用transient修饰的？" class="headerlink" title="扩展：为什么ArrayList的elementData是用transient修饰的？"></a>扩展：为什么ArrayList的elementData是用transient修饰的？</h2><p>在ArrayList中定义的数据结构是数组，具体是这么定义的：</p>
<pre><code class="java">    transient Object[] elementData; // non-private to simplify nested class access</code></pre>
<p>可以看到elementData是用transient修饰的（注：Vector的elementData没有用transient修饰）。</p>
<p>再来看看ArrayList的定义：</p>
<pre><code class="java">public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;
        implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable</code></pre>
<p>ArrayList实现了Serializable接口，即是可以被序列化的，用transient修饰elementData意味着不希望elementData数组被序列化。</p>
<p>这是为什么呢？</p>
<p>因为序列化ArrayList的时候，ArrayList里面的elementData未必是满的，比方说elementData有10的大小，但是实际只用了其中3个，那么是否有必要序列化整个elementData呢？显然没有整个必要。</p>
<p>因此ArrayList中重写了writeObject方法：</p>
<pre><code class="java">    private void writeObject(java.io.ObjectOutputStream s)
        throws java.io.IOException{
        // Write out element count, and any hidden stuff
        int expectedModCount = modCount;
        s.defaultWriteObject();

        // Write out size as capacity for behavioural compatibility with clone()
        s.writeInt(size);

        // Write out all elements in the proper order.
        for (int i=0; i&lt;size; i++) {
            s.writeObject(elementData[i]);
        }

        if (modCount != expectedModCount) {
            throw new ConcurrentModificationException();
        }
    }</code></pre>
<p>每次序列化的时候调用这个方法，先调用defaultWriteObject()方法序列化ArrayList中的非transient元素，elementData不去序列化它，然后遍历elementData，只序列化那些有的元素，这样：</p>
<ol>
<li><p>加快了序列化的速度</p>
</li>
<li><p>减小了序列化之后的文件大小</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
        <category>集合</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>ArrayList</tag>
        <tag>Collection</tag>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title>【职业生涯】2016～2018工作总结</title>
    <url>/2018/10/12/2018-11-4-thinking-huawei-workreview/</url>
    <content><![CDATA[<p> 从技术角度总结我的第一份工作，15年校招入HW做SDN平台相关的工作，头一年做了HW vcenter设备的client sdk，属于碰壁摸索阶段。从16年开始做产品平台通信框架（resconf、rpc），17年产品开始向微服务架构转型，产品平台开始自建我们自己的容器框架以及配套的通信框架并重构，17、18年为产品转型上车奉献无数个日夜，直到离开。本篇博客主要总结近离开时近两年的事。是一个脉络包含了自己的思考，没有完整的叙述，是给我自己看的。后续我会伴随以后的工作慢慢完整、修复这些脉络，使其精简而丰满。</p>
<h1 id="一、微服务概念"><a href="#一、微服务概念" class="headerlink" title="一、微服务概念"></a>一、微服务概念</h1><p><a href="http://www.importnew.com/17588.html" target="_blank" rel="noopener">http://www.importnew.com/17588.html</a></p>
<p>什么是微服务（概念）</p>
<p>​         单体-&gt;SOA-&gt;微服务</p>
<h2 id="1、单体"><a href="#1、单体" class="headerlink" title="1、单体"></a>1、单体</h2><p>单体-&gt;一个WAR包</p>
<p>​        </p>
<p><strong>优先：</strong></p>
<p>开发简单直接，集中式管理</p>
<p>基本不会重复开发</p>
<p>功能都在本地，没有分布式管理的开销和调用通信开销</p>
<p><strong>缺点：</strong></p>
<p>开发效率低：所有开发都在一个项目上改代码，代码冲突</p>
<p>代码维护难：代码功能很容易耦合在一起，新人不知从何下手</p>
<p>部署不灵活：构建不灵活，必须重新构建整个项目，时间长</p>
<p>稳定性不高：一个小问题可能搞挂整改应用</p>
<p>扩展性不够：无法满足高并发，新增功能必须重新构建、部署整改应用</p>
<h2 id="2、SOA"><a href="#2、SOA" class="headerlink" title="2、SOA"></a>2、SOA</h2><p>没有去中心化，基于模块化的应用拆分，应用的交互依赖服务总线、</p>
<p>中间件服务器比如数据库、ETCD等独立的中间件进程为集群式部署、且服务端的信息相互共享不隔离。</p>
<h2 id="3、微服务"><a href="#3、微服务" class="headerlink" title="3、微服务"></a>3、微服务</h2><p>真正分布式的，去中心化的SOA，服务之间的不实例相互隔离，比如ETCD、数据库实例是相互隔离的。把服务内的逻辑封装在自己内部，把路由、消息解析放在服务内部，服务间轻量级通信（HTTP、跨进程的Global RPC）。</p>
<p>简单来说，微服务的目的是有效拆分应用，实现敏捷开发和部署。</p>
<ol>
<li>一些列的独立的服务共同组成系统</li>
<li>单独部署，跑在自己的进程里</li>
<li>每个服务为独立的业务开发</li>
<li>分布式的管理</li>
</ol>
<h2 id="4、怎么实践微服务"><a href="#4、怎么实践微服务" class="headerlink" title="4、怎么实践微服务"></a>4、怎么实践微服务</h2><h3 id="1）如何访问这么多拆分的微服务？"><a href="#1）如何访问这么多拆分的微服务？" class="headerlink" title="1）如何访问这么多拆分的微服务？"></a>1）如何访问这么多拆分的微服务？</h3><p>APIGateway：</p>
<p>提供统一的服务入口，让服务对前台透明</p>
<p>聚合后台的服务，节省流量，提升性能</p>
<p>提供安全、过滤、流控等管理功能</p>
<h3 id="2）服务之间如何通信？"><a href="#2）服务之间如何通信？" class="headerlink" title="2）服务之间如何通信？"></a>2）服务之间如何通信？</h3><p>同步调用（REST、RPC），我们现在REST也支持异步调用。实现简单、兼容性好</p>
<p>异步消息调用（Kafka,RMQ），消息有缓存、通信上来说存在弱一致</p>
<h3 id="3）服务怎么找？"><a href="#3）服务怎么找？" class="headerlink" title="3）服务怎么找？"></a>3）服务怎么找？</h3><p>注册中心（etcd或者zk做服务信息的分布式管理），服务可在本地做缓存，服务变更通知客户端。</p>
<p>提供寻址算法（负载均衡）</p>
<p>客户端做：架构简单，扩展灵活，只对注册中心依赖。大公司</p>
<p>服务端做：优化是简单，所有服务对于前台调用方透明。小公司。</p>
<h3 id="4）这么多服务，挂了怎么办？"><a href="#4）这么多服务，挂了怎么办？" class="headerlink" title="4）这么多服务，挂了怎么办？"></a>4）这么多服务，挂了怎么办？</h3><p>雪崩、调用链太长一个挂了 导致服务整个调用链不可用。</p>
<p>手段：</p>
<p>重试机制</p>
<p>限流</p>
<p>熔断机制</p>
<p>负载均衡</p>
<p>降级（本地缓存）</p>
<h3 id="5）微服务需要考虑的问题"><a href="#5）微服务需要考虑的问题" class="headerlink" title="5）微服务需要考虑的问题"></a>5）微服务需要考虑的问题</h3><p>API Gateway</p>
<p>服务间调用</p>
<p>服务发现</p>
<p>服务容错</p>
<p>服务部署</p>
<p>数据调用</p>
<p>优缺点：</p>
<p>优点</p>
<p>​    开发简单</p>
<p>​    技术栈灵活</p>
<p>根源    服务独立无依赖</p>
<p>​    独立按需扩展</p>
<p>​    可用性高</p>
<p>缺点</p>
<p>​    多服务运维难度</p>
<p>​    系统部署依赖</p>
<p>​    服务间通信成本</p>
<p>​    数据一致性</p>
<p>​    系统集成测试</p>
<p>​    重复工作根源</p>
<p>​    性能监控</p>
<h3 id="6）我们的架构和应用"><a href="#6）我们的架构和应用" class="headerlink" title="6）我们的架构和应用"></a>6）我们的架构和应用</h3><p>提供最精简的karaf容器底座</p>
<p>提供微服务打包的开发模板</p>
<p>提供微服务的restful通信开发模板</p>
<p>提供进程间通信（restful、rpc）的调用框架</p>
<h1 id="二、微服务进程间通信"><a href="#二、微服务进程间通信" class="headerlink" title="二、微服务进程间通信"></a>二、微服务进程间通信</h1><p><strong>服务自动发现，注册，上下线更新</strong></p>
<p><strong>关联技术：websocket</strong></p>
<p><strong>服务性能（本地缓存优化）</strong></p>
<p>1）注册时建立服务的依赖关系，以及class访问时与path的对应关系，path与实例的映射，实例自动缓存在本地，这样class访问时自动映射到实例地址</p>
<p>2）服务实例变更通知，采用disruptor框架将消息广播出去，便于其他业务获取服务信息</p>
<p><strong>关联技术：缓存方式设计、disruptor框架</strong></p>
<p>服务路由的负载均衡</p>
<p>用户自由扩展路由策略</p>
<p><strong>关联技术：反射</strong></p>
<p><strong>服务可靠性</strong></p>
<p>注册中心容错、服务的容错熔断</p>
<p><strong>服务间通信</strong></p>
<p>1）流程：</p>
<p>Swagger生成开发模板-&gt;</p>
<p>请求方式从restful调用转换为API调用-&gt;</p>
<p>反射获取服务的API实例-&gt;</p>
<p>框架将API注解扫描，并解析出注解上的Path加入本地缓存-&gt;</p>
<p>调用API的方法，找到请求的方法对应的Path-&gt;</p>
<p>然后通过path和class信息找到实例地址-&gt;</p>
<p>然后调用转换为HTTP请求发送过去。</p>
<p><strong>关联技术：反射</strong></p>
<p>2）通信方式（REST、RPC）</p>
<p><strong>关联技术：同步REST、异步REST（jetty client、jetty server）</strong></p>
<p>3）序列化反序列化</p>
<p><strong>关联技术：fastxml.jackson</strong> <strong>不同序列化框架的性能对比，工作原理，为什么快？</strong></p>
<p>​        </p>
<p><strong>最终一致性</strong></p>
<p>事件通知型（可靠事件通知型（同步事件、异步事件）、最大努力通知模式）</p>
<p>补偿型（TCC模式、业务补偿）</p>
<h1 id="三、Jetty"><a href="#三、Jetty" class="headerlink" title="三、Jetty"></a>三、Jetty</h1><p>Jetty架构</p>
<p>Jetty的原理</p>
<p>Jetty热加载等其他特性</p>
<p><strong>关联技术：java NIO机制、HTTP1.1/HTTP2协议、servlet机制</strong></p>
<h1 id="四、Jersey"><a href="#四、Jersey" class="headerlink" title="四、Jersey"></a>四、Jersey</h1><p>原理</p>
<p>序列化反序列化</p>
<p><strong>关联技术：servlet机制、javax-ws-rs协议、反射、序列化框架</strong></p>
<h1 id="五、WebApp统一鉴权框架"><a href="#五、WebApp统一鉴权框架" class="headerlink" title="五、WebApp统一鉴权框架"></a>五、WebApp统一鉴权框架</h1><p>注册原理</p>
<p>优化</p>
<p>Servlet规范和原理</p>
<p><strong>关联技术：servlet机制、osgi机制、jetty api使用</strong></p>
<h1 id="六、性能数据上报"><a href="#六、性能数据上报" class="headerlink" title="六、性能数据上报"></a>六、性能数据上报</h1><p>上报流程</p>
<p>上报优化（报文合并分批上报）</p>
<p><strong>关联技术：kafka</strong>、<strong>优化思路</strong></p>
<h1 id="七、大容量——restful异步、HTTP2"><a href="#七、大容量——restful异步、HTTP2" class="headerlink" title="七、大容量——restful异步、HTTP2"></a>七、大容量——restful异步、HTTP2</h1><p>Jetty httpclient 异步</p>
<p>Jetty server 异步</p>
<p>Jersey异步</p>
<p>Jetty对HTTP2协议实现</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>最后，我是一个不盲目追求新技术的人，力求看透技术的本质，这往往是最困难的。技术只是工具，我想一旦你明白同类工具的原理，你一定能举一反三，了解你不曾使用的工具。技术是永远学不完的，对新技术保持热情，又不盲目随从，注重基础，看清本质，方能走得更远。</p>
]]></content>
      <categories>
        <category>职业生涯</category>
      </categories>
      <tags>
        <tag>work summary</tag>
      </tags>
  </entry>
  <entry>
    <title>HTTP/2特性总结</title>
    <url>/2015/11/11/http2-features-introduce/</url>
    <content><![CDATA[<p>HTTP/2 更简单，高效，强大。它在传输层解决了以前我们HTTP1.x中一直存在的问题。使用它可以优化我们的应用。HTTP/2 的首要目标是通过完全的请求，响应多路复用，头部的压缩头部域来减小头部的体积，添加了请求优先级，服务端推送。为了支持这些特性，他需要大量的协议增加头部字段来支持。例如新的流量控制，差错处理，升级机制。而这些是每个web开发者都应该在他们的应用中用到的。HTTP/2并没有在应用中改变HTTP的语义，而是通过在客户端和服务端传输的数据格式(frame)和传输。它通过在新的二进制帧层控制整个过程以及隐藏复杂性，而这不需要改变原来有的东西就可以实现。</p>
<h1 id="1-HTTP2的设计和目标"><a href="#1-HTTP2的设计和目标" class="headerlink" title="1.HTTP2的设计和目标"></a>1.HTTP2的设计和目标</h1><ul>
<li>HTTP2更简单，高效，强大。解决了HTTP1.x中一直存在的问题。（待扩展）</li>
<li>特点：响应多路复用、头部压缩、请求优先级、服务端推送等。</li>
<li>解决问题：HTTP1.x需要开启多个连接来实现并发和潜在影响。HTTP1.x的头部没有压缩，造成不必要的网络拥塞。HTTP1.x没有应用资源优先级，导致重要TCP连接的糟糕使用。</li>
</ul>
<h1 id="2-二进制帧"><a href="#2-二进制帧" class="headerlink" title="2.二进制帧"></a>2.二进制帧</h1><p>性能提升的核心在于二进制帧。指HTTP消息在客户端和服务端何如封装和传输。</p>
<p><img data-src="https://upload-images.jianshu.io/upload_images/5281821-5e2e23de6cbbc698.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/607/format/webp" alt=""></p>
<p>这一层主要是将原先的应用层HTTP1.1的txt文本传输转换为headers与data等二进制帧。HTTP1.x阶段采用的换行分割文本不同，HTTP2消息分成很小的消息和frame。然后每个消息和frame用二进制编码。客户端和服务端都用二进制编码和解码。HTTP1.x的客户端不能与只有HTTP2的服务端通信。不过这对应用来说高层的API没什么变化，只在底层的消息二进制格式和编解码上的变化来改变性能。</p>
<h1 id="3-流、消息，帧"><a href="#3-流、消息，帧" class="headerlink" title="3.流、消息，帧"></a>3.流、消息，帧</h1><p>下面介绍下二进制帧机制，明白数据如何在客户端和服务端交互。</p>
<blockquote>
<p><strong>流</strong>：已经建立的连接之间双向流动的字节，它能携带一个至多个消息。</p>
<p><strong>消息</strong>：一个完整的帧序列，它映射到逻辑的请求和响应消息。</p>
<p><strong>帧</strong>：在HTTP2通信的最小单位。每个帧包括一个帧头，里面有个很小标志，来区分属于哪个流。</p>
</blockquote>
<ul>
<li>所有的通信都建立在一个TCP连接上，可以传递大量的双向流通的流。</li>
<li>每个流都有独一无二的标志和优先级。</li>
<li>每个消息都是逻辑上的请求和响应消息。由一个活多个帧组成。</li>
<li>来自不同流的帧可以通过帧头的标志关联和组装起来。</li>
</ul>
<p><img data-src="https://upload-images.jianshu.io/upload_images/5281821-7b0c2aa12ccc6d42.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/603/format/webp" alt=""></p>
<h1 id="4-请求和响应的多路复用"><a href="#4-请求和响应的多路复用" class="headerlink" title="4.请求和响应的多路复用"></a>4.请求和响应的多路复用</h1><p>在HTTP1.x中，用户想要多个并行的请求来提供性能，必须得使用多个TCP连接。它能保证在每个连接中在一个时间点只有个响应被发送出去。糟糕的是，它使得队头阻塞和重要TCP连接的低效使用。在HTTP2中，新的二进制帧层解除了这个限制。使得所有的请求和响应可以多路复用。通过允许客户端和服务端把HTTP消息分解成独立的帧，交错的传输，然后在另一端组装。</p>
<p><img data-src="https://upload-images.jianshu.io/upload_images/5281821-ce9d374b7d0adf09.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/654/format/webp" alt=""></p>
<p>上图显示了在一次连接中的多个流。客户端传输帧到服务端(stream5)。服务端传输交错的帧序列(stream1，stream3)到客户端。此时，同时存在并行的3个流。能够把HTTP消息分解成交错的帧，并在另一端组装它们是HTTP2中一个非常重要的提高。</p>
<ul>
<li>交错的多个并行的请求，而不需要阻塞。</li>
<li>使用一个连接传递所有的并行的请求和响应。</li>
<li>移除HTTP1.x中没有的必要的解决方法。例如级联文件，域分片。</li>
<li>淘汰没必要的潜在因素来降低页面载入的时间，提升可用网络容积的使用率。</li>
</ul>
<p>新的二进制帧层解决了HTTP1.x中头部阻塞的问题，在并行处理和传输的请求和响应不再需要多个连接，这使得我们的应用更简单，快捷和便宜。</p>
<h1 id="5-流的优先级"><a href="#5-流的优先级" class="headerlink" title="5.流的优先级"></a>5.流的优先级</h1><p>为了能方便的传输顺序，HTTP2提出，使每个流有一个权重和依赖。</p>
<ul>
<li>每个流的权重值1~256之间</li>
<li>每个流可以详细给出对其他流的依赖</li>
</ul>
<p>流权重和依赖的结合使客户端可以构造和通信一个优先级二叉树来表达它更想得到哪种响应。然后服务端可以按权重分配硬件资源（CPU，内存）。</p>
<p><img data-src="https://upload-images.jianshu.io/upload_images/5281821-a424cc207432cde0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/666/format/webp" alt=""></p>
<p>在HTTP2，一个流的依赖可以显式用其他流的标志来表达，如果省略了标志，则说明它的依赖是根流。一般来说，父流应该在它的依赖流之前分配资源。例如D应该是C之前被发送。依赖于同一个父节点的应该按照他们的权重分配资源。例如A节点的权重为12，它的兄弟结点B的结点权重为4。然后按分配资源，A占12/16，B占4/16。如上面所述，流的依赖和权重提供了一种很好的表达式语言来表达资源的优先级。但是，流的依赖和权重只是提供了一种传输偏好，而不是说一定是这样的比例。</p>
<h1 id="6-每个源一个连接"><a href="#6-每个源一个连接" class="headerlink" title="6.每个源一个连接"></a>6.每个源一个连接</h1><p>HTTP2.0的连接是持久的，每个源仅仅需要一个连接。大部分HTTP的传输是短的，并且突然的。然而TCP连接却适合长期存活，批量的数据传输。通过利用相同的HTTP2连接，既能够充分利用TCP连接，也能够减少整体协议的头部。更进一步来说，更少的连接内存的占用以及全连接路径的处理过程。向HTTP2的转移不仅减少了网络潜在因素，更减少了操作代价。</p>
<blockquote>
<p>Tips：减少连接，同时也提高了HTTPS的性能，因为仅需要更少的TLS层的握手。</p>
</blockquote>
<h1 id="7-流量控制"><a href="#7-流量控制" class="headerlink" title="7.流量控制"></a>7.流量控制</h1><p>流量控制是一种机制，用来阻止发送者发送大量的接受者不需要的或者没能力处理的数据。接收者可能会在重负下繁忙，或者只愿意分配固定的资源给特定的流。例如，客户端可能以高的优先级请求大量的视频数据，然后暂停了视频，那么客户端现在想要停止或者减少服务端的传输来避免取和缓存没必要的数据。或者一个代理服务器连接有很快的下流，很慢的上流。同样的也要控制以多大的流速传输数据，从而匹配上流的速度，从而控制资源的使用。</p>
<p>这些需求可能让你想起了TCP流量控制，由于HTTP2的那些流是在一个TCP的连接上。那么TCP连接不够细粒度，也没能够提供应用级的API来控制单个流的传输。为了应对这种情况，HTTP2提供了一系列的简单方法，来允许客户端和服务端实现他们自己的流级别的，连接级别的流量控制。</p>
<ul>
<li>流量控制是有方向的，每个流和连接，每个接收者可以设置它想用窗口的大小。</li>
<li>流量控制是基于信用的。每个接收者通告其初始连接和流量控制窗口（以字节为单位），只要发送者发送数据帧并通过接受者发送的WINDOW_UPDATE帧递增，该窗口就会减少。</li>
<li>流量控制不能禁用。当建立HTTP2连接时，客户端和服务端交换SETTINGS帧，这些帧设置双向流量控制窗口的大小。流量控制窗口的默认设置65535字节，但接收方可以设置更大的最大窗口大小。（2的31次方-1），并通过在接收到任何数据时发送WINDOW_UPDATE帧来维护它。</li>
<li>流量控制是逐跳的，而不是端到端的。也就是，一个中介可以使用它控制资源的使用，从而根据自己的标准和启发式实现资源分配机制。</li>
</ul>
<p>HTTP2没有规定用于实现流量控制的任何特定算法。相反，它提供了简单的构建模块并将实现推迟到客户端和服务器，这可以用它来实现自定义策略来调节资源使用和分配，以及实现新的传输功能。</p>
<p>例如，应用程序层流量控制允许浏览器仅提取特定资源的一部分，通过将流量控制窗口降至零来暂停提取，然后稍后恢复。例如，获取预览或第一预览图像，显示图像并允许进行其他高优先级操作，并在关键资源完成加载后又开始取。</p>
<h1 id="7-服务端推送"><a href="#7-服务端推送" class="headerlink" title="7.服务端推送"></a>7.服务端推送</h1><p>HTTP2的另一个强大的新功能是服务器为单个客户端请求发送多个响应的能力。也就是说，除了对原始请求的响应之外，服务器还可以向客户端推送额外的资源（如下图），而不需要客户端请求每一个资源！</p>
<p><img data-src="https://upload-images.jianshu.io/upload_images/5281821-d97e0c65b1491baa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/636/format/webp" alt=""></p>
<p>为什么需要在浏览器中使用这种机制？一个典型的Web应用程序由几十个资源组成，所有这些资源都是客户端通过检查服务器提供的文档发现的。因此，为什么不消除额外的延迟并让服务器推送相关资源？服务器已经知道客户端需要哪些资源；这是服务器推送。</p>
<ul>
<li>推送的资源可以由客户端缓存</li>
<li>推送的资源可以在不同的页面上重复使用</li>
<li>推送的资源可以与其他资源一起复用</li>
<li>推送的资源可以由服务器优先</li>
<li>推送的资源可以被客户拒绝</li>
</ul>
<p>每个推送的资源都是一个流，与内联资源不同，它允许客户端对其单独复用，优先化和处理。由浏览器执行的唯一安全限制是推送资源必须遵守同源策略；服务器必须对提供的内容具有权限。</p>
<h1 id="8-头部压缩"><a href="#8-头部压缩" class="headerlink" title="8.头部压缩"></a>8.头部压缩</h1><p>每个HTTP传输都包含一组描述传输资源及其属性的标题。在HTTP/1.x中，此元数据始终以纯文本形式发送，并每次传输的开销都会在任何位置增加500~800字节，如果使用HTTP Cookie，则会增加数千字节。为了减少这种开销并提高性能，HTTP2使用两种简单但强大的技术使用HPACK压缩格式（算法了解<a href="[https://imququ.com/post/header-compression-in-http2.html](https://link.jianshu.com/?t=https%3A%2F%2Fimququ.com%2Fpost%2Fheader-compression-in-http2.html)"></a>）来压缩请求和响应头元数据：</p>
<ul>
<li>它允许通过静态霍夫曼编码对传输的头部字段进行编码，从而减少它们各自的传输大小。</li>
<li>它要求客户端和服务端都维护和更新先前看到的标题字段的索引列表（即，建立共享压缩上下文），然后将其用作参考以高效编码先前传输的值。</li>
</ul>
<p>霍夫曼编码允许单个值在传输时被压缩，并且先前传输值得索引列表允许我们通过传输索引值来编码重复值（下图），索引值可用于有效地查找和重建完整头部键和值。</p>
<p><img data-src="https://upload-images.jianshu.io/upload_images/5281821-38055e8dde4b4436.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/654/format/webp" alt=""></p>
<p>作为进一步优化，HPACK压缩上下文由静态和动态表组成：静态表在规范中定义，并提供给所有连接可能使用的常见HTTP头部字段的列表（例如，有效头名称）。动态表最终是空的，并基于特定连接内的交换值进行更新。因此，通过对以前未见过的值使用静态霍夫曼编码，并将索引替换为已存在与客户端和服务端静态或动态表中的值得索引，可以减少每个请求的大小。</p>
<h1 id="9-二进制帧的简短介绍"><a href="#9-二进制帧的简短介绍" class="headerlink" title="9.二进制帧的简短介绍"></a>9.二进制帧的简短介绍</h1><p>HTTP2改进的核心是新的二进制帧层。与以换行符分割的纯文本HTTP1.x协议相比，二进制框架提供了更紧凑的表示形式，可以更高效地处理并更容易正确实现。</p>
<p>一旦建立了HTTP2连接，客户端和服务端就通过交换帧来进行通信，这些帧用作协议内最小的通信单元。所有帧共享一个共同的9字节头，其中包含帧的长度，类型，标志位字段和31位流标识符。</p>
<p><img data-src="https://upload-images.jianshu.io/upload_images/5281821-d8687e8eed1e6823.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/642/format/webp" alt=""></p>
<ul>
<li>24位长度字段：允许一个帧携带2的24次方数据字节。</li>
<li>8位类型字段：确定帧的格式和语义。</li>
<li>8位标志字段：传递帧类型特定的布尔标志。</li>
<li>31位流标识符：唯一标识HTTP/2流。</li>
</ul>
<blockquote>
<p>从技术上讲，长度字段允许每帧高达字段（<del>16MB）的有效载荷。但是，HTTP2标准将DATA帧的默认最大有效负载大小设置为每帧字节（</del>16KB），并允许客户端和服务器协商较高的值。更大并不总是更好：较小的帧大小能够实现高效的多路复用并将头部阻塞降至最低。</p>
</blockquote>
<h1 id="10-分析二进制帧数据流"><a href="#10-分析二进制帧数据流" class="headerlink" title="10.分析二进制帧数据流"></a>10.分析二进制帧数据流</h1><p>掌握了不同的帧类型的只是后，现在可以重新看下前面在请求和响应复用中遇到的图（下图）并分析HTTP2交换：</p>
<p><img data-src="https://upload-images.jianshu.io/upload_images/5281821-b28c3451bc8fc3fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/682/format/webp" alt=""></p>
<ul>
<li>有三个流，ID设置为1,3和5</li>
<li>所有三个流ID都是奇数；所有这三个都是客户端启动的流。（即发起方是客户端）</li>
<li>在这个交换中没有服务器启动（“推送”）流。（即服务器推送）</li>
<li>服务器正在为流1发送交错数据帧，这些数据帧携带应用程序响应客户端先前的请求。</li>
<li>服务器已经在数据帧之间为流3交错了HEADERS和DATA帧，以便实现流1响应流1响应多路复用。</li>
<li>客户端正在传输数据流5的数据帧，这表明HEADERS帧已在先传输。</li>
</ul>
<p>当然，上述分析基于实际HTTP2交换的简化标识，但它依然说明了新协议的很多优点和特点。</p>
]]></content>
      <categories>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>HTTP</tag>
        <tag>HTTP2</tag>
      </tags>
  </entry>
  <entry>
    <title>【Jetty源码阅读系列】二、连接管理</title>
    <url>/2015/11/05/jetty-source-connection/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Jetty</category>
      </categories>
      <tags>
        <tag>Jetty</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown学习笔记</title>
    <url>/2015/11/04/2018-11-4-markdown-studying-knowledage/</url>
    <content><![CDATA[<p><strong>1、标题</strong></p>
<h1 id="这是一级标题"><a href="#这是一级标题" class="headerlink" title="这是一级标题"></a>这是一级标题</h1><h2 id="这是二级标题"><a href="#这是二级标题" class="headerlink" title="这是二级标题"></a>这是二级标题</h2><h3 id="这是三级标题"><a href="#这是三级标题" class="headerlink" title="这是三级标题"></a>这是三级标题</h3><h4 id="这是四级标题"><a href="#这是四级标题" class="headerlink" title="这是四级标题"></a>这是四级标题</h4><h5 id="这是五级标题"><a href="#这是五级标题" class="headerlink" title="这是五级标题"></a>这是五级标题</h5><p><strong>2、字体</strong></p>
<p><strong>这是加粗的文字</strong></p>
<p><em>这是倾斜的文字</em></p>
<p><strong><em>这是斜体加粗的文字</em></strong></p>
<p><del>这是加删除线的文字</del></p>
<p><strong>3、引用</strong></p>
<blockquote>
<p>这是引用的内容</p>
<blockquote>
<p>这是引用的内容</p>
<blockquote>
<p>这是引用的内容</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>4、分割线</strong></p>
<hr>
<hr>
<hr>
<p><strong>5、图片</strong></p>
<p><img data-src="F:%5CA7R3%E7%85%A7%E7%89%87%E5%AF%BC%E5%87%BA%5C2018.10.28%E7%AC%AC%E4%B8%89%E6%AC%A1%E5%8E%BB%E6%B3%B0%E8%BF%AA%5CDSC04322-3.jpg" alt=""></p>
<p><strong>6、超链接</strong></p>
<p><a href="超链接测试地址">这是我的超链接</a></p>
<p><strong>7、链表</strong></p>
<ul>
<li><p>列表内容</p>
</li>
<li><p>列表内容</p>
</li>
<li><p>列表内容</p>
</li>
</ul>
<p>1.有序列表<br>2.有序列表<br>3.有序列表</p>
<ul>
<li>列表嵌套</li>
</ul>
<p>上一级和下一级之间敲三个空格即可</p>
<ul>
<li><p>一级无须列表内容</p>
<ul>
<li>二级无序列表</li>
<li>二级有序列表</li>
</ul>
<ol>
<li>三级有序列表</li>
<li>三级有序列表</li>
</ol>
<ul>
<li>二级无序列表<ul>
<li>三级无序列表<ul>
<li>四级无序列表</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>8、表格</strong></p>
<table>
<thead>
<tr>
<th>表头</th>
<th align="center">表头</th>
<th align="right">表头</th>
</tr>
</thead>
<tbody><tr>
<td>内容</td>
<td align="center">内容</td>
<td align="right">内容</td>
</tr>
<tr>
<td>内容</td>
<td align="center">内容</td>
<td align="right">内容</td>
</tr>
</tbody></table>
<p>第二行分割表头和内容。</p>
<p>有一个就行，为了对齐，多加了几个<br>文字默认居左<br>-两边加：表示文字居中<br>-右边加：表示文字居右<br>注：原生的语法两边都要用 | 包起来。此处省略</p>
<p><strong>9、代码</strong></p>
<p>单行代码：代码之间分别用一个反引号包起来</p>
<p><code>System.out.println(&quot;hello world&quot;)</code></p>
<p>代码块：代码之间分别用三个反引号抱起来，且两边的反引号独占一行</p>
<pre><code class="java">public class A
{
    public static void main(String[] args)
    {
        String a = &quot;abc&quot;;
        System.out.println(a);
        if ( a != null)
        {
            System.out.println(&quot;hello world!&quot;);
        }
    }
}</code></pre>
]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
</search>
