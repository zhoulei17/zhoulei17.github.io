
<!DOCTYPE html>
<html lang="en">


<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
  <meta name="theme-color" content="#202020"/>
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>
  
  
    <meta name="keywords" content="随机梯度下降,有监督,线性回归," />
  

  
    <meta name="description" content="【NLP】一、线性回归与随机梯度下降法" />
  
  
  
  <link rel="icon" type="image/x-icon" href="/images/footer-logo.png">
  
  <title>【NLP】一、线性回归与随机梯度下降法 [ Hexo ]</title>
  
    <!-- stylesheets list from config.yml -->
    
      <link rel="stylesheet" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css">
    
      <link rel="stylesheet" href="/css/xoxo.css">
    
  
<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <div class="nav-container">
    <nav class="home-menu pure-menu pure-menu-horizontal">
  <a class="pure-menu-heading" href="/">
    
    <span class="title" style="text-transform:none">Hexo</span>
  </a>

  <ul class="pure-menu-list clearfix">
      
          
            
              <li class="pure-menu-item"><a href="/" class="pure-menu-link">Home</a></li>
            
          
      
          
            
              <li class="pure-menu-item pure-menu-has-children pure-menu-allow-hover">
            
              <a href="#" id="post" class="pure-menu-link">文章</a>
              <ul class="pure-menu-children">
              
                  
                    <li class="pure-menu-item"><a href="/categories" style="color:#202020;" class="pure-menu-link">Categories</a></li>
                  
              
                  
                    <li class="pure-menu-item"><a href="/archives" style="color:#202020;" class="pure-menu-link">Archives</a></li>
                  
              
                  
                    <li class="pure-menu-item"><a href="/tags" style="color:#202020;" class="pure-menu-link">Tags</a></li>
                  
              
              </ul>
            </li>
          
      
          
            
              <li class="pure-menu-item"><a href="/paper" class="pure-menu-link">Papers</a></li>
            
          
      
          
            
              <li class="pure-menu-item"><a href="/project" class="pure-menu-link">项目</a></li>
            
          
      
          
            
              <li class="pure-menu-item"><a href="/activity" class="pure-menu-link">动态</a></li>
            
          
      
          
            
              <li class="pure-menu-item"><a href="/search" class="pure-menu-link">Search</a></li>
            
          
      
  </ul>
   
</nav>

  </div>

  <div class="container" id="content-outer">
    <div class="inner" id="content-inner">
      <div class="post-container">
  <article class="post" id="post">
    <header class="post-header text-center">
      <h1 class="title">
        【NLP】一、线性回归与随机梯度下降法
      </h1>
      <span>
        
        <time class="time" datetime="2019-11-26T16:00:00.000Z">
        2019-11-27
      </time>
        
      </span>
      <span class="slash">/</span>
      <span class="post-meta">
      <span class="post-tags">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%9C%89%E7%9B%91%E7%9D%A3/" rel="tag">有监督</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" rel="tag">线性回归</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/" rel="tag">随机梯度下降</a></li></ul>
      </span>
    </span>
      <span class="slash">/</span>
      <span class="read">
      <span id="busuanzi_value_page_pv"></span> 点击
    </span>
      <span class="slash">/</span>
      <span class="read">阅读耗时 9 分钟</span>
    </header>

    <div class="post-content">
      <p>在NLP的学习中，我们了解熵、信息熵、交叉熵的基础概念，通过将熵（信息量的度量）的计算转换为概率模型的计算，然后介绍了在一些语料库中的样本中，计算出一些词与其他词同时出现在一个句子或者短语的概率，引入了N-gramm的概念，但是N个词的N-gramm的概率非常难以计算而且计算出的概率很小，因此一般使用bigram model计算（即认为当前词只与前面那个词相关）但这种方式相对不够精确。</p>
<p>如果我们把一个词放在整改语料库里去看，并利用当前语料库的输入（one hot represetation）通过神经网络模型计算损失函数的最优解（参数众多），以此来预测其他词出现的情况，这里就会用到一个基础的线性回归的方法——随机梯度法的概念。神经网络是通用方法，而基础就是基于线性回归的方法，线性回归最基础的方法就是梯度下降，因此理解线性回归以及他的基本方法随机梯度下降非常重要。</p>
<p>本篇文章就以机器学习中常用的线性回归的基本方法——随机梯度下降进行总结。</p>
<p>下面就一个实际的线性回归问题：<strong>如何预测房价</strong>作为引入。</p>
<h1 id="一、问题：如何预测房价？"><a href="#一、问题：如何预测房价？" class="headerlink" title="一、问题：如何预测房价？"></a>一、问题：如何预测房价？</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p><img src="/img/in-post/image-20200102230850144.png" alt=""></p>
<p>已知一些面积对应的房价的样本数据，利用这些样本数据预测其他面积的房价。</p>
<p>这是一个监督学习的例子，因为例子中每个点都有明确的“正确答案”，如1000平的房子在170W美金，预测出的某个平方的房子也一定有明确的价钱。同时这也是监督学习中典型的回归问题，输出是一个具体指（当然另外一种典型的监督学习问题是分类，用来预测离散值的输出）。</p>
<h2 id="训练集"><a href="#训练集" class="headerlink" title="训练集"></a>训练集</h2><p><img src="/img/in-post/image-20200103005523817.png" alt=""></p>
<p><img src="/img/in-post/image-20200103005727295.png" alt=""></p>
<h1 id="二、模型定义"><a href="#二、模型定义" class="headerlink" title="二、模型定义"></a>二、模型定义</h1><p><img src="/img/in-post/image-20200103005804747.png" alt=""></p>
<p>可以用一个一元线性函数去拟合样本数据，利用拟合出的函数去预测其他未知数据。</p>
<p><strong>具体怎么拟合呢？</strong>下面看看怎么实现。</p>
<h1 id="三、如何实现"><a href="#三、如何实现" class="headerlink" title="三、如何实现"></a>三、如何实现</h1><p><img src="/img/in-post/image-20200103011806806.png" alt=""></p>
<p><img src="/img/in-post/image-20200103011906592.png" alt=""></p>
<p><img src="/img/in-post/image-20200103011919467.png" alt=""></p>
<p>即单个样本的最小问题转化为：</p>
<p><img src="/img/in-post/image-20200103012030839.png" alt=""></p>
<p>使此式的指最小，即通过假设函数h(x)计算出的值与实际样本中的y之间的差异最小的问题。</p>
<p>对所有样本来说，假设样本有M个点，即求i=1到i=M样本的差值的平方和。</p>
<p><img src="/img/in-post/image-20200103012351585.png" alt=""></p>
<h1 id="四、定义代价函数"><a href="#四、定义代价函数" class="headerlink" title="四、定义代价函数"></a>四、定义代价函数</h1><p><img src="/img/in-post/image-20200103012500164.png" alt=""></p>
<h1 id="五、代价函数的求解过程"><a href="#五、代价函数的求解过程" class="headerlink" title="五、代价函数的求解过程"></a>五、代价函数的求解过程</h1><h2 id="简化假设函数和代价函数求解"><a href="#简化假设函数和代价函数求解" class="headerlink" title="简化假设函数和代价函数求解"></a>简化假设函数和代价函数求解</h2><p><img src="/img/in-post/image-20200103012711613.png" alt=""></p>
<p>先列出假设函数和代价函数的定义，目标是使代价函数的最小。为了方便计算我们使用右边的简化版进行手动推倒。</p>
<ul>
<li><p>步骤一、</p>
<p><img src="/img/in-post/image-20200103012928258.png" alt=""></p>
</li>
<li><p>步骤二、</p>
</li>
</ul>
<p><img src="/img/in-post/image-20200103012954273.png" alt=""></p>
<ul>
<li><p>步骤三、</p>
<p><img src="/img/in-post/image-20200103013011186.png" alt=""></p>
</li>
<li><p>步骤四、五 发现计算出的代价函数值越来越大，即越来越不接近实际样本值。因此取步骤1的假设值。</p>
</li>
</ul>
<h2 id="恢复两个参数的假设函数和代价函数的版本"><a href="#恢复两个参数的假设函数和代价函数的版本" class="headerlink" title="恢复两个参数的假设函数和代价函数的版本"></a>恢复两个参数的假设函数和代价函数的版本</h2><p><img src="/img/in-post/image-20200103013416357.png" alt=""></p>
<p>其手动拟合的过程如下：</p>
<p><img src="/img/in-post/image-20200103013441570.png" alt=""></p>
<h1 id="六、随机梯度法"><a href="#六、随机梯度法" class="headerlink" title="六、随机梯度法"></a>六、随机梯度法</h1><p>上面讲了线性回归手动去尝试计算代价函数一次来求得假设函数的最优函数。实际在工程中是不可能没有规律的去尝试取不同的参数值计算的。必须满足一定的规律来求解，以保证收敛。</p>
<ul>
<li><p><strong>目标定义</strong></p>
<p><img src="/img/in-post/image-20200103013855639.png" alt=""></p>
</li>
<li><p><strong>求解过程</strong></p>
<p><img src="/img/in-post/image-20200103013918848.png" alt=""></p>
</li>
</ul>
<h2 id="随机梯度下降的公式推导"><a href="#随机梯度下降的公式推导" class="headerlink" title="随机梯度下降的公式推导"></a>随机梯度下降的公式推导</h2><p><img src="/img/in-post/image-20200103014119287.png" alt=""></p>
<p>将上文提到的代价函数带入随机梯度下降的公式中：</p>
<p><img src="/img/in-post/image-20200103014153175.png" alt=""></p>
<p><img src="/img/in-post/image-20200103014236092.png" alt=""></p>
<p><img src="/img/in-post/image-20200103014342482.png" alt=""></p>
<p><img src="/img/in-post/image-20200103014514092.png" alt=""></p>
<p>慢慢拟合</p>
<p><img src="/img/in-post/image-20200103014754500.png" alt=""></p>
<p>最后找到全局最小值，假设函数得出的数据很好的收敛了房价的价格数据。</p>
<p>得到了假设函数的参数后就可以使用实际的函数来预测房价了。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol>
<li><p>线性回归问题实际就是求代价函数的问题，通过代价函数的最优化去拟合得出最合适的假设函数。</p>
</li>
<li><p>求解代价函数的典型方法和最常用的就有随机梯度下降法，本例中使用的随机梯度下降叫：<strong>Batch梯度下降</strong>：即使用所有的样本数据。</p>
</li>
<li><p>当然像这种简单的线性回归也可以使用正规方程组求解代价函数J的最小值。梯度下降适合更大的数据集。</p>
<p>本文中也没有讲多元函数的随机梯度下降法。主要是通过简单的例子理解随机梯度下降。为理解神经网络以及在NPL中的相关应用做理论准备。</p>
</li>
</ol>

    </div>

  </article>
  <div class="toc-container">
    
  <div id="toc" class="toc-article">
    <strong class="toc-title">Posts</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#一、问题：如何预测房价？"><span class="toc-text">一、问题：如何预测房价？</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#问题描述"><span class="toc-text">问题描述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#训练集"><span class="toc-text">训练集</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#二、模型定义"><span class="toc-text">二、模型定义</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#三、如何实现"><span class="toc-text">三、如何实现</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#四、定义代价函数"><span class="toc-text">四、定义代价函数</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#五、代价函数的求解过程"><span class="toc-text">五、代价函数的求解过程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#简化假设函数和代价函数求解"><span class="toc-text">简化假设函数和代价函数求解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#恢复两个参数的假设函数和代价函数的版本"><span class="toc-text">恢复两个参数的假设函数和代价函数的版本</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#六、随机梯度法"><span class="toc-text">六、随机梯度法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#随机梯度下降的公式推导"><span class="toc-text">随机梯度下降的公式推导</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#总结"><span class="toc-text">总结</span></a></li></ol>
  </div>


  </div>
</div>
<div class="copyright">
    <span>本作品采用</span>
    <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener">知识共享署名 4.0 国际许可协议</a>
    <span>进行许可。 转载时请注明原文链接。</span>
</div>


  
    <div class="post-nav">
      <div class="post-nav-item post-nav-next">
        
          <span>〈 </span>
          <a href="/2019/11/27/Json%20Facet/" rel="next" title="【Solr应用】——Json Facet使用总结">
          【Solr应用】——Json Facet使用总结
          </a>
        
      </div>
  
      <div class="post-nav-item post-nav-prev">
          
          <a href="/2019/11/27/java-concurrency-container-Executor/" rel="prev" title="【并发容器和框架】四、Executor框架">
            【并发容器和框架】四、Executor框架
          </a>
          <span>〉</span>
        
      </div>
    </div>
  

    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
    <div id="gitalk-container"></div>
    <script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
    <script type="text/javascript">
        var gitalk = new Gitalk({
            clientID: 'xxx',
            clientSecret: 'xxx',
            id: window.location.pathname,
            repo: 'issue repo name',
            owner: 'Github username',
            admin: 'github username'
        })
        gitalk.render('gitalk-container')
    </script>



    </div>

    

  </div>
  <footer class="footer text-center">
    <div id="bottom-inner">
        <a class="bottom-item" href="https://github.com/fooying" target="_blank">GitHub</a> |
        <a class="bottom-item" href="/links">友情链接</a> |
        <a class="bottom-item" href="https://hexo.io" target="_blank">Powered by hexo</a> |
        <a class="bottom-item" href="https://github.com/fooying/hexo-theme-xoxo-plus" target="_blank">Theme xoxo-plus</a> |
        <a class="bottom-item" href="/atom.xml">RSS</a>
    </div>
</footer>

  

<script>
  (function(window, document, undefined) {

    var timer = null;

    function returnTop() {
      cancelAnimationFrame(timer);
      timer = requestAnimationFrame(function fn() {
        var oTop = document.body.scrollTop || document.documentElement.scrollTop;
        if (oTop > 0) {
          document.body.scrollTop = document.documentElement.scrollTop = oTop - 50;
          timer = requestAnimationFrame(fn);
        } else {
          cancelAnimationFrame(timer);
        }
      });
    }

    var hearts = [];
    window.requestAnimationFrame = (function() {
      return window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.oRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        function(callback) {
          setTimeout(callback, 1000 / 60);
        }
    })();
    init();

    function init() {
      css(".heart{z-index:9999;width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: absolute;}.heart:after{top: -5px;}.heart:before{left: -5px;}");
      attachEvent();
      gameloop();
      addMenuEvent();
    }

    function gameloop() {
      for (var i = 0; i < hearts.length; i++) {
        if (hearts[i].alpha <= 0) {
          document.body.removeChild(hearts[i].el);
          hearts.splice(i, 1);
          continue;
        }
        hearts[i].y--;
        hearts[i].scale += 0.004;
        hearts[i].alpha -= 0.013;
        hearts[i].el.style.cssText = "left:" + hearts[i].x + "px;top:" + hearts[i].y + "px;opacity:" + hearts[i].alpha + ";transform:scale(" + hearts[i].scale + "," + hearts[i].scale + ") rotate(45deg);background:" + hearts[i].color;
      }
      requestAnimationFrame(gameloop);
    }

    /**
     * 给logo设置点击事件
     * 
     * - 回到顶部
     * - 出现爱心
     */
    function attachEvent() {
      var old = typeof window.onclick === "function" && window.onclick;
      var logo = document.getElementById("logo");
      if (logo) {
        logo.onclick = function(event) {
          returnTop();
          old && old();
          createHeart(event);
        }
      }
      
    }

    function createHeart(event) {
      var d = document.createElement("div");
      d.className = "heart";
      hearts.push({
        el: d,
        x: event.clientX - 5,
        y: event.clientY - 5,
        scale: 1,
        alpha: 1,
        color: randomColor()
      });
      document.body.appendChild(d);
    }

    function css(css) {
      var style = document.createElement("style");
      style.type = "text/css";
      try {
        style.appendChild(document.createTextNode(css));
      } catch (ex) {
        style.styleSheet.cssText = css;
      }
      document.getElementsByTagName('head')[0].appendChild(style);
    }

    function randomColor() {
      // return "rgb(" + (~~(Math.random() * 255)) + "," + (~~(Math.random() * 255)) + "," + (~~(Math.random() * 255)) + ")";
      return "#F44336";
    }

    function addMenuEvent() {
      var menu = document.getElementById('menu-main-post');
      if (menu) {
        var toc = document.getElementById('toc');
        if (toc) {
          menu.onclick = function() {
            if (toc) {
              if (toc.style.display == 'block') {
                toc.style.display = 'none';
              } else {
                toc.style.display = 'block';
              }
            }
          };
        } else {
          menu.style.display = 'none';
        }
      }
    }

  })(window, document);
</script>

  



  
<script>
  (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
          bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      }
      else {
          bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
  })();
</script>


</body>
</html>
